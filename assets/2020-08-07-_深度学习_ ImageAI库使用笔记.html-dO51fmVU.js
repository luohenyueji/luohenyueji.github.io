import{_ as s,c as e,a,o as n}from"./app-HB0Nuzez.js";const t={};function l(p,i){return n(),e("div",null,i[0]||(i[0]=[a(`<h1 id="深度学习-imageai库使用笔记" tabindex="-1"><a class="header-anchor" href="#深度学习-imageai库使用笔记"><span>[深度学习] ImageAI库使用笔记</span></a></h1><p>ImageAI是一个Python库，旨在使开发人员，研究人员和学生能够使用简单的几行代码来构建具有独立的深度学习和计算机视觉功能的应用程序和系统。 ImageAI的官方GitHub存储库为<a href="https://github.com/OlafenwaMoses/ImageAI" target="_blank" rel="noopener noreferrer">https://github.com/OlafenwaMoses/ImageAI</a></p><p>@[toc]</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/blog/[深度学习] ImageAI库使用笔记/20200807132152107.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1b2hlbllK,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" tabindex="0" loading="lazy"><figcaption>在这里插入图片描述</figcaption></figure><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">## 去掉警告</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> warnings</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">warnings.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">filterwarnings</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;ignore&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">## 多行输出</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> IPython.core.interactiveshell </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> InteractiveShell</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">InteractiveShell.ast_node_interactivity </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;all&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_0-安装" tabindex="-1"><a class="header-anchor" href="#_0-安装"><span>0 安装</span></a></h2><p>ImageAI要求您安装Python 3.5.1或更高版本以及其他一些Python库和框架。在安装ImageAI之前，必须安装以下依赖项。</p><ul><li>Python 3.5.1或更高版本， 下载Python</li><li>pip3， 下载PyPi</li><li>Tensorflow 1.4.0或更高版本</li></ul><blockquote><p>pip3 install --upgrade tensorflow</p></blockquote><ul><li>OpenCV</li></ul><blockquote><p>pip3 install opencv-python</p></blockquote><ul><li>Keras</li></ul><blockquote><p>pip3 install keras</p></blockquote><ul><li>ImageAI</li></ul><blockquote><p>pip3 install imageai --upgrade</p></blockquote><p>一旦安装好ImageAI，通过几行代码就能够实现深度学习诸多任务功能。主要有：</p><ul><li>图像识别：识别图像中的1000个不同对象</li><li>图像物体检测：检测图像中的80个最常见的日常物体</li><li>视频对象检测：检测视频中80个最常见的日常物品</li><li>视频检测分析：对视频中检测到的对象进行基于时间的分析</li><li>自定义图像识别训练和推理：在识别自定义对象上训练新的图像新的深度学习模型</li><li>自定义目标检测训练和推理：训练新的YOLOv3模型以检测自定义对象</li></ul><p>本文主要内容有：</p><ol><li>图像预测</li><li>目标检测</li><li>视频实时检测与分析</li><li>其他功能介绍</li></ol><p>注意有官方中文文档，但是内容实时性不强。具体文档见：</p><blockquote><p><a href="https://imageai-cn.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener noreferrer">https://imageai-cn.readthedocs.io/zh_CN/latest/</a></p></blockquote><h2 id="_1-图像预测" tabindex="-1"><a class="header-anchor" href="#_1-图像预测"><span>1 图像预测</span></a></h2><p>ImageAI提供ImagePrediction类来识别1000个不同的对象。您可以使用范围仅在5行到12行之间的python代码来执行所有这些最新的计算机视觉任务。ImageAI提供用于图像预测的4种算法包括 SqueezeNet，ResNet，InceptionV3 和 DenseNet。这些算法中的每一个都有单独的模型文件，您必须根据所选算法使用相对应的模型文件。</p><ul><li><a href="https://github.com/OlafenwaMoses/ImageAI/releases/tag/1.0/" target="_blank" rel="noopener noreferrer">SqueezeNet</a>（文件大小：4.82 MB，预测时间最短，精准度适中）</li><li><a href="https://github.com/OlafenwaMoses/ImageAI/releases/tag/1.0/" target="_blank" rel="noopener noreferrer">ResNet50</a>（文件大小：98 MB，预测时间较快，精准度高）</li><li><a href="https://github.com/OlafenwaMoses/ImageAI/releases/tag/1.0/" target="_blank" rel="noopener noreferrer">InceptionV3</a>（文件大小：91.6 MB，预测时间慢，精度更高）</li><li><a href="https://github.com/OlafenwaMoses/ImageAI/releases/tag/1.0/" target="_blank" rel="noopener noreferrer">DenseNet</a> （文件大小：31.6 MB，预测时间较慢，精度最高）</li></ul><p>要在您的代码中初始化ImageAI提供ImagePrediction类来识别1000个不同的对象，您将在代码中创建该类的新实例，如下所示</p><h3 id="_1-1-参数说明" tabindex="-1"><a class="header-anchor" href="#_1-1-参数说明"><span>1.1 参数说明</span></a></h3><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> imageai.Prediction </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ImagePrediction</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">prediction </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> ImagePrediction</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>创建ImagePrediction类的新实例后，可以使用下面的函数设置实例属性并开始识别图像中的对象。</p><ul><li>.setModelTypeAsSqueezeNet()，此函数将您创建的图像识别实例的模型类型设置为SqueezeNet模型，这意味着您将使用从上面的链接下载的经过预先训练的“ SqueezeNet”模型执行图像预测任务。示例代码如下：</li></ul><blockquote><p>prediction.setModelTypeAsSqueezeNet()</p></blockquote><ul><li>.setModelTypeAsResNet()，此函数将您创建的图像识别实例的模型类型设置为ResNet模型，这意味着您将使用从上面的链接下载的经过预先训练的“ ResNet”模型执行图像预测任务。示例代码如下：</li></ul><blockquote><p>prediction.setModelTypeAsResNet()</p></blockquote><ul><li>.setModelTypeAsInceptionV3()，此函数将您创建的图像识别实例的模型类型设置为InecptionV3模型，这意味着您将使用从上面的链接下载的经过预先训练的“ InceptionV3”模型执行图像预测任务。示例代码如下：</li></ul><blockquote><p>prediction.setModelTypeAsInceptionV3()</p></blockquote><ul><li>.setModelTypeAsDenseNet()，此函数将您创建的图像识别实例的模型类型设置为DenseNet模型，这意味着您将使用从上面的链接下载的经过预先训练的“ DenseNet”模型执行图像预测任务。示例代码如下：</li></ul><blockquote><p>prediction.setModelTypeAsDenseNet()</p></blockquote><ul><li>.setModelPath()，此函数接受一个字符串，该字符串必须是您下载的模型文件的路径，并且必须与您为图像预测实例设置的模型类型相对应。示例代码如下：</li></ul><blockquote><p>prediction.setModelPath(&quot;resnet50_weights_tf_dim_ordering_tf_kernels.h5&quot;)</p></blockquote><ul><li>.loadModel()，此函数将模型从您在上面的函数调用中指定的路径加载到图像预测实例中。示例代码如下：</li></ul><blockquote><p>prediction.loadModel()</p></blockquote><pre><code>可选参数：  
prediction_speed：使用此参数可以将图像预测所需的时间减少多达80％，从而导致精度略有下降。此参数接受字符串值。可用值为“normal”, “fast”, “faster” and “fastest”。默认值为“normal”
</code></pre><ul><li>.predictImage()，这是执行图像实际预测的功能。一旦将模型加载到预测实例中，就可以在许多图像上多次调用它。示例代码如下：</li></ul><blockquote><p>predictions, probabilities = prediction.predictImage(&quot;image1.jpg&quot;, result_count=10)</p></blockquote><pre><code>参数： 
 1. image_input（必填）：这是指图像文件的路径，图像的Numpy数组或图像的图像文件流，具体取决于您指定的输入类型。
 2. result_count（可选）：这是指应返回的可能预测的数量。该参数默认设置为5。
 3. input_type（可选）：这是指您要解析为image_input参数的输入的类型。默认情况下是“文件”，并且也接受“数组”和“流”。
 4. prediction_results（python列表）：predictImage函数返回的第一个值是一个包含所有可能的预测结果的列表。结果按概率百分比的降序排列。
 5. prediction_probabilities（python列表）：predictImage函数返回的第二个值是一个列表，其中包含预测结果中所有可能预测的相应百分比概率。
</code></pre><h3 id="_1-2-样例代码" tabindex="-1"><a class="header-anchor" href="#_1-2-样例代码"><span>1.2 样例代码</span></a></h3><p>预测图片如图所示： <img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/blog/[深度学习] ImageAI库使用笔记/20200807132348764.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1b2hlbllK,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" loading="lazy"></p><p>以下为用于预测一张图像的示例代码：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> imageai.Prediction </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ImagePrediction</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">## 获得当前路径</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">execution_path </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">getcwd</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">prediction </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> ImagePrediction</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">## 加载SqueezeNet模型</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">prediction.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">setModelTypeAsSqueezeNet</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">prediction.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">setModelPath</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;squeezenet_weights_tf_dim_ordering_tf_kernels.h5&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">))</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">## 加载模型</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">prediction.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">loadModel</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">## 返回预测结果</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">predictions, probabilities </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> prediction.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">predictImage</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;image1.jpg&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">result_count</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">10</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> eachPrediction, eachProbability </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> zip</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(predictions, probabilities):</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">    print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(eachPrediction , </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot; : &quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> , eachProbability)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><pre><code>WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use \`rate\` instead of \`keep_prob\`. Rate should be set to \`rate = 1 - keep_prob\`.
sports_car  :  46.19710445404053
convertible  :  37.57524788379669
grille  :  8.19731280207634
minivan  :  2.456847205758095
pickup  :  2.162572182714939
racer  :  1.6961924731731415
beach_wagon  :  1.1535477824509144
car_wheel  :  0.24655587039887905
cab  :  0.08109718910418451
Model_T  :  0.07264625746756792
</code></pre><p>此外还可以设置检测模式，通过以下代码设定：</p><blockquote><p>prediction.loadModel(prediction_speed=&quot;fast&quot;)</p></blockquote><p>实际上改变模式，就是改变输入图片的大小，但是结果也会随之改变。同等配置下，速度越快，精度越低。 (实验环境 OS:Windows 8, CPU:Intel Celeron N2820 2.13GHz)具体效果如下：</p><ul><li>速度模式=”normal”，图片大小设置为224，224，花费时间= 5.9秒</li><li>速度模式=”fast”，图片大小设置为160，160，花费时间= 3.4秒</li><li>速度模式=”faster”，图片大小设置为120，120，花费时间= 2.7秒</li><li>速度模式=”fastest”，图片大小设置为100，100，花费时间= 2.2秒</li></ul><p>另外也可以使用多线程预测，代码如下：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>import os</span></span>
<span class="line"><span>import threading</span></span>
<span class="line"><span>execution_path = os.getcwd()</span></span>
<span class="line"><span></span></span>
<span class="line"><span>prediction = ImagePrediction()</span></span>
<span class="line"><span>prediction.setModelTypeAsResNet()</span></span>
<span class="line"><span>prediction.setModelPath( os.path.join(execution_path, &quot;resnet50_weights_tf_dim_ordering_tf_kernels.h5&quot;))</span></span>
<span class="line"><span></span></span>
<span class="line"><span>picturesfolder = os.environ[&quot;USERPROFILE&quot;] + &quot;\\Pictures\\&quot;</span></span>
<span class="line"><span>allfiles = os.listdir(picturesfolder)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>class PredictionThread(threading.Thread):</span></span>
<span class="line"><span>    def init(self):</span></span>
<span class="line"><span>        threading.Thread.init(self)</span></span>
<span class="line"><span>    def run(self):</span></span>
<span class="line"><span>        prediction.loadModel()</span></span>
<span class="line"><span>    for eachPicture in allfiles:</span></span>
<span class="line"><span>        if eachPicture.endswith(&quot;.png&quot;) or eachPicture.endswith(&quot;.jpg&quot;):</span></span>
<span class="line"><span>            predictions, probabilities = prediction.predictImage(picturesfolder + eachPicture, result_count=1)</span></span>
<span class="line"><span>            for prediction, percentage_probability in zip(predictions, probabilities):</span></span>
<span class="line"><span>                print(prediction + &quot; : &quot; + percentage_probability)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>predictionThread = PredictionThread()</span></span>
<span class="line"><span>predictionThread.start()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-目标检测" tabindex="-1"><a class="header-anchor" href="#_2-目标检测"><span>2 目标检测</span></a></h2><h3 id="_2-1-参数说明" tabindex="-1"><a class="header-anchor" href="#_2-1-参数说明"><span>2.1 参数说明</span></a></h3><p>ImageAI提供了非常强大但易于使用的类和函数来执行图像对象检测和提取。ImageAI允许您使用最新的深度学习算法（例如RetinaNet，YOLOv3和TinyYOLOv3）执行所有这些操作。使用ImageAI，您可以运行检测任务并分析图像。</p><p>ImageAI的ObjectDetection类为您提供使用在COCO数据集上训练的预训练模型对任何图像或一组图像执行对象检测的功能。支持的模型是RetinaNet，YOLOv3和TinyYOLOv3。这意味着您可以检测和识别80种常见的日常物品。首先，请通过下面的链接下载要使用的任何预训练模型。</p><ul><li><a href="https://github.com/OlafenwaMoses/ImageAI/releases/tag/1.0/" target="_blank" rel="noopener noreferrer">RetinaNet</a> （大小= 145 mb，高性能和准确性，更长的检测时间）</li><li><a href="https://github.com/OlafenwaMoses/ImageAI/releases/tag/1.0/" target="_blank" rel="noopener noreferrer">YOLOv3</a> （大小= 237 mb，性能和准确性适中，检测时间适中）</li><li><a href="https://github.com/OlafenwaMoses/ImageAI/releases/tag/1.0/" target="_blank" rel="noopener noreferrer">TinyYOLOv3</a> （大小= 34 mb，针对速度和中等性能进行了优化，具有快速检测时间）</li><li><a href="https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/resnet50_coco_best_v2.0.1.h5" target="_blank" rel="noopener noreferrer">RetinaNet</a> （大小= 145 mb，高性能和准确性，更长的检测时间）</li></ul><p>一旦下载了所选择的模型，就应该创建ObjectDetection类的新实例，如以下示例所示：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> imageai.Detection </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ObjectDetection</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> ObjectDetection</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><pre><code>Using TensorFlow backend.
</code></pre><p>一旦创建了类的实例，就可以使用下面的函数来设置实例属性并开始检测图像中的对象。</p><ul><li>.setModelTypeAsRetinaNet()，此函数将您创建的对象检测实例的模型类型设置为RetinaNet模型，这意味着您将使用从上面的链接下载的经过预先训练的“ RetinaNet”模型执行对象检测任务。示例代码如下：</li></ul><blockquote><p>detector.setModelTypeAsRetinaNet()</p></blockquote><ul><li>.setModelTypeAsYOLOv3（），此函数将您创建的对象检测实例的模型类型设置为YOLOv3模型，这意味着您将使用从上面的链接下载的经过预先训练的“ YOLOv3”模型执行对象检测任务。示例代码如下：</li></ul><blockquote><p>detector.setModelTypeAsYOLOv3()</p></blockquote><ul><li>.setModelTypeAsTinyYOLOv3()，此函数将您创建的对象检测实例的模型类型设置为TinyYOLOv3模型，这意味着您将使用从上面的链接下载的经过预先训练的“ TinyYOLOv3”模型执行对象检测任务。示例代码如下：</li></ul><blockquote><p>detector.setModelTypeAsTinyYOLOv3()</p></blockquote><ul><li>setModelTypeAsRetinaNet()，此函数将您创建的对象检测实例的模型类型设置为RetinaNet模型，这意味着您将使用从上面的链接下载的经过预先训练的“ RetinaNet3”模型执行对象检测任务。示例代码如下：</li></ul><blockquote><p>detector.setModelTypeAsRetinaNet()</p></blockquote><ul><li>.setModelPath()和.loadModel() 与图像预测中所述一样。</li><li>.detectObjectsFromImage()，此函数在加载模型后执行对象检测任务。可以多次调用它以检测任意数量的图像中的对象。示例代码如下：</li></ul><blockquote><p>detections = detector.detectObjectsFromImage(input_image=&quot;image.jpg&quot;, output_image_path=&quot;imagenew.jpg&quot;, minimum_percentage_probability=30)</p></blockquote><pre><code>参数：
1. input_image（必填）：这是指您要检测的图像文件的路径。如果将参数input_type设置为“ array”或“ stream”，则可以将此参数设置为任何图像的File流的Numpy数组。
2. output_image_path（仅在input_type =“ file” 时才需要）：表示将检测到的图像保存到的文件路径。仅当input_type =“ file” 时才需要。
3. minimum_percentage_probability（可选）：此参数用于确定检测结果的完整性。降低该值将显示更多的对象，而增加该值可确保检测到精度最高的对象。默认值为50。
4. output_type（可选）：此参数用于设置将产生检测到的图像的格式。可用值为“file”和“array”。默认值为“file”。如果此参数设置为“ array”，则该函数将返回检测到的图像的Numpy数组。请参见以下示例：
&gt; returned_image, detections = detector.detectObjectsFromImage(input_image=”image.jpg”, output_type=”array”, minimum_percentage_probability=30)
5. display_percentage_probability（可选）：如果设置为False，则此参数可用于隐藏在检测到的图像中检测到的每个对象的百分比概率。默认值为True。
6. display_object_name（可选）：如果设置为False，则此参数可用于隐藏检测到的图像中检测到的每个对象的名称。默认值为True。
7. extract_detected_objects（可选）：此参数可用于提取和保存/返回图像中检测到的每个对象作为单独的图像。默认值为False。
8. thread_safe（可选）：如果设置为true，则确保加载的检测模型可在所有线程上工作。
</code></pre><ul><li>.CustomObjects()，当您只想检测选定数量的对象时，可以使用此函数。它返回对象及其正确或错误值的字典。要检测图像中的选定对象，必须将this函数返回的字典与detectCustomObjectsFromImage（）函数一起使用。在下面的注释和代码示例中找到详细信息：</li></ul><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>There are 80 possible objects that you can detect with the</span></span>
<span class="line"><span>ObjectDetection class, and they are as seen below.</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    person,   bicycle,   car,   motorcycle,   airplane,</span></span>
<span class="line"><span>    bus,   train,   truck,   boat,   traffic light,   fire hydrant,   stop_sign,</span></span>
<span class="line"><span>    parking meter,   bench,   bird,   cat,   dog,   horse,   sheep,   cow,   elephant,   bear,   zebra,</span></span>
<span class="line"><span>    giraffe,   backpack,   umbrella,   handbag,   tie,   suitcase,   frisbee,   skis,   snowboard,</span></span>
<span class="line"><span>    sports ball,   kite,   baseball bat,   baseball glove,   skateboard,   surfboard,   tennis racket,</span></span>
<span class="line"><span>    bottle,   wine glass,   cup,   fork,   knife,   spoon,   bowl,   banana,   apple,   sandwich,   orange,</span></span>
<span class="line"><span>    broccoli,   carrot,   hot dog,   pizza,   donot,   cake,   chair,   couch,   potted plant,   bed,</span></span>
<span class="line"><span>    dining table,   toilet,   tv,   laptop,   mouse,   remote,   keyboard,   cell phone,   microwave,</span></span>
<span class="line"><span>    oven,   toaster,   sink,   refrigerator,   book,   clock,   vase,   scissors,   teddy bear,   hair dryer,</span></span>
<span class="line"><span>    toothbrush.</span></span>
<span class="line"><span></span></span>
<span class="line"><span>To detect only some of the objects above, you will need to call the CustomObjects function and set the name of the</span></span>
<span class="line"><span>object(s) yiu want to detect to through. The rest are False by default. In below example, we detected only chose detect only person and dog.</span></span>
<span class="line"><span></span></span>
<span class="line"><span>custom = detector.CustomObjects(person=True, dog=True)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>.detectCustomObjectsFromImage()，此函数具有所有参数，并返回detectObjectsFromImage()函数所做的所有值，但略有不同。使用此功能可以仅检测图像中的选定对象。与常规的detectObjectsFromImage()函数不同，它需要一个额外的参数“ custom_object”，该参数接受CustomObject()函数返回的字典。在下面的示例中，我们将检测功能设置为仅报告对人和狗的检测：</li></ul><blockquote><p>custom = detector.CustomObjects(person=True, dog=True)<br> detections = detector.detectCustomObjectsFromImage( custom_objects=custom, input_image=os.path.join(execution_path , &quot;image3.jpg&quot;), output_image_path=os.path.join(execution_path , &quot;image3new-custom.jpg&quot;), minimum_percentage_probability=30)</p></blockquote><p>对于类检测的返回参数说明如下：</p><ul><li><p>如果设置了所有必需的参数，并且将“ output_image_path”设置为要保存检测到的图像的文件路径，该函数将返回：</p><ol><li>检测图像的numpy数组 <ul><li>name (string)</li><li>percentage_probability (float)</li><li>box_points (tuple of x1,y1,x2 and y2 coordinates)</li></ul></li></ol><blockquote><p>detections = detector.detectObjectsFromImage(input_image=”image.jpg”, output_image_path=”imagenew.jpg”, minimum_percentage_probability=30)</p></blockquote></li><li><p>如果设置了所有必需的参数并且output_type =&#39;array&#39;，该函数将返回：</p><ol><li>检测图像的numpy数组</li><li>字典数组，每个字典对应于对象</li></ol><blockquote><p>returned_image, detections = detector.detectObjectsFromImage(input_image=”image.jpg”, output_type=”array”, minimum_percentage_probability=30)</p></blockquote></li><li><p>如果extract_detected_objects = True，并且“ output_image_path”设置为所需的文件路径，该函数将返回：</p><ol><li>字典数组，每个字典对应于对象</li><li>从图像中提取的每个对象的图像的字符串路径数组</li></ol><blockquote><p>detections, extracted_objects = detector.detectObjectsFromImage(input_image=”image.jpg”, output_image_path=”imagenew.jpg”, extract_detected_objects=True, minimum_percentage_probability=30)</p></blockquote></li><li><p>如果extract_detected_objects = True且output_type =&#39;array&#39;，则该函数将返回：</p><ol><li>检测图像的numpy数组</li><li>字典数组，每个字典对应于对象</li><li>图像中检测到的每个对象的numpy数组的数组</li></ol><blockquote><p>returned_image, detections, extracted_objects = detector.detectObjectsFromImage(input_image=”image.jpg”, output_type=”array”, extract_detected_objects=True, minimum_percentage_probability=30)</p></blockquote></li></ul><h3 id="_2-2-样例代码" tabindex="-1"><a class="header-anchor" href="#_2-2-样例代码"><span>2.2 样例代码</span></a></h3><p>样例图片如下：</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/blog/[深度学习] ImageAI库使用笔记/20200807132430480.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1b2hlbllK,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" tabindex="0" loading="lazy"><figcaption>在这里插入图片描述</figcaption></figure><p>基本使用代码如下：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> imageai.Detection </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ObjectDetection</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">execution_path </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">getcwd</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> ObjectDetection</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">setModelTypeAsTinyYOLOv3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">setModelPath</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">( os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path , </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;yolo-tiny.h5&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">))</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">loadModel</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detections </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">detectObjectsFromImage</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">input_image</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path , </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;image2.jpg&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">output_image_path</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path , </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;image2new.jpg&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">minimum_percentage_probability</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">30</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> eachObject </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> detections:</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">    print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(eachObject[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;name&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] , </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot; : &quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, eachObject[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;percentage_probability&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot; : &quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, eachObject[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;box_points&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] )</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">    print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;--------------------------------&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><pre><code>donut  :  56.126707792282104  :  (15, 379, 129, 438)
--------------------------------
person  :  56.23413324356079  :  (169, 104, 285, 297)
--------------------------------
person  :  62.340474128723145  :  (412, 120, 567, 282)
--------------------------------
person  :  83.61815810203552  :  (307, 169, 384, 256)
--------------------------------
</code></pre><p>检测效果很一般，结果如图所示：</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/blog/[深度学习] ImageAI库使用笔记/20200807132454632.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1b2hlbllK,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" tabindex="0" loading="lazy"><figcaption>在这里插入图片描述</figcaption></figure><p>当extract_detected_objects为True时，可以保存各个检测到物体的图像</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> imageai.Detection </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ObjectDetection</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">execution_path </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">getcwd</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> ObjectDetection</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">setModelTypeAsTinyYOLOv3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">setModelPath</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">( os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path , </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;yolo-tiny.h5&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">))</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">loadModel</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detections, objects_path </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">detectObjectsFromImage</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">input_image</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path , </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;image3.jpg&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">output_image_path</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path , </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;image3new.jpg&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">minimum_percentage_probability</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">30</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,  </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">extract_detected_objects</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> eachObject, eachObjectPath </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> zip</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(detections, objects_path):</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">    print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(eachObject[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;name&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] , </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot; : &quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> , eachObject[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;percentage_probability&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot; : &quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, eachObject[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;box_points&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] )</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">    print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;--------------------------------&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><pre><code>dog  :  56.62620663642883  :  (395, 324, 449, 434)
--------------------------------
motorcycle  :  42.00802147388458  :  (264, 190, 354, 306)
--------------------------------
person  :  34.74058508872986  :  (143, 119, 170, 159)
--------------------------------
person  :  40.15779793262482  :  (461, 131, 509, 222)
--------------------------------
person  :  64.91314768791199  :  (157, 159, 246, 362)
--------------------------------
person  :  78.07608842849731  :  (601, 130, 640, 222)
--------------------------------
person  :  89.72326517105103  :  (10, 100, 65, 252)
--------------------------------
person  :  97.73167967796326  :  (536, 99, 580, 228)
--------------------------------
</code></pre><p>检测前后结果如图所示： <img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/blog/[深度学习] ImageAI库使用笔记/20200807132759255.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1b2hlbllK,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/blog/[深度学习] ImageAI库使用笔记/20200807132759155.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1b2hlbllK,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p><p>此外还可以自定义对象检测，也就是选择检测某几个物体。ImageAI允许您对上述一项或多项进行检测。这意味着您可以自定义要在图像中检测到的对象的类型。具体的物体类别前面已经说过。下面代码显示只检测狗。但是速度明显慢很多。</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> imageai.Detection </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ObjectDetection</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">execution_path </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">getcwd</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> ObjectDetection</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">setModelTypeAsTinyYOLOv3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">setModelPath</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">( os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path , </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;yolo-tiny.h5&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">))</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">loadModel</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">custom_objects </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">CustomObjects</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dog</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detections </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">detectCustomObjectsFromImage</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">custom_objects</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">custom_objects, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">input_image</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path , </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;image3.jpg&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">output_image_path</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path , </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;image3custom.jpg&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">minimum_percentage_probability</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">30</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> eachObject </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> detections:</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">    print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(eachObject[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;name&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] , </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot; : &quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, eachObject[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;percentage_probability&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot; : &quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, eachObject[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;box_points&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] )</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">    print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;--------------------------------&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><pre><code>dog  :  56.62620663642883  :  (395, 324, 449, 434)
--------------------------------
</code></pre><p>其他用法，比如加快速度，类似对象检测的用法。</p><h2 id="_3-视频实时检测与分析" tabindex="-1"><a class="header-anchor" href="#_3-视频实时检测与分析"><span>3 视频实时检测与分析</span></a></h2><h3 id="_3-1-参数说明" tabindex="-1"><a class="header-anchor" href="#_3-1-参数说明"><span>3.1 参数说明</span></a></h3><p>ImageAI提供了非常强大但易于使用的类和函数来执行 视频对象检测和跟踪 以及视频分析。ImageAI允许您使用最新的深度学习算法（例如RetinaNet，YOLOv3和TinyYOLOv3）执行所有这些操作。使用ImageAI您可以运行检测任务并分析来自设备摄像机和IP摄像机的视频和实况视频源。</p><p>VideoObjectDetection类提供了使用在COCO数据集上进行训练的预训练模型来检测视频中的对象以及来自设备摄像机和IP摄像机的实时馈送的功能。支持的模型是RetinaNet，YOLOv3和TinyYOLOv3。这意味着您可以在任何视频中检测和识别80种常见的日常物体。首先，请通过下面的链接下载要使用的任何预训练模型。</p><ul><li><a href="https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/resnet50_coco_best_v2.0.1.h5" target="_blank" rel="noopener noreferrer">RetinaNet</a> （大小= 145 mb，高性能和准确性，更长的检测时间）</li><li><a href="https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo.h5" target="_blank" rel="noopener noreferrer">YOLOv3</a> （大小= 237 mb，性能和准确性适中，检测时间适中）</li><li><a href="https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo-tiny.h5" target="_blank" rel="noopener noreferrer">TinyYOLOv3</a> （大小= 34 mb，针对速度和中等性能进行了优化，具有快速检测时间）</li></ul><p>由于视频对象检测是一项计算密集型任务，因此建议您使用装有NVIDIA GPU和GPU版本的Tensorflow的计算机执行此实验。执行视频对象检测CPU的速度将比使用NVIDIA GPU驱动的计算机慢。</p><p>下载选择使用的模型后，创建VideoObjectDetection的实例，如下所示：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> imageai.Detection </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> VideoObjectDetection</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> VideoObjectDetection</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>创建该类的实例后，您可以调用以下函数来设置其属性并检测视频中的对象。</p><ul><li>.setModelTypeAsRetinaNet()，此函数将您创建的对象检测实例的模型类型设置为RetinaNet模型，这意味着您将使用从上面的链接下载的经过预先训练的“ RetinaNet”模型执行对象检测任务。示例代码如下：</li></ul><blockquote><p>detector.setModelTypeAsRetinaNet()</p></blockquote><ul><li>.setModelTypeAsYOLOv3()，此函数将您创建的对象检测实例的模型类型设置为YOLOv3模型，这意味着您将使用从上面的链接下载的经过预先训练的“ YOLOv3”模型执行对象检测任务。示例代码如下</li></ul><blockquote><p>detector.setModelTypeAsYOLOv3()</p></blockquote><ul><li>.setModelTypeAsTinyYOLOv3()，此函数将您创建的对象检测实例的模型类型设置为TinyYOLOv3模型，这意味着您将使用从上面的链接下载的经过预先训练的“ TinyYOLOv3”模型执行对象检测任务。示例代码如下</li></ul><blockquote><p>detector.setModelTypeAsTinyYOLOv3()</p></blockquote><ul><li>.setModelPath()、.loadModel()与其他检测类型一样。</li><li>.detectObjectsFromVideo()。这个函数在将模型加载到您创建的实例中之后，对视频文件或视频实时提要执行对象检测。找到一个完整的样本代码如下:</li></ul><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>from imageai.Detection import VideoObjectDetection</span></span>
<span class="line"><span>import os</span></span>
<span class="line"><span></span></span>
<span class="line"><span>execution_path = os.getcwd()</span></span>
<span class="line"><span></span></span>
<span class="line"><span>detector = VideoObjectDetection()</span></span>
<span class="line"><span>detector.setModelTypeAsYOLOv3()</span></span>
<span class="line"><span>detector.setModelPath( os.path.join(execution_path , &quot;yolo.h5&quot;))</span></span>
<span class="line"><span>detector.loadModel()</span></span>
<span class="line"><span></span></span>
<span class="line"><span>video_path = detector.detectObjectsFromVideo(input_file_path=os.path.join(execution_path, &quot;traffic.mp4&quot;),</span></span>
<span class="line"><span>                            output_file_path=os.path.join(execution_path, &quot;traffic_detected&quot;)</span></span>
<span class="line"><span>                            , frames_per_second=20, log_progress=True)</span></span>
<span class="line"><span>print(video_path)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>参数 input_file_path（如果未设置camera_input，则为必需）：这是指您要检测的视频文件的路径。</li><li>参数 output_file_path（如果未设置save_detected_video = False，则为必需）：这是指将检测到的视频保存到的路径。默认情况下，此功能保存视频 .avi格式。</li><li>参数 frames_per_second（可选，但建议使用）：使用此参数可以为要保存的检测到的视频设置每秒所需的帧数。默认值为20，但我们建议您设置适合视频或摄像机实时供稿的值。</li><li>参数 log_progress（可选）：将此参数设置为True将显示检测到的视频或实时视频的进度。它将报告每一帧检测到的进展。默认值为False。</li><li>参数 return_detected_frame（可选）该参数允许您在检测到的视频的每一帧、每一秒和每一分钟中以Numpy数组的形式返回检测到的帧。返回的Numpy数组将被解析为各自的per_frame_function、per_second_function和per_minute_function。</li><li>参数 camera_input（可选）：如果您想在摄像机的实时提要中检测对象，可以设置这个参数来替代input_file_path。您所需要做的就是用OpenCV的VideoCapture()函数加载摄像机，并将对象解析为这个参数。</li><li>参数 minimum_percentage_probability（可选）：此参数用于确定检测结果的完整性。降低该值将显示更多的对象，而增加该值可确保检测到精度最高的对象。默认值为50。</li><li>参数 display_percentage_probability（可选）：如果设置为False，则此参数可用于隐藏在检测到的视频中检测到的每个对象的百分比概率。默认值为True。</li><li>参数 display_object_name（可选）：如果设置为False，则此参数可用于隐藏检测到的视频中检测到的每个对象的名称。默认值为True。</li><li>参数 save_detected_video（可选）：此参数可用于是否保存检测到的视频或不保存。默认情况下将其设置为True。</li><li>参数 per_frame_function（可选）：使用此参数可以解析您定义的函数的名称。然后，对于检测到的视频的每一帧，将功能解析为参数，然后执行该参数，并将视频的解析数据解析为功能。返回的数据可以可视化或保存在NoSQL数据库中，以备将来处理和可视化。</li><li>参数 per_second_function（可选）：使用此参数可以解析定义的函数的名称。然后，对于检测到的视频的每一秒，将功能解析为参数，将执行参数，并将视频的解析数据解析为功能。返回的数据可以可视化或保存在NoSQL数据库中，以备将来处理和可视化。</li><li>参数 per_minute_function（可选）：使用此参数可以解析您定义的函数的名称。然后，对于检测到的视频的每一分，将执行已解析为参数的功能，并将视频的解析数据解析为该功能。返回的数据与per_second_function具有相同的性质；区别在于它覆盖了视频过去1分钟的所有帧。</li><li>参数 video_complete_function（可选）：使用此参数可以解析您定义的函数的名称。一旦视频中的所有帧都被完全检测到，该函数将被解析为参数，并且参数将被解析为视频。返回的数据与per_second_function和per_minute_function具有相同的性质；区别在于不会返回索引，并且索引会覆盖整个视频中的所有帧。</li><li>参数 detection_timeout（可选）：此功能允许您声明应该检测的视频的秒数，在此秒之后，检测功能将停止处理视频。</li></ul><h3 id="_3-2-样例代码" tabindex="-1"><a class="header-anchor" href="#_3-2-样例代码"><span>3.2 样例代码</span></a></h3><p>视频下载地址： <a href="https://github.com/OlafenwaMoses/ImageAI/blob/master/data-videos/traffic.mp4" target="_blank" rel="noopener noreferrer">https://github.com/OlafenwaMoses/ImageAI/blob/master/data-videos/traffic.mp4</a></p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> imageai.Detection </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> VideoObjectDetection</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">execution_path </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">getcwd</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> VideoObjectDetection</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">setModelTypeAsTinyYOLOv3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">setModelPath</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">( os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path , </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;yolo-tiny.h5&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">))</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">loadModel</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">## frames_per_second保存的视频每秒帧数,视频检测秒数</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">video_path </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">detectObjectsFromVideo</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">input_file_path</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;traffic.mp4&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">),</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                                output_file_path</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;traffic_detected&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                , </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">frames_per_second</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">20</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">log_progress</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">detection_timeout</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><pre><code>0
1
Processing Frame :  1
0
2
Processing Frame :  2
0
3
Processing Frame :  3
0
4
Processing Frame :  4
0
5
Processing Frame :  5
0
6
Processing Frame :  6
0
7
Processing Frame :  7
0
8
Processing Frame :  8
0
9
Processing Frame :  9
0
10
Processing Frame :  10
0
11
Processing Frame :  11
0
12
Processing Frame :  12
0
13
Processing Frame :  13
0
14
Processing Frame :  14
0
15
Processing Frame :  15
0
16
Processing Frame :  16
0
17
Processing Frame :  17
0
18
Processing Frame :  18
0
19
Processing Frame :  19
1
20
</code></pre><p>输出视频如图所示： <img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/blog/[深度学习] ImageAI库使用笔记/20200807132924397.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1b2hlbllK,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" loading="lazy"></p><p>有趣的是，ImageAI允许您对上述一项或多项进行检测。这意味着您可以自定义要在视频中检测到的对象的类型。让我们看一下下面的代码：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> imageai.Detection </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> VideoObjectDetection</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">execution_path </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">getcwd</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> VideoObjectDetection</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">setModelTypeAsTinyYOLOv3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">setModelPath</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">( os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path , </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;yolo-tiny.h5&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">))</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">loadModel</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">custom_objects </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">CustomObjects</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">person</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">bicycle</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">motorcycle</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">video_path </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> detector.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">detectCustomObjectsFromVideo</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                custom_objects</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">custom_objects,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                input_file_path</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;traffic.mp4&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">),</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                output_file_path</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(execution_path, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;traffic_custom_detected&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">),</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                frames_per_second</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">20</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">log_progress</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">detection_timeout</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><pre><code>0
1
Processing Frame :  1
0
2
Processing Frame :  2
0
3
Processing Frame :  3
0
4
Processing Frame :  4
0
5
Processing Frame :  5
0
6
Processing Frame :  6
0
7
Processing Frame :  7
0
8
Processing Frame :  8
0
9
Processing Frame :  9
0
10
Processing Frame :  10
0
11
Processing Frame :  11
0
12
Processing Frame :  12
0
13
Processing Frame :  13
0
14
Processing Frame :  14
0
15
Processing Frame :  15
0
16
Processing Frame :  16
0
17
Processing Frame :  17
0
18
Processing Frame :  18
0
19
Processing Frame :  19
1
20
</code></pre><p>此外还有视频分功能。ImageAI现在在“视频对象检测”类中为视频文件输入和摄像机输入提供商业级视频分析。此功能使开发人员可以深入了解使用ImageAI处理的任何视频。这些见解可以实时可视化，存储在NoSQL数据库中，以备将来查看或分析。</p><p>对于视频分析，detectObjectsFromVideo()和detectCustomObjectsFromVideo()现在可以让您声明自己定义的功能，该功能将针对检测到的视频的每一帧，秒和/或分钟执行，并提供一种状态，该功能将在视频检测结束时执行。声明此功能后，它们将接收有关帧/秒/分钟的索引，检测到的对象（名称，percent_probability和box_points），检测到的每个唯一对象的实例数以及每个对象的平均出现次数的原始但全面的分析数据在每秒/分钟和整个视频中检测到的唯一对象。</p><p>若要获取视频分析，只需指定一个函数，该函数描述它将接收的相应参数，并将函数名称解析为检测函数中的 per_frame_function、per_second_function、per_minute_function 和 video_complete_function 参数。</p><h2 id="_4-其他功能介绍" tabindex="-1"><a class="header-anchor" href="#_4-其他功能介绍"><span>4 其他功能介绍</span></a></h2><p>ImageAI还有自定义检测模型训练，自定义对象检测，自定义视频对象检测与分析等功能。</p><p>具体见链接</p><blockquote><p><a href="https://github.com/OlafenwaMoses/ImageAI" target="_blank" rel="noopener noreferrer">https://github.com/OlafenwaMoses/ImageAI</a></p></blockquote><h2 id="_5-参考" tabindex="-1"><a class="header-anchor" href="#_5-参考"><span>5 参考</span></a></h2><blockquote><p><a href="https://github.com/OlafenwaMoses/ImageAI" target="_blank" rel="noopener noreferrer">https://github.com/OlafenwaMoses/ImageAI</a></p></blockquote><blockquote><p><a href="https://imageai.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">https://imageai.readthedocs.io/en/latest/</a></p></blockquote><blockquote><p><a href="https://imageai-cn.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener noreferrer">https://imageai-cn.readthedocs.io/zh_CN/latest/</a></p></blockquote>`,134)]))}const r=s(t,[["render",l],["__file","2020-08-07-_深度学习_ ImageAI库使用笔记.html.vue"]]),k=JSON.parse('{"path":"/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2020-08-07-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20ImageAI%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0.html","title":"[深度学习] ImageAI库使用笔记","lang":"zh-CN","frontmatter":{"date":"2020-08-07T13:31:38.000Z","category":["深度学习"],"tag":["深度学习","Python"],"description":"[深度学习] ImageAI库使用笔记 ImageAI是一个Python库，旨在使开发人员，研究人员和学生能够使用简单的几行代码来构建具有独立的深度学习和计算机视觉功能的应用程序和系统。 ImageAI的官方GitHub存储库为https://github.com/OlafenwaMoses/ImageAI @[toc] 在这里插入图片描述在这里插入图...","head":[["meta",{"property":"og:url","content":"https://luohenyueji.github.io/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2020-08-07-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20ImageAI%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0.html"}],["meta",{"property":"og:site_name","content":"落痕月极的博客"}],["meta",{"property":"og:title","content":"[深度学习] ImageAI库使用笔记"}],["meta",{"property":"og:description","content":"[深度学习] ImageAI库使用笔记 ImageAI是一个Python库，旨在使开发人员，研究人员和学生能够使用简单的几行代码来构建具有独立的深度学习和计算机视觉功能的应用程序和系统。 ImageAI的官方GitHub存储库为https://github.com/OlafenwaMoses/ImageAI @[toc] 在这里插入图片描述在这里插入图..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/blog/%5B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%5D%20ImageAI%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/20200807132152107.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1b2hlbllK,size_16,color_FFFFFF,t_70#pic_center"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:tag","content":"深度学习"}],["meta",{"property":"article:tag","content":"Python"}],["meta",{"property":"article:published_time","content":"2020-08-07T13:31:38.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"[深度学习] ImageAI库使用笔记\\",\\"image\\":[\\"https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/blog/%5B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%5D%20ImageAI%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/20200807132152107.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1b2hlbllK,size_16,color_FFFFFF,t_70#pic_center\\",\\"https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/blog/%5B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%5D%20ImageAI%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/20200807132348764.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1b2hlbllK,size_16,color_FFFFFF,t_70#pic_center\\",\\"https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/blog/%5B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%5D%20ImageAI%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/20200807132430480.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1b2hlbllK,size_16,color_FFFFFF,t_70#pic_center\\",\\"https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/blog/%5B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%5D%20ImageAI%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/20200807132454632.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1b2hlbllK,size_16,color_FFFFFF,t_70#pic_center\\",\\"https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/blog/%5B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%5D%20ImageAI%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/20200807132759255.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1b2hlbllK,size_16,color_FFFFFF,t_70\\",\\"https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/blog/%5B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%5D%20ImageAI%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/20200807132759155.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1b2hlbllK,size_16,color_FFFFFF,t_70\\",\\"https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/blog/%5B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%5D%20ImageAI%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/20200807132924397.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1b2hlbllK,size_16,color_FFFFFF,t_70#pic_center\\"],\\"datePublished\\":\\"2020-08-07T13:31:38.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"落痕月极\\",\\"url\\":\\"/\\"}]}"]]},"headers":[{"level":2,"title":"0 安装","slug":"_0-安装","link":"#_0-安装","children":[]},{"level":2,"title":"1 图像预测","slug":"_1-图像预测","link":"#_1-图像预测","children":[{"level":3,"title":"1.1 参数说明","slug":"_1-1-参数说明","link":"#_1-1-参数说明","children":[]},{"level":3,"title":"1.2 样例代码","slug":"_1-2-样例代码","link":"#_1-2-样例代码","children":[]}]},{"level":2,"title":"2 目标检测","slug":"_2-目标检测","link":"#_2-目标检测","children":[{"level":3,"title":"2.1 参数说明","slug":"_2-1-参数说明","link":"#_2-1-参数说明","children":[]},{"level":3,"title":"2.2 样例代码","slug":"_2-2-样例代码","link":"#_2-2-样例代码","children":[]}]},{"level":2,"title":"3 视频实时检测与分析","slug":"_3-视频实时检测与分析","link":"#_3-视频实时检测与分析","children":[{"level":3,"title":"3.1 参数说明","slug":"_3-1-参数说明","link":"#_3-1-参数说明","children":[]},{"level":3,"title":"3.2 样例代码","slug":"_3-2-样例代码","link":"#_3-2-样例代码","children":[]}]},{"level":2,"title":"4 其他功能介绍","slug":"_4-其他功能介绍","link":"#_4-其他功能介绍","children":[]},{"level":2,"title":"5 参考","slug":"_5-参考","link":"#_5-参考","children":[]}],"git":{},"readingTime":{"minutes":22.35,"words":6706},"filePathRelative":"blog/深度学习/深度学习笔记/2020-08-07-[深度学习] ImageAI库使用笔记.md","localizedDate":"2020年8月7日","excerpt":"\\n<p>ImageAI是一个Python库，旨在使开发人员，研究人员和学生能够使用简单的几行代码来构建具有独立的深度学习和计算机视觉功能的应用程序和系统。\\nImageAI的官方GitHub存储库为<a href=\\"https://github.com/OlafenwaMoses/ImageAI\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://github.com/OlafenwaMoses/ImageAI</a></p>\\n<p>@[toc]</p>\\n<figure><img src=\\"https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/blog/[深度学习] ImageAI库使用笔记/20200807132152107.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1b2hlbllK,size_16,color_FFFFFF,t_70#pic_center\\" alt=\\"在这里插入图片描述\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>在这里插入图片描述</figcaption></figure>","autoDesc":true}');export{r as comp,k as data};

import{_ as r}from"./plugin-vue_export-helper-x3n3nnut.js";import{r as d,o as s,c as i,a as e,b as a,d as l,e as t}from"./app-MsA2k2kn.js";const T={},Q=t(`<h1 id="机器学习-sklearn聚类" tabindex="-1"><a class="header-anchor" href="#机器学习-sklearn聚类" aria-hidden="true">#</a> [机器学习] sklearn聚类</h1><p>聚类（Clustering）简单来说就是一种分组方法，将一类事物中具有相似性的个体分为一类，将另一部分比较相近的个体分为另一类。例如人和猿都是灵长目动物，但是根据染色体数目不同可以将人和猿分类不同的两类。虽然人根据肤色又可以分为黄种人，白种人，有色种人，但是根据行为举止和形态，往往把黄种人，白种人等归于人这一大类。</p><h2 id="k-means-算法" tabindex="-1"><a class="header-anchor" href="#k-means-算法" aria-hidden="true">#</a> K-Means 算法</h2><p>K-Means算法是聚类中一种非常常用的算法。具体步骤如下：</p><ol><li>从n个对象中任意选择k个对象作为初始聚类中心</li><li>计算每个对象计算与这k个初始聚类中心的距离。</li><li>经过步骤2的计算，各个对象都与这k个聚类中心都有一个距离。对于某个对象将其和距离其最近的初始聚类中心归为一个类簇。</li><li>重新计算每个类簇的聚类中心的位置。</li><li>重复3，4两个步骤，直到每次计算发生类簇变化的对象数量较少时结束分类。</li></ol><p>K-Means算法中，需要实现确定有： 初始聚类中心的数量，距离计算公式（曼哈顿距离，欧氏距离），类簇的数量。</p><p><strong>sklearn基础代码</strong></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
 
#15个点
x1 = np.array([1, 2, 3, 2, 1, 5, 6, 5, 5, 6, 7, 8, 9, 7, 9])
x2 = np.array([1, 3, 2, 2, 2, 8, 6, 7, 6, 7, 1, 2, 1, 1, 3])
X = np.array(list(zip(x1, x2))).reshape(len(x1), 2)
plt.xlim([0, 10])
plt.ylim([0, 10])
plt.title(&#39;Sample&#39;)
#查看15个点的分布
plt.scatter(x1, x2)
plt.show()
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>上面代码首先获得15个点，15个点分布如下图所示：</p><figure><img src="https://img-blog.csdn.net/20180417220748969" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>`,10),m={href:"http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans",target:"_blank",rel:"noopener noreferrer"},o=t(`<div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>#类簇的数量
clusters=3
 
#聚类
kmeans_model = KMeans(n_clusters=clusters).fit(X)
#打印聚类结果
print(&#39;聚类结果：&#39;, kmeans_model.labels_) #聚类结果： [1 1 1 1 1 0 0 0 0 0 2 2 2 2 2]
#画图
colors = [&#39;black&#39;, &#39;green&#39;, &#39;red&#39;]  
markers = [&#39;o&#39;, &#39;s&#39;, &#39;D&#39;]  
 
for i, l in enumerate(kmeans_model.labels_):  
    plt.plot(x1[i], x2[i], color=colors[l],marker=markers[l],ls=&#39;None&#39;)  
    plt.xlim([0, 10])  
    plt.ylim([0, 10])  
    plt.title(&#39;K = %s&#39; %(clusters)) 
plt.show()
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>分类结果：</p><figure><img src="https://img-blog.csdn.net/20180417221901230" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="层次聚类" tabindex="-1"><a class="header-anchor" href="#层次聚类" aria-hidden="true">#</a> 层次聚类</h2><p>层次聚类（Hierarchical Clustering）是指通过聚类算法将样本分为若干的大类簇，然后将大类簇分为若干个小类簇。最后形成类似一棵树的结构。例如大学里面可以分为若干学院，学院又可分为若干的系。sklearn中对应的算法函数为cluster.AgglomerativeClustering函数。该函数有三种策略：</p><ul><li>Ward策略：以所有类簇中的方差最小化为目标</li><li>Maximum策略： 以各类簇之间的距离最大值最小化为目标</li><li>Average linkage策略： 以各类簇之间的距离的平均值最小化为目标</li></ul><p>函数使用为：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>model = AgglomerativeClustering(linkage=&#39;ward&#39;,n_clusters=clusters).fit(X)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div>`,8),c={href:"http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering",target:"_blank",rel:"noopener noreferrer"},u={href:"https://blog.csdn.net/sinat_30665603/article/details/52207925",target:"_blank",rel:"noopener noreferrer"},p=e("h2",{id:"密度聚类",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#密度聚类","aria-hidden":"true"},"#"),a(" 密度聚类")],-1),v=e("p",null,"密度聚类适用于聚类形状不规则的情况，如下图所示：",-1),h=e("figure",null,[e("img",{src:"https://img-blog.csdn.net/20180417234022400",alt:"",tabindex:"0",loading:"lazy"}),e("figcaption")],-1),g={href:"https://www.cnblogs.com/pinard/p/6217852.html",target:"_blank",rel:"noopener noreferrer"},b=e("p",null,"sklearn中进行密度聚类的函数为cluster.DBSCAN。函数使用为：",-1),_=e("div",{class:"language-text line-numbers-mode","data-ext":"text"},[e("pre",{class:"language-text"},[e("code",null,`DBSCAN(eps=2000, min_samples=1).fit(X)
`)]),e("div",{class:"line-numbers","aria-hidden":"true"},[e("div",{class:"line-number"})])],-1),f=e("p",null,"其中eps是指设定的阈值，在算法进行时，如果在这个范围内找不到对象，则认为所操作的类簇确认完毕。",-1),x={href:"http://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN",target:"_blank",rel:"noopener noreferrer"},k=e("h2",{id:"聚类评估",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#聚类评估","aria-hidden":"true"},"#"),a(" 聚类评估")],-1),H=e("p",null,"聚类的质量评估主要有最佳类簇数的确定和聚类效果评价。",-1),M=e("p",null,[e("strong",null,"最佳簇数确定")],-1),y=e("p",null,"最佳簇数的确定主要有两种方法：经验法和肘方法。",-1),L=e("ol",null,[e("li",null,"经验法，主要指对于含有n个对象的空间，最佳簇数为")],-1),w={class:"MathJax",jax:"SVG",display:"true",style:{position:"relative"}},Z={style:{"vertical-align":"-1.965ex"},xmlns:"http://www.w3.org/2000/svg",width:"4.661ex",height:"5.566ex",role:"img",focusable:"false",viewBox:"0 -1591.3 2060 2460","aria-hidden":"true"},D=t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msqrt"><g transform="translate(1020,0)"><g data-mml-node="mfrac"><g data-mml-node="mi" transform="translate(220,676)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(270,-686)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><rect width="800" height="60" x="120" y="220"></rect></g></g><g data-mml-node="mo" transform="translate(0,81.3)"><path data-c="221A" d="M424 -948Q422 -947 313 -434T202 80L170 31Q165 24 157 10Q137 -21 137 -21Q131 -16 124 -8L111 5L264 248L473 -720Q473 -717 727 359T983 1440Q989 1450 1001 1450Q1007 1450 1013 1445T1020 1433Q1020 1425 742 244T460 -941Q458 -950 439 -950H436Q424 -950 424 -948Z"></path></g><rect width="1040" height="60" x="1020" y="1471.3"></rect></g></g></g>',1),V=[D],C=e("mjx-assistive-mml",{unselectable:"on",display:"block"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[e("msqrt",null,[e("mfrac",null,[e("mi",null,"n"),e("mn",null,"2")])])])],-1),K=t(`<p>但是该方法没有太多理论依据，实际应用只能作为参考。</p><ol start="2"><li>肘方法是目前用的较多的确定最佳簇数的方法。具体方法如下：</li></ol><ul><li>将包含n个对象的对象空间分为m个簇类（m位于[0, n]），计算这m个类簇各自的空间中心点（空间重心）在哪。</li><li>计算m个类簇中每个类簇中每个对象与该类簇重心的距离的和，最后把m个类簇各自的距离和相加得到和函数。</li><li>确定m遍历[0，n]之间的值，当增加一个簇类时距离的变化没有前一个分类距</li></ul><p>如下图所示，m从1次、2次逐渐增加，整个曲线的斜率迅速下降，下降过程会出现拐点，使得曲线变得平滑。图中当m取为3或4的时候，都可以被认为是最佳类簇数。由于聚类是一种无监督学习的方法，该方法很多时候拐点较难确定，适当选择就好。</p><figure><img src="https://img-blog.csdn.net/20180418102623255" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>上图的python代码如下所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist
 
#15个点
x1 = np.array([1, 2, 3, 2, 1, 5, 6, 5, 5, 6, 7, 8, 9, 7, 9])
x2 = np.array([1, 3, 2, 2, 2, 8, 6, 7, 6, 7, 1, 2, 1, 1, 3])
X = np.array(list(zip(x1, x2))).reshape(len(x1), 2)
 
#类簇的数量1到9
clusters = range(1, 10) 
#距离函数
distances_sum = []
 
for k in clusters:
    kmeans_model = KMeans(n_clusters = k).fit(X)
    print(&#39;类簇中心的坐标点: &#39;, kmeans_model.cluster_centers_ ) #类簇中心大小为(k, 2)
    #计算各对象离各类簇中心的欧氏距离，生成距离表，大小为(15， k)
    distances_point = cdist(X, kmeans_model.cluster_centers_, &#39;euclidean&#39;)
    #提取每个对象到其类簇中心的距离（该距离最短，所以用min函数），并相加。
    distances_cluster = sum(np.min(distances_point,axis=1))
    #依次存入range(1, 12)的距离结果
    distances_sum.append(distances_cluster)
 
 
plt.plot(clusters, distances_sum, &#39;bx-&#39;)
plt.xlabel(&#39;k&#39;)
plt.ylabel(&#39;distances&#39;)
plt.show()
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,7),A={href:"https://blog.csdn.net/kancy110/article/details/75675574",target:"_blank",rel:"noopener noreferrer"},B=e("p",null,[e("strong",null,"聚类质量测定")],-1),N=e("p",null,"目前测定聚类质量的方法很多，常用的是使用轮廓系数进行。轮廓函数定义如下：",-1),S={class:"MathJax",jax:"SVG",display:"true",style:{position:"relative"}},X={style:{"vertical-align":"-2.172ex"},xmlns:"http://www.w3.org/2000/svg",width:"22.555ex",height:"5.475ex",role:"img",focusable:"false",viewBox:"0 -1460 9969.2 2420","aria-hidden":"true"},z=t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(469,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(858,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mo" transform="translate(1343,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2009.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(3065.6,0)"><g data-mml-node="mrow" transform="translate(1098.6,710)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(429,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(818,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mo" transform="translate(1303,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(1914.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(2914.4,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mo" transform="translate(3443.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(3832.4,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mo" transform="translate(4317.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(878,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1407,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1979,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mi" transform="translate(2257,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mo" transform="translate(2786,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(3175,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mo" transform="translate(3660,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4049,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(4493.7,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(4922.7,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5311.7,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mo" transform="translate(5796.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(6185.7,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g><rect width="6663.7" height="60" x="120" y="220"></rect></g></g></g>',1),j=[z],E=e("mjx-assistive-mml",{unselectable:"on",display:"block"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[e("mi",null,"s"),e("mo",{stretchy:"false"},"("),e("mi",null,"v"),e("mo",{stretchy:"false"},")"),e("mo",null,"="),e("mfrac",null,[e("mrow",null,[e("mi",null,"b"),e("mo",{stretchy:"false"},"("),e("mi",null,"v"),e("mo",{stretchy:"false"},")"),e("mo",null,"−"),e("mi",null,"a"),e("mo",{stretchy:"false"},"("),e("mi",null,"v"),e("mo",{stretchy:"false"},")")]),e("mrow",null,[e("mi",null,"m"),e("mi",null,"a"),e("mi",null,"x"),e("mo",{stretchy:"false"},"["),e("mi",null,"a"),e("mo",{stretchy:"false"},"("),e("mi",null,"v"),e("mo",{stretchy:"false"},")"),e("mo",null,","),e("mi",null,"b"),e("mo",{stretchy:"false"},"("),e("mi",null,"v"),e("mo",{stretchy:"false"},")"),e("mo",{stretchy:"false"},"]")])])])],-1),q=t(`<p>上述公式对于某对象v来说，a(v)为v到本类簇中其他各点距离的平均值，b(v)为v到其他类簇的最小平均值（从其他各类簇中取一个离v最近的对象，计算距离）。一般s(v)在-1到1之间。当s(v)接近1，表明v的类簇非常紧凑，s(v)接近-1，表明聚类效果不好。s(v)越接近1越好，但是要考虑计算成本。</p><p>sklearn具体实例如下</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn import metrics
 
#15个点
x1 = np.array([1, 2, 3, 2, 1, 5, 6, 5, 5, 6, 7, 8, 9, 7, 9])
x2 = np.array([1, 3, 2, 2, 2, 8, 6, 7, 6, 7, 1, 2, 1, 1, 3])
X = np.array(list(zip(x1, x2))).reshape(len(x1), 2)
 
plt.figure()
plt.subplot(2,2,1) #将图像分为2行2列，现在是第一个子图进行绘图
 
plt.title(&#39;Sample&#39;)
plt.scatter(x1, x2)
 
colors =[&#39;black&#39;, &#39;green&#39;, &#39;red&#39;, &#39;yellow&#39;, &#39;blue&#39;, &#39;gray&#39;, &#39;purple&#39;]
markers =[&#39;o&#39;, &#39;s&#39;,&#39;D&#39;, &#39;v&#39;, &#39;p&#39;, &#39;+&#39;, &#39;*&#39; ]
clusters=[3, 4, 7] #类簇数
suplot_counter =1 #画板位置
for k in clusters:
    suplot_counter += 1
    plt.subplot(2, 2, suplot_counter)
    kmeans_model = KMeans(n_clusters=k).fit(X)
    for i, l in enumerate(kmeans_model.labels_):
        plt.plot(x1[i], x2[i], color=colors[l],marker=markers[l],ls=&#39;None&#39;)  
        score = metrics.silhouette_score(X, kmeans_model.labels_, metric=&#39;euclidean&#39;)
        plt.title(&#39;k=%s, s(v)=%.03f&#39; %(k, score))
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="https://img-blog.csdn.net/20180418112801159" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>由上图可以知道当k=3轮廓稀疏最大，k=4其次。代码中metrics.silhouette_score为轮廓评价函数，具体见官方文档：</p>`,5),F={href:"http://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html",target:"_blank",rel:"noopener noreferrer"};function G(I,J){const n=d("ExternalLinkIcon");return s(),i("div",null,[Q,e("p",null,[a("然后将15个点分为3个类簇，并用黑色，绿色，红色标记各个类簇中的点。对于sklearn中用KMeans函数进行聚类，其他用默认参数便可获得较好分类效果。KMeans其他参数改动可参考官网文档："),e("a",m,[a("sklearn.cluster.KMeans"),l(n)])]),o,e("p",null,[a("其中linkage为策略选择参数，函数其他参数改动可参考官网文档："),e("a",c,[a("sklearn.cluster.AgglomerativeClustering"),l(n)]),a("。具体例子见"),e("a",u,[a("sklearn Hierarchical Clustering"),l(n)]),a("。")]),p,v,h,e("p",null,[a("通常在这种情况，K-Means算法往往聚类效果较差。因此通过密度聚类能够很好的解决这种情况。具体算法见"),e("a",g,[a("用scikit-learn学习DBSCAN聚类"),l(n)])]),b,_,f,e("p",null,[a("min_sample是指类簇最小应该有多少个点。如果小于该数字，则会将对象总数小于该数字的类簇视为噪声点，在结果中直接丢弃。函数其他参数改动可参考官网文档："),e("a",x,[a("sklearn.cluster.DBSCAN"),l(n)]),a("。")]),k,H,M,y,L,e("mjx-container",w,[(s(),i("svg",Z,V)),C]),K,e("p",null,[a("其中cdist函数为距离计算函数，上述代码用的是欧氏距离。具体函数使用见："),e("a",A,[a("scipy.spatial.distance.cdist"),l(n)])]),B,N,e("mjx-container",S,[(s(),i("svg",X,j)),E]),q,e("p",null,[e("a",F,[a("sklearn.metrics.silhouette_score"),l(n)])])])}const P=r(T,[["render",G],["__file","2018-04-17-_机器学习_ sklearn聚类.html.vue"]]);export{P as default};

import{_ as a,c as n,a as o,o as i}from"./app-CJwJJlha.js";const t={};function s(r,e){return i(),n("div",null,e[0]||(e[0]=[o('<h1 id="论文总结-深度学习在农业领域应用论文笔记7" tabindex="-1"><a class="header-anchor" href="#论文总结-深度学习在农业领域应用论文笔记7"><span>[论文总结] 深度学习在农业领域应用论文笔记7</span></a></h1><h2 id="_1-applications-of-deep-learning-approaches-in-horticultural-research-a-review-2020-horticulture-research" tabindex="-1"><a class="header-anchor" href="#_1-applications-of-deep-learning-approaches-in-horticultural-research-a-review-2020-horticulture-research"><span>1. Applications of deep-learning approaches in horticultural research: a review，2020，Horticulture Research</span></a></h2><p><strong>总结</strong>：综述论文，写的一般，但里面提到了很多数据集，需要时候可以参考。</p><h2 id="_2-improved-kiwifruit-detection-using-pre-trained-vgg16-with-rgb-and-nir-information-fusion-ieee-access-2020" tabindex="-1"><a class="header-anchor" href="#_2-improved-kiwifruit-detection-using-pre-trained-vgg16-with-rgb-and-nir-information-fusion-ieee-access-2020"><span>2. Improved Kiwifruit Detection Using Pre-Trained VGG16 With RGB and NIR Information Fusion，IEEE Access,2020</span></a></h2><p>将RGB-D（红绿蓝深）传感器与深沉的聚变神经网络（CNN）融合成对齐的RGB和NIR图像，用于水果检测。它旨在建立一个更准确、更快、更可靠的水果检测系统，该系统是水果产量估算和自动收获的重要元素。最近在深度神经网络方面的工作导致开发出一种称为&quot;更快区域&quot;CNN（更快R-CNN）的最先进的物体探测器。通过传输学习采用了一种常见的更快的 R-CNN 网络 VGG16，用于使用从两种模式获得的图像进行奇异果检测：RGB（红色、绿色、蓝色）和近红外 （NIR） 图像。Kinect v2 用于对奇异果树冠的 NIR 和 RGB 图像进行底部查看。NIR （1 通道） 和 RGB 图像 （3 通道） 对齐并并排列成 6 通道图像。VGG16 的输入层经过修改以接收 6 通道图像。使用两种不同的聚变方法提取特征：图像融合（输入层上的 RGB 和 NIR 图像的融合）和功能融合（分别输入 RGB 和 NIR 图像的两个 VGG16 网络的特征图融合）。改进后的网络使用背传和随机梯度下降技术进行端到端培训，并与仅具有 RGB 和 NIR 图像输入的原始 VGG16 网络进行比较。结果表明，原VGG16与RGB和NIR图像输入的平均精度分别为88.4%和89.2%，采用功能融合法的6通道VGG16达到90.5%，而采用图像融合法的AP最高为90.7%，最快的检测速度为0.134 s/图像。结果表明，拟议的奇异果检测方法显示出更好的水果检测潜力。 <strong>总结</strong>：方法很老了，对比的模型是VGG16.自己拍摄的奇异果数据集，并对数据进行了开源。</p><h2 id="_3-fast-and-accurate-detection-of-banana-fruits-in-complex-background-orchards-ieee-access-2020" tabindex="-1"><a class="header-anchor" href="#_3-fast-and-accurate-detection-of-banana-fruits-in-complex-background-orchards-ieee-access-2020"><span>3. Fast and Accurate Detection of Banana Fruits in Complex Background Orchards, IEEE Access, 2020</span></a></h2><p>香蕉水果的检测是香蕉种植园智能管理的重要组成部分。为了在复杂的果园环境中快速准确地检测香蕉果实，本文提出了一种基于最新深度学习算法检测香蕉果的方法。利用单眼相机，我们应用YOLOv4神经网络算法提取香蕉果实的深层特征，实现不同香蕉大小的准确检测。检测算法检测率达到99.29%，平均执行时间为0.171s，最短执行时间为0.135s，AP为0.9995。此外，还与YOLOv3算法和机器学习算法讨论了检测结果。与机器学习算法相比，深度学习算法在检测精度和检测时间上都优于机器学习算法。YOLOV4 的检测置信度和检测率高于 YOLOV3。结果表明，该方法可在不同的照明和封闭条件下，实现香蕉种植园不同品种、不同成熟度的快速检测，为香蕉采摘、成熟度和产量估算提供信息。 <strong>总结</strong>：1164 张图片自己拍摄的香蕉图像+1分，YOLOV4+2分=3分</p><h2 id="_4-identification-of-growing-points-of-cotton-main-stem-based-on-convolutional-neural-network-ieee-access-2020" tabindex="-1"><a class="header-anchor" href="#_4-identification-of-growing-points-of-cotton-main-stem-based-on-convolutional-neural-network-ieee-access-2020"><span>4. Identification of Growing Points of Cotton Main Stem Based on Convolutional Neural Network， IEEE Access, 2020</span></a></h2><p>确定棉花主茎的生长点是实现智能化、精确化机顶和化学浇头的关键。采用传统的目标检测模型来识别增长点存在精度低、识别速度慢、模型参数多、存储成本大、计算工作量大等一系列缺点。基于YOV3的优缺点，提出了一种经过修改的YOV3轻量级模型，用于识别棉花主茎的生长点，通过增加密集连接模块和修改密集模块内的非线性转换，实现了低级语义特征和高等级语义特征的多重集成。该模型利用深度可分离卷积，显著减少了模型参数的数量，并通过应用分层多尺度方法提高了多尺度特征的学习能力。基于自备数据集，我们的模型的准确率达到 90.93%，比原始 YOLOv3 模型的精度高 1.64%，而训练参数的数量显著减少了 48.90%。与其他不同照明条件下和实际复杂环境下的目标检测模型相比，本文提出的改进后的YOLOv3模型在识别棉花主茎生长点方面表现出更好的坚固性、更高的精度和更高的速度。</p><p>总结： 改进YOLOV3+1分，</p><h2 id="_5-malaria-parasite-detection-in-thick-blood-smear-microscopic-images-using-modified-yolov3-and-yolov4-models-bmc-bioinformatics-2021" tabindex="-1"><a class="header-anchor" href="#_5-malaria-parasite-detection-in-thick-blood-smear-microscopic-images-using-modified-yolov3-and-yolov4-models-bmc-bioinformatics-2021"><span>5. Malaria parasite detection in thick blood smear microscopic images using modified YOLOV3 and YOLOV4 models， BMC Bioinformatics ，2021</span></a></h2><p><strong>总结</strong>：改进YOLOV3和YOLOV4模型，对公开可用的疟疾数据集上进行了评估。改论文方法一般，没有很多的创新性以及使用新的方法。</p><h2 id="_6-early-recognition-of-tomato-gray-leaf-spot-disease-based-on-mobilenetv2-yolov3-model-plant-methods-2020" tabindex="-1"><a class="header-anchor" href="#_6-early-recognition-of-tomato-gray-leaf-spot-disease-based-on-mobilenetv2-yolov3-model-plant-methods-2020"><span>6. Early recognition of tomato gray leaf spot disease based on MobileNetv2-YOLOv3 model, plant methods, 2020</span></a></h2><p>本研究提出了基于MobilleNetv2-YOLOv3模型的番茄叶斑的早期识别方法，以达到番茄灰叶斑点的准确性和实时检测之间的良好平衡。该方法通过引入GIoU界框回归损益功能，提高了番茄灰叶点识别回归盒的精度。建议采用移动网络2-YOLOv3轻量级网络模式，以移动网络2为该模型的骨干网络，以方便迁移到移动终端。采用混合训练与转学相结合的预训方法，提高模式的综合能力。对在四种不同条件下拍摄的图像进行统计分析。模型的识别效果由 F1 分数和 AP 值进行评估，并将实验与快速 RCNN 和 SSD 模型进行比较。实验结果表明，拟建模型的识别效果显著提高。在没有叶掩蔽的充足光线下拍摄的图像测试数据集中，F1得分和AP值分别为94.13%和92.53%，IOU平均值为89.92%。在所有测试中，F1 得分和 AP 值分别为 93.24% 和 91.32%，IOU 平均值为 86.98%。GPU上的物体检测速度可达246帧/s，单张416×416图片的外推速度为16.9ms，CPU的探测速度可达22帧/s，外推速度为80.9ms，模型占用的内存为28MB。</p><p><strong>总结</strong>：该研究收集了2166份原始图像，通过网络爬行器获取了 219 张番茄灰叶点图像，数据集中的图像总数为 2385 张。方法和论文研究的主题都缺乏创新性。</p><h2 id="_7-tomato-anomalies-detection-in-greenhouse-scenarios-based-on-yolo-dense-plant-methods-2021" tabindex="-1"><a class="header-anchor" href="#_7-tomato-anomalies-detection-in-greenhouse-scenarios-based-on-yolo-dense-plant-methods-2021"><span>7. Tomato Anomalies Detection in Greenhouse Scenarios Based on YOLO-Dense， plant methods, 2021</span></a></h2><p>温室栽培可以提高作物产量和质量，不仅解决了人们的日常需要，而且给农业职工带来了可观的收益。种植最广泛的温室作物之一是番茄，主要是因为它具有很高的营养价值和良好的口感。然而，番茄作物存在一些异常现象，对它的温室种植构成威胁。在复杂的自然环境中检测番茄异常是植物科学领域的一个重要研究方向。由于番茄体积小，背景复杂，自动识别番茄异常仍然是一项具有挑战性的任务。为了解决复杂自然环境中番茄异常检测问题，在一级深度检测YOLO框架的基础上，提出了一种新的YOLO-致密。通过在网络架构中添加密集连接模块，可以有效提高拟建模型的网络推理速度。通过使用 K-指算法对锚箱进行聚类，获得了 9 种不同尺寸的锚箱，其中有潜在的对象需要识别。采用了多尺度训练战略，以提高不同尺度物体的识别精度。实验结果表明，YOLO-密集网络单图像的mAP和检测时间分别为96.41%和20.28ms。与 SSD、更快的 R-CNN 和原始的 YOLOv3 网络相比，YOLO-密集模型在复杂的自然环境中实现了番茄异常检测的最佳性能。</p><p>总结：改进YOLOV3，采用自己拍摄了一部分数据和公共数据集（没有说明具体数量）。创新性和方法都不强。</p><h2 id="_8-deep-convolutional-neural-networks-for-image-based-convolvulus-sepium-detection-in-sugar-beet-fields-plant-methods-2020" tabindex="-1"><a class="header-anchor" href="#_8-deep-convolutional-neural-networks-for-image-based-convolvulus-sepium-detection-in-sugar-beet-fields-plant-methods-2020"><span>8. Deep convolutional neural networks for image-based Convolvulus sepium detection in sugar beet fields， plant methods, 2020</span></a></h2><p>652 张图像被手动标记为边界框。图像很少，方法也不新。</p><h2 id="_9-plant-diseases-and-pests-detection-based-on-deep-learning-a-review-plant-methods-2020" tabindex="-1"><a class="header-anchor" href="#_9-plant-diseases-and-pests-detection-based-on-deep-learning-a-review-plant-methods-2020"><span>9. Plant diseases and pests detection based on deep learning: a review， plant methods, 2020</span></a></h2><p>植物病虫害是决定植物产量和质量的重要因素。植物病虫害鉴定可以通过数字图像处理进行。近年来，深度学习在数字图像处理领域取得了突破性进展，远远优于传统方法。如何运用深造技术研究植物病虫害鉴定，已成为科研人员十分关注的研究课题。本次审查对植物病虫害的检测问题进行了界定，提出了与传统植物病虫害的比较检测方法。根据网络结构的差异，从分类网络、检测网络和分割网络三个方面对近年来植物病虫害检测的研究进行了概述，总结了每种方法的优缺点。引入了常见的数据集，并比较了现有研究的性能。在此基础上，本研究在深入学习的基础上，探讨了植物病虫害检测实际应用中可能面临的挑战。此外，还提出了应对挑战的可能解决方案和研究想法，并提出了若干建议。最后，本研究在深入学习的基础上，对植物病虫害检测的未来趋势进行了分析和展望。</p><p>总结：没有列出公共数据，可利用价值不大。</p><h2 id="_10-yolo-based-deep-learning-framework-for-olive-fruit-fly-detection-and-counting-ieee-access-2021" tabindex="-1"><a class="header-anchor" href="#_10-yolo-based-deep-learning-framework-for-olive-fruit-fly-detection-and-counting-ieee-access-2021"><span>10. YOLO-Based Deep Learning Framework for Olive Fruit Fly Detection and Counting, IEEE Access, 2021</span></a></h2><p>橄榄果蝇可以损害高达100%的收获水果，并可能导致高达80%的橄榄油价值降低。因此，必须尽早发现橄榄园的存在，尽早采取相应的化学或生物对策。充满吸引人信息素的陷阱通常部署在果园内以吸引和捕捉苍蝇。传统上，捕获的苍蝇是手动计数的，容易出错。最近，这些陷阱被用在相机和通讯设备上，将捕获的苍蝇的照片发送给专家进行分析，分析这些照片也容易出错，效率低下。因此，机器和深度学习被利用来开发全自动和精确的检测，其中不包括人。由于检测到的对象体积小、拍摄照片的光线条件不同以及缺乏足够的数据来训练学习模型，这种学习问题是具有挑战性的。本文介绍了一个深入的学习框架，用于检测和计数橄榄果蝇的数量，利用数据增强来增加数据集大小，在训练中包括负样本以提高检测精度，并将图像正常化为陷阱背景的颜色，即黄色，以统一照明条件。拟议框架的结果表明，精度为0.84，召回为0.97，F1得分为0.9，平均精度（mAP）为96.68%，明显优于现有的害虫检测系统。</p><p><strong>总结</strong>： 用的是改进的YoloV4网络，用的是公共数据集，然后自己标注。写的一般。</p><h2 id="_11-real-time-visual-localization-of-the-picking-points-for-a-ridge-planting-strawberry-harvesting-robot-ieee-access-2021" tabindex="-1"><a class="header-anchor" href="#_11-real-time-visual-localization-of-the-picking-points-for-a-ridge-planting-strawberry-harvesting-robot-ieee-access-2021"><span>11. Real-Time Visual Localization of the Picking Points for a Ridge-Planting Strawberry Harvesting Robot， IEEE Access, 2021</span></a></h2><p>草莓收获机器人使用的主要技术威慑因素是收成率低，需要提高本地化算法的准确性和实时性能，以检测草莓茎上的采摘点。水果目标（水果轴方向）的姿势估计可以提高本地化算法的准确性。这项研究提出了一种新型的收获机器人的山脊种植草莓，以及一个水果姿势估计器称为旋转YORA（R-YOLO），这显著提高了采摘点的本地化精度。首先，利用轻量级网络Mobilnet-V1取代汇流神经网络作为功能提取的骨干网络。简化的网络结构大大提高了运行速度。第二，旋转角度参数α用于标记培训集和设置锚：使用旋转锚的物流回归预测目标水果边界箱的旋转。一组100张草莓图像的测试结果显示，拟建模型的平均识别率为94.43%，召回率为93.46%。在机器人的嵌入式控制器上每秒处理 18 帧 （FPS），展示了良好的实时性能。与水果收获机器人采用的其他几种目标检测方法相比，该模型在采摘点的实时检测和定位精度方面表现出较好的性能。现场试验结果表明，改良情况下收获成功率达到84.35%。这项研究的结果为改进收获机器人嵌入式控制器的目标检测提供了技术支持。</p><p><strong>总结</strong>：提出了新方法，有硬件，有大田数据，但测试集只有100张图片。用的对比方法也比较老了。</p><h2 id="_12-small-object-detection-based-on-yolo-and-dense-block-via-image-super-resolution-2020" tabindex="-1"><a class="header-anchor" href="#_12-small-object-detection-based-on-yolo-and-dense-block-via-image-super-resolution-2020"><span>12. Small-Object Detection Based on YOLO and Dense Block via Image Super-Resolution，2020</span></a></h2><p>小对象检测是计算机视觉任务中一个基本且具有挑战性的问题。广泛应用于行人检测、交通标志检测等领域。本文提出了基于图像超分辨率的深度学习小对象检测方法，以提高小对象检测的速度和准确性。首先，我们在输入端添加功能纹理传输 （FTT） 模块，以提高此端的图像分辨率，并消除图像中的噪声。然后，在骨干网络中，使用 Darknet53 框架，我们使用密集块替换残块，以减少网络结构参数的数量，以避免不必要的计算。然后，为了充分利用图像中小目标的特征，颈部使用 SPPnet 和 PANnet 的组合来完成这部分多尺度功能融合工作。最后，通过在YOLOv4损益函数部分中添加前景和背景平衡损失函数，解决了图像背景和前景不平衡的问题。使用我们自建数据集进行的实验结果表明，与目前可用的小目标检测方法相比，该方法具有更高的精度和速度。</p><p><strong>总结</strong>：进了一系列操作后，速度比YOLOV4快了一点，个人感觉这个论文大概3-4分。</p><h2 id="_13-identification-of-fruit-tree-pests-with-deep-learning-on-embedded-drone-to-achieve-accurate-pesticide-spraying-2020" tabindex="-1"><a class="header-anchor" href="#_13-identification-of-fruit-tree-pests-with-deep-learning-on-embedded-drone-to-achieve-accurate-pesticide-spraying-2020"><span>13. Identification of Fruit Tree Pests With Deep Learning on Embedded Drone to Achieve Accurate Pesticide Spraying，2020</span></a></h2><p>苔丝拉托玛瘤（德鲁里）于 2009 年首次入侵台湾。每年， T . 瘤都会对龙根作物造成严重破坏。本研究应用了边缘智能的新应用，建立了智能害虫识别系统来管理这一害虫问题。我们使用检测无人机拍摄害虫，并采用了一个内嵌系统 NVIDIA Jetson TX2 构建的 Tiny - YOLOv3 神经网络模型，在果园中识别 T . 瘤，实时确定害虫的位置。然后，害虫的位置用于规划农业无人机的最佳农药喷洒路线。除了为喷洒无人机规划优化喷洒农药外，TX2 嵌入式平台还通过计算机或移动设备将害虫的位置和生成传输到云中，以记录和分析龙骨的生长情况。本研究使农民能够了解害虫分布情况，并实时采取适当的预防措施。农业无人机仅在需要时喷洒杀虫剂，从而减少农药的使用，减少对环境的破坏，提高作物产量。</p><p><strong>总结</strong>：有硬件可以加分。</p><h2 id="_14-early-real-time-detection-algorithm-of-tomato-diseases-and-pests-in-the-natural-environment-2021" tabindex="-1"><a class="header-anchor" href="#_14-early-real-time-detection-algorithm-of-tomato-diseases-and-pests-in-the-natural-environment-2021"><span>14. Early real-time detection algorithm of tomato diseases and pests in the natural environment,2021</span></a></h2><p>针对自然环境中番茄病虫害早期图像物体的复杂背景，提出了基于YOROV3的改进对象检测算法，以便对番茄病虫害进行早期实时检测。首先，针对自然条件下番茄病虫害图像的复杂背景，利用扩张的卷积层取代骨干网中的卷积层，保持高分辨率和受体场，提高小物体检测能力。其次，在检测网络中，根据多个网格预测的候选箱交叉比（IOU）和线性衰减置信任度计，保留番茄病虫害的模糊对象，解决番茄病虫害相互遮挡物的检测问题。第三，为了减少模型体积和减少模型参数，网络采用了聚化因子化的理念，是轻量级的。最后，通过引入平衡因子，优化了损失功能中的小物体重量。对六种不同背景条件下九种常见番茄病虫害的检测结果进行了统计分析。建议的方法F1值为94.77%，AP值为91.81%，误检率仅为2.1%，检测时间仅为55.5%，检测结果表明，该方法适用于利用农业物联网采集的大型视频图像对番茄病虫害进行早期检测。</p><p><strong>总结</strong>：缺乏创新性</p><h2 id="_15-a-novel-deep-learning-method-for-detection-and-classification-of-plant-diseases-complex-intelligent-systems-2021-if-4-927" tabindex="-1"><a class="header-anchor" href="#_15-a-novel-deep-learning-method-for-detection-and-classification-of-plant-diseases-complex-intelligent-systems-2021-if-4-927"><span>15. A novel deep learning method for detection and classification of plant diseases, Complex &amp; Intelligent Systems, 2021,IF=4.927</span></a></h2><p>农业生产率在一个国家的经济发展中起着举足轻重的作用。然而，植物病是食品生产和质量的最严重障碍。早期发现植物疾病对全球健康和福祉至关重要。传统的诊断过程包括病理学家通过现场访问对单个植物进行视觉评估。然而，由于准确性低和人力资源的可及性小，作物疾病的人工检查受到限制。为了解决这些问题，需要设计能够有效检测和分类许多植物疾病的自动化方法。由于图像背景和前景中低强度信息的发生、健康和患病植物区域的巨大颜色相似性、样品中噪音的发生以及植物叶的位置、色度、结构和大小的变化，对植物病害的精确识别和分类是一项繁琐的工作。为了解决上述问题，我们引入了一个以DemdemNet-77为基本网络的定制中心网框架，从而引入了一个强大的植物病害分类系统。呈现的方法遵循三个步骤。在第一步中，开发注释以获取感兴趣的区域。其次，引入了改进的 CenterNet，其中建议采用登登网-77进行深键点提取。最后，一级检测中心网用于检测和分类多种植物疾病。为了进行性能分析，我们使用了植物植物植物群卡格尔数据库，该数据库是植物疾病的标准数据集，在强度变化、颜色变化以及叶子形状和大小上的差异方面面临挑战。定性和定量分析都证实，与其他最新方法相比，所呈现的方法在识别和分类植物疾病方面更熟练、更可靠。</p><p><strong>总结</strong>：该论文提出了一个定制的模型，多重LOSS，数据来源于公开数据集。</p><h2 id="_16-a-remote-sensing-and-airborne-edge-computing-based-detection-system-for-pine-wilt-disease-ieee-access-2021" tabindex="-1"><a class="header-anchor" href="#_16-a-remote-sensing-and-airborne-edge-computing-based-detection-system-for-pine-wilt-disease-ieee-access-2021"><span>16. A Remote Sensing and Airborne Edge-Computing Based Detection System for Pine Wilt Disease， IEEE access , 2021</span></a></h2><p>松枯萎病（PWD）是针叶林最危险和最具破坏性的疾病之一。迅速蔓延的趋势和强烈的破坏直接威胁着森林的安全。复杂的传播模式和艰苦的诊断过程要求有效检测感染区域。本文采用图像传感器设计为PWD检测的机载边缘计算和轻量级深度学习系统。无人机（UAV）首先用于实现森林的大规模覆盖，从而大大减少了辛勤劳动。除了受感染的树木外，无人机还获取了大量不相关的图像，这将加重过程和传输的负担。然后，建议采用轻量级改进的 YOLOv4-Tiny 方法（命名为 YOLOv4-Tiny-3Layers），通过利用边缘计算的计算能力来过滤这些不感兴趣的图像，从而实现快速粗粒度检测，并具有较低的缺失率。最后，所有剩余的图像被传输到地面工作站进行最后的细粒数检测。实验结果表明，与其他方法相比，该系统可实施性能优越的快速检测，有助于快速检测受感染的松树。</p><p>总结：idea不错，用了YOLOv4-Tiny 方法，无人机数据，机载边缘计算检测系统，细粒度检测，大概7-8分。</p><h2 id="_17-a-peduncle-detection-method-of-tomato-for-autonomous-harvesting-complex-intelligent-systems-2021-if-4-927" tabindex="-1"><a class="header-anchor" href="#_17-a-peduncle-detection-method-of-tomato-for-autonomous-harvesting-complex-intelligent-systems-2021-if-4-927"><span>17. A peduncle detection method of tomato for autonomous harvesting， Complex &amp; Intelligent Systems, 2021,IF=4.927</span></a></h2><p>要使一串西红柿在温室中自动收获，最终效应者需要达到确切的切口，并自适应地调整番茄的姿势。本文提出了一种方法，用于切入点定位和姿势估计。使用 YOLOv4-Tiny 探测器实时捕获的图像，精度为 92.7%，检测速度为每帧 0.0091 秒，然后使用 MAP 为 73.1 和每帧 0.109 秒的 YOLACT + 网络来分割特写距离。分段的 peduncle 面罩使用最少的方块安装到曲线上，并找到曲线上的三个关键点。最后，建立了几何模型来估计西红柿的姿势，在 30 组测试中，平均误差为 4.98°，音高角度为 4.75°。</p><p><strong>总结</strong>：有一定自己想法，用的YOLOV4，大概4分。</p><h2 id="_18-fruit-maturity-and-location-identification-of-beef-tomato-using-r-cnn-and-binocular-imaging-technology-journal-of-food-measurement-and-characterization-2021-if-2-43" tabindex="-1"><a class="header-anchor" href="#_18-fruit-maturity-and-location-identification-of-beef-tomato-using-r-cnn-and-binocular-imaging-technology-journal-of-food-measurement-and-characterization-2021-if-2-43"><span>18. Fruit maturity and location identification of beef tomato using R-CNN and binocular imaging technology ，Journal of Food Measurement and Characterization，2021, IF=2.43</span></a></h2><p>这项研究的目的是确定西红柿在温室中的成熟度和位置。本研究包括三个部分：建立图像捕获和物体检测模型、成熟水果的位置识别和成熟水果大小预测。第一部分，将在温室中进行不同时间的图像捕捉和物体检测，以识别成熟的水果。第二部分，将双目视觉计算的成熟水果的相对3D位置与实际测量位置进行比较。第三部分，将物体检测的界框大小与成熟水果的实际尺寸进行比较，并计算相关性，以便预先调整抓手的宽度，以便将来进行采摘操作。本研究成熟成果的精确度和回忆度均在95%以上。3D 位置的平均误差为 0.5 厘米。水果的实际大小和边界框大小的 R 方形超过 0.9。</p><p><strong>总结</strong>：缺乏创新性，数据集太小</p><h2 id="_19-yield-estimation-and-visualization-solution-for-precision-agriculture-sensors-2021" tabindex="-1"><a class="header-anchor" href="#_19-yield-estimation-and-visualization-solution-for-precision-agriculture-sensors-2021"><span>19. Yield Estimation and Visualization Solution for Precision Agriculture，sensors, 2021</span></a></h2><p>通过使用对象检测和跟踪来计算视频中的水果。我们使用和训练你只看一次模型 （YOLO） 在苹果， 橙子和南瓜的视频剪辑.通过异议检测获得的边界框用作我们选定的跟踪模型 DeepSORT 的输入。DeepSORT 的原始版本无法与水果数据一起使用，因为外观特征提取器仅适用于人。我们实施 ResNet 作为深度 SORT 的新功能提取器，该提取器重量轻、准确且通用于不同水果上。我们的产量估计模块显示苹果树真实镜头的准确度在 91%到 95% 之间。我们的修改成功地用于计数橙子和南瓜，准确率为79%和93.9%，无需培训。我们的框架还包括产量的可视化。这是通过纳入地理空间数据来完成的。我们还提出了一个机制，以注释一组框架与各自的GPS坐标。在计数过程中，记录帧集内的计数和匹配的 GPS 坐标，然后在地图上可视化。我们利用这些信息提出最佳的容器放置解决方案。我们建议的解决方案包括根据一系列限制因素，最大限度地减少收获前在田间放置的容器数量。这是农民在收获前制定高效物流计划（如劳动力、设备和收集路径）的决策支持系统。</p><p><strong>总结</strong>：用的YOLOV3</p><h2 id="_20-deep-learning-based-automated-palm-tree-counting-and-geolocation-in-large-farms-from-aerial-geotagged-images-sensors-2021" tabindex="-1"><a class="header-anchor" href="#_20-deep-learning-based-automated-palm-tree-counting-and-geolocation-in-large-farms-from-aerial-geotagged-images-sensors-2021"><span>20. Deep-Learning-Based Automated Palm Tree Counting and Geolocation in Large Farms from Aerial Geotagged Images, sensors, 2021</span></a></h2><p>在本文中，我们提出了一个原始的深度学习框架，用于使用卷积神经网络从航空图像中自动计数和定位棕榈树。为此，我们使用两架DJI无人机从沙特阿拉伯的两个不同地区收集了航空图像，并构建了大约11，000棵棕榈树的数据集。然后，我们应用了几个最近的卷积神经网络模型（更快的R-CNN，YOLOv3，YOLOv4，和高效Det）来检测手掌和其他树木，并进行了一个完整的比较评估，在平均精度和推理速度方面。YOLOv4 和高效Det-D5在精度和速度之间产生了最佳的权衡（高达 99% 的平均精度和 7.4 FPS）。此外，我们使用航空图像的地理标记元数据，使用摄影测量概念和距离校正自动检测到的棕榈树的地理位置。这种地理定位技术在两种不同类型的无人机上进行了测试（DJI Mavic Pro 和幻影 4 pro），并被评估为提供平均地理定位精度达到 1.6 米。此 GPS 标记使我们能够唯一识别棕榈树，并从一系列无人机图像中计算它们的数量，同时正确处理图像重叠的问题。此外，深度学习对象检测和地理定位之间的这种创新组合可以推广到无人机图像中的任何其他对象。</p><p>总结：有无人机数据，用的YOLOV4</p><h2 id="_21-small-object-recognition-algorithm-of-grain-pests-based-on-ssd-feature-fusion" tabindex="-1"><a class="header-anchor" href="#_21-small-object-recognition-algorithm-of-grain-pests-based-on-ssd-feature-fusion"><span>21. Small Object Recognition Algorithm of Grain Pests Based on SSD Feature Fusion</span></a></h2><p>粮食病虫害的发现对粮食收储具有重要意义。然而，在实践中，因为谷物昆虫的大小太小，无法识别。本文提出了基于自上而下策略的功能融合SSD（单射多盒探测器）算法。首先，自上而下模块用于融合凸4和凸5的输出特性，删除不利于小物体检测的块11。其次，K-指聚类算法用于聚类前边界盒，使其更适合谷物害虫，提高了小对象检测谷物害虫的性能。采用五种方法增强了粮食害虫的自制数据集，增强数据集达到9990张图像。增强型数据集上的实验表明，优化后的模型实现了 mAP（平均精度）96.89%，每个图像的检测速度为 0.040s。与原 SSD 算法实现的 95.45% 的 mAP 相比，建议的模型在检测性能方面有很大提高。与两个阶段的快速 R-CNN（mAP 为 90.53%，速度为每幅图像 0.115s）、YOLOV3、TDFSSD 和 EfficentDet （D2、D1） 相比，优化 SSD 算法的速度和精度具有明显的优势。实验结果表明，所拟的SSD模型对小对象检测谷物害虫有良好的效果，对后续的粮食害虫图像检测具有一定的指导意义。</p><p><strong>总结</strong>：与YOLOV3进行了比较，用的公共数据集。</p><h2 id="_22-deep-learning-based-object-detection-improvement-for-tomato-disease" tabindex="-1"><a class="header-anchor" href="#_22-deep-learning-based-object-detection-improvement-for-tomato-disease"><span>22. Deep Learning-Based Object Detection Improvement for Tomato Disease</span></a></h2><p>为了提高作物病叶和病叶定位识别模型的准确性，本文提出了改进RCNN检测健康番茄叶和四种疾病：粉状霉菌、斑点、叶霉菌和TOMV。首先，我们使用深度残余网络替换 VGG16 进行图像特征提取，以便获得更深的疾病特征。其次，K-意味着聚类算法用于聚类边界框。我们根据聚类结果改进锚定。改进的锚架倾向于数据集的真正边界框。最后，我们用三种不同的功能提取网络进行了k-手段实验。实验结果表明，改进后的作物叶病检测方法比原快RCNN具有2.71%的识别精度和更快的检测速度。</p><p><strong>总结</strong>：缺乏创新性，用的公共数据集。</p>',62)]))}const d=a(t,[["render",s],["__file","2021-10-30-_论文总结_ 深度学习在农业领域应用论文笔记7.html.vue"]]),c=JSON.parse('{"path":"/blog/%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/2021-10-30-_%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93_%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%A8%E5%86%9C%E4%B8%9A%E9%A2%86%E5%9F%9F%E5%BA%94%E7%94%A8%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B07.html","title":"[论文总结] 深度学习在农业领域应用论文笔记7","lang":"zh-CN","frontmatter":{"date":"2021-10-30T11:20:52.000Z","category":["论文总结"],"tag":["论文总结"],"description":"[论文总结] 深度学习在农业领域应用论文笔记7 1. Applications of deep-learning approaches in horticultural research: a review，2020，Horticulture Research 总结：综述论文，写的一般，但里面提到了很多数据集，需要时候可以参考。 2. Improved...","head":[["meta",{"property":"og:url","content":"https://luohenyueji.github.io/blog/%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/2021-10-30-_%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93_%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%A8%E5%86%9C%E4%B8%9A%E9%A2%86%E5%9F%9F%E5%BA%94%E7%94%A8%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B07.html"}],["meta",{"property":"og:site_name","content":"落痕月极的博客"}],["meta",{"property":"og:title","content":"[论文总结] 深度学习在农业领域应用论文笔记7"}],["meta",{"property":"og:description","content":"[论文总结] 深度学习在农业领域应用论文笔记7 1. Applications of deep-learning approaches in horticultural research: a review，2020，Horticulture Research 总结：综述论文，写的一般，但里面提到了很多数据集，需要时候可以参考。 2. Improved..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:tag","content":"论文总结"}],["meta",{"property":"article:published_time","content":"2021-10-30T11:20:52.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"[论文总结] 深度学习在农业领域应用论文笔记7\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2021-10-30T11:20:52.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"落痕月极\\",\\"url\\":\\"/\\"}]}"]]},"headers":[{"level":2,"title":"1. Applications of deep-learning approaches in horticultural research: a review，2020，Horticulture Research","slug":"_1-applications-of-deep-learning-approaches-in-horticultural-research-a-review-2020-horticulture-research","link":"#_1-applications-of-deep-learning-approaches-in-horticultural-research-a-review-2020-horticulture-research","children":[]},{"level":2,"title":"2. Improved Kiwifruit Detection Using Pre-Trained VGG16 With RGB and NIR Information Fusion，IEEE Access,2020","slug":"_2-improved-kiwifruit-detection-using-pre-trained-vgg16-with-rgb-and-nir-information-fusion-ieee-access-2020","link":"#_2-improved-kiwifruit-detection-using-pre-trained-vgg16-with-rgb-and-nir-information-fusion-ieee-access-2020","children":[]},{"level":2,"title":"3. Fast and Accurate Detection of Banana Fruits in Complex Background Orchards, IEEE Access, 2020","slug":"_3-fast-and-accurate-detection-of-banana-fruits-in-complex-background-orchards-ieee-access-2020","link":"#_3-fast-and-accurate-detection-of-banana-fruits-in-complex-background-orchards-ieee-access-2020","children":[]},{"level":2,"title":"4. Identification of Growing Points of Cotton Main Stem Based on Convolutional Neural Network， IEEE Access, 2020","slug":"_4-identification-of-growing-points-of-cotton-main-stem-based-on-convolutional-neural-network-ieee-access-2020","link":"#_4-identification-of-growing-points-of-cotton-main-stem-based-on-convolutional-neural-network-ieee-access-2020","children":[]},{"level":2,"title":"5. Malaria parasite detection in thick blood smear microscopic images using modified YOLOV3 and YOLOV4 models， BMC Bioinformatics ，2021","slug":"_5-malaria-parasite-detection-in-thick-blood-smear-microscopic-images-using-modified-yolov3-and-yolov4-models-bmc-bioinformatics-2021","link":"#_5-malaria-parasite-detection-in-thick-blood-smear-microscopic-images-using-modified-yolov3-and-yolov4-models-bmc-bioinformatics-2021","children":[]},{"level":2,"title":"6. Early recognition of tomato gray leaf spot disease based on MobileNetv2-YOLOv3 model, plant methods,  2020","slug":"_6-early-recognition-of-tomato-gray-leaf-spot-disease-based-on-mobilenetv2-yolov3-model-plant-methods-2020","link":"#_6-early-recognition-of-tomato-gray-leaf-spot-disease-based-on-mobilenetv2-yolov3-model-plant-methods-2020","children":[]},{"level":2,"title":"7. Tomato Anomalies Detection in Greenhouse Scenarios Based on YOLO-Dense， plant methods,  2021","slug":"_7-tomato-anomalies-detection-in-greenhouse-scenarios-based-on-yolo-dense-plant-methods-2021","link":"#_7-tomato-anomalies-detection-in-greenhouse-scenarios-based-on-yolo-dense-plant-methods-2021","children":[]},{"level":2,"title":"8. Deep convolutional neural networks for image-based Convolvulus sepium detection in sugar beet fields， plant methods,  2020","slug":"_8-deep-convolutional-neural-networks-for-image-based-convolvulus-sepium-detection-in-sugar-beet-fields-plant-methods-2020","link":"#_8-deep-convolutional-neural-networks-for-image-based-convolvulus-sepium-detection-in-sugar-beet-fields-plant-methods-2020","children":[]},{"level":2,"title":"9. Plant diseases and pests detection based on deep learning: a review， plant methods,  2020","slug":"_9-plant-diseases-and-pests-detection-based-on-deep-learning-a-review-plant-methods-2020","link":"#_9-plant-diseases-and-pests-detection-based-on-deep-learning-a-review-plant-methods-2020","children":[]},{"level":2,"title":"10. YOLO-Based Deep Learning Framework for Olive Fruit Fly Detection and Counting, IEEE Access, 2021","slug":"_10-yolo-based-deep-learning-framework-for-olive-fruit-fly-detection-and-counting-ieee-access-2021","link":"#_10-yolo-based-deep-learning-framework-for-olive-fruit-fly-detection-and-counting-ieee-access-2021","children":[]},{"level":2,"title":"11. Real-Time Visual Localization of the Picking Points for a Ridge-Planting Strawberry Harvesting Robot， IEEE Access, 2021","slug":"_11-real-time-visual-localization-of-the-picking-points-for-a-ridge-planting-strawberry-harvesting-robot-ieee-access-2021","link":"#_11-real-time-visual-localization-of-the-picking-points-for-a-ridge-planting-strawberry-harvesting-robot-ieee-access-2021","children":[]},{"level":2,"title":"12. Small-Object Detection Based on YOLO and Dense Block via Image Super-Resolution，2020","slug":"_12-small-object-detection-based-on-yolo-and-dense-block-via-image-super-resolution-2020","link":"#_12-small-object-detection-based-on-yolo-and-dense-block-via-image-super-resolution-2020","children":[]},{"level":2,"title":"13. Identification of Fruit Tree Pests With Deep Learning on Embedded Drone to Achieve Accurate Pesticide Spraying，2020","slug":"_13-identification-of-fruit-tree-pests-with-deep-learning-on-embedded-drone-to-achieve-accurate-pesticide-spraying-2020","link":"#_13-identification-of-fruit-tree-pests-with-deep-learning-on-embedded-drone-to-achieve-accurate-pesticide-spraying-2020","children":[]},{"level":2,"title":"14. Early real-time detection algorithm of tomato diseases and pests in the natural environment,2021","slug":"_14-early-real-time-detection-algorithm-of-tomato-diseases-and-pests-in-the-natural-environment-2021","link":"#_14-early-real-time-detection-algorithm-of-tomato-diseases-and-pests-in-the-natural-environment-2021","children":[]},{"level":2,"title":"15. A novel deep learning method for detection and classification of plant diseases, Complex & Intelligent Systems, 2021,IF=4.927","slug":"_15-a-novel-deep-learning-method-for-detection-and-classification-of-plant-diseases-complex-intelligent-systems-2021-if-4-927","link":"#_15-a-novel-deep-learning-method-for-detection-and-classification-of-plant-diseases-complex-intelligent-systems-2021-if-4-927","children":[]},{"level":2,"title":"16. A Remote Sensing and Airborne Edge-Computing Based Detection System for Pine Wilt Disease， IEEE  access , 2021","slug":"_16-a-remote-sensing-and-airborne-edge-computing-based-detection-system-for-pine-wilt-disease-ieee-access-2021","link":"#_16-a-remote-sensing-and-airborne-edge-computing-based-detection-system-for-pine-wilt-disease-ieee-access-2021","children":[]},{"level":2,"title":"17. A peduncle detection method of tomato for autonomous harvesting， Complex & Intelligent Systems, 2021,IF=4.927","slug":"_17-a-peduncle-detection-method-of-tomato-for-autonomous-harvesting-complex-intelligent-systems-2021-if-4-927","link":"#_17-a-peduncle-detection-method-of-tomato-for-autonomous-harvesting-complex-intelligent-systems-2021-if-4-927","children":[]},{"level":2,"title":"18. Fruit maturity and location identification of beef tomato using R-CNN and binocular imaging technology ，Journal of Food Measurement and Characterization，2021, IF=2.43","slug":"_18-fruit-maturity-and-location-identification-of-beef-tomato-using-r-cnn-and-binocular-imaging-technology-journal-of-food-measurement-and-characterization-2021-if-2-43","link":"#_18-fruit-maturity-and-location-identification-of-beef-tomato-using-r-cnn-and-binocular-imaging-technology-journal-of-food-measurement-and-characterization-2021-if-2-43","children":[]},{"level":2,"title":"19. Yield Estimation and Visualization Solution for Precision Agriculture，sensors, 2021","slug":"_19-yield-estimation-and-visualization-solution-for-precision-agriculture-sensors-2021","link":"#_19-yield-estimation-and-visualization-solution-for-precision-agriculture-sensors-2021","children":[]},{"level":2,"title":"20. Deep-Learning-Based Automated Palm Tree Counting and Geolocation in Large Farms from Aerial Geotagged Images, sensors, 2021","slug":"_20-deep-learning-based-automated-palm-tree-counting-and-geolocation-in-large-farms-from-aerial-geotagged-images-sensors-2021","link":"#_20-deep-learning-based-automated-palm-tree-counting-and-geolocation-in-large-farms-from-aerial-geotagged-images-sensors-2021","children":[]},{"level":2,"title":"21. Small Object Recognition Algorithm of Grain Pests Based on SSD Feature Fusion","slug":"_21-small-object-recognition-algorithm-of-grain-pests-based-on-ssd-feature-fusion","link":"#_21-small-object-recognition-algorithm-of-grain-pests-based-on-ssd-feature-fusion","children":[]},{"level":2,"title":"22. Deep Learning-Based Object Detection Improvement for Tomato Disease","slug":"_22-deep-learning-based-object-detection-improvement-for-tomato-disease","link":"#_22-deep-learning-based-object-detection-improvement-for-tomato-disease","children":[]}],"git":{},"readingTime":{"minutes":23.8,"words":7140},"filePathRelative":"blog/论文总结/2021-10-30-[论文总结] 深度学习在农业领域应用论文笔记7.md","localizedDate":"2021年10月30日","excerpt":"\\n<h2>1. Applications of deep-learning approaches in horticultural research: a review，2020，Horticulture Research</h2>\\n<p><strong>总结</strong>：综述论文，写的一般，但里面提到了很多数据集，需要时候可以参考。</p>\\n<h2>2. Improved Kiwifruit Detection Using Pre-Trained VGG16 With RGB and NIR Information Fusion，IEEE Access,2020</h2>\\n<p>将RGB-D（红绿蓝深）传感器与深沉的聚变神经网络（CNN）融合成对齐的RGB和NIR图像，用于水果检测。它旨在建立一个更准确、更快、更可靠的水果检测系统，该系统是水果产量估算和自动收获的重要元素。最近在深度神经网络方面的工作导致开发出一种称为\\"更快区域\\"CNN（更快R-CNN）的最先进的物体探测器。通过传输学习采用了一种常见的更快的 R-CNN 网络 VGG16，用于使用从两种模式获得的图像进行奇异果检测：RGB（红色、绿色、蓝色）和近红外 （NIR） 图像。Kinect v2 用于对奇异果树冠的 NIR 和 RGB 图像进行底部查看。NIR （1 通道） 和 RGB 图像 （3 通道） 对齐并并排列成 6 通道图像。VGG16 的输入层经过修改以接收 6 通道图像。使用两种不同的聚变方法提取特征：图像融合（输入层上的 RGB 和 NIR 图像的融合）和功能融合（分别输入 RGB 和 NIR 图像的两个 VGG16 网络的特征图融合）。改进后的网络使用背传和随机梯度下降技术进行端到端培训，并与仅具有 RGB 和 NIR 图像输入的原始 VGG16 网络进行比较。结果表明，原VGG16与RGB和NIR图像输入的平均精度分别为88.4%和89.2%，采用功能融合法的6通道VGG16达到90.5%，而采用图像融合法的AP最高为90.7%，最快的检测速度为0.134 s/图像。结果表明，拟议的奇异果检测方法显示出更好的水果检测潜力。\\n<strong>总结</strong>：方法很老了，对比的模型是VGG16.自己拍摄的奇异果数据集，并对数据进行了开源。</p>","autoDesc":true}');export{d as comp,c as data};

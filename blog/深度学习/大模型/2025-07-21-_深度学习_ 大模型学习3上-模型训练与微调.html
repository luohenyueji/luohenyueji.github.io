<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.19" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.71" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://luohenyueji.github.io/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/2025-07-21-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03%E4%B8%8A-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83.html"><meta property="og:site_name" content="落痕月极的博客"><meta property="og:title" content="[深度学习] 大模型学习3上-模型训练与微调"><meta property="og:description" content="[深度学习] 大模型学习3上-模型训练与微调 在文章大语言模型基础知识里，模型训练与微调作为大语言模型（Large Language Model，LLM）应用构建的主要方式被简要提及，本系列文章将从技术原理、实施流程及应用场景等维度展开深度解析。相关知识的进一步参考见：LLM训练理论和实战。本文作为系列的上半部分，内容涵盖第1章大语言模型概览和第2章大..."><meta property="og:type" content="article"><meta property="og:image" content="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83/img/img00.jpg"><meta property="og:locale" content="zh-CN"><meta property="article:tag" content="深度学习"><meta property="article:tag" content="自然语言处理与语音识别"><meta property="article:published_time" content="2025-07-21T20:28:00.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"[深度学习] 大模型学习3上-模型训练与微调","image":["https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83/img/img00.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83/img/img01.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83/img/img02.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83/img/img03.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83/img/img04.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83/img/img05.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83/img/img06.gif","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83/img/img07.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83/img/img08.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83/img/img09.jpg"],"datePublished":"2025-07-21T20:28:00.000Z","dateModified":null,"author":[{"@type":"Person","name":"落痕月极","url":"/"}]}</script><link rel="icon" href="/logo.png"><title>[深度学习] 大模型学习3上-模型训练与微调 | 落痕月极的博客</title><meta name="description" content="[深度学习] 大模型学习3上-模型训练与微调 在文章大语言模型基础知识里，模型训练与微调作为大语言模型（Large Language Model，LLM）应用构建的主要方式被简要提及，本系列文章将从技术原理、实施流程及应用场景等维度展开深度解析。相关知识的进一步参考见：LLM训练理论和实战。本文作为系列的上半部分，内容涵盖第1章大语言模型概览和第2章大...">
    <link rel="preload" href="/assets/style-7oyYUlCQ.css" as="style"><link rel="stylesheet" href="/assets/style-7oyYUlCQ.css">
    <link rel="modulepreload" href="/assets/app-BNuIUq7T.js"><link rel="modulepreload" href="/assets/2025-07-21-_深度学习_ 大模型学习3上-模型训练与微调.html-DDCqJTbo.js">
    <link rel="prefetch" href="/assets/about.html-bGguhb-r.js" as="script"><link rel="prefetch" href="/assets/intro.html-Bo86sGN7.js" as="script"><link rel="prefetch" href="/assets/index.html-5AbxGoUy.js" as="script"><link rel="prefetch" href="/assets/index.html-HpNuprnF.js" as="script"><link rel="prefetch" href="/assets/index.html-B-eSpScv.js" as="script"><link rel="prefetch" href="/assets/2019-01-21-_常用工具_ 深度学习Caffe处理工具.html-C8E1Vfnj.js" as="script"><link rel="prefetch" href="/assets/2019-03-12-_常用工具_ Caffe ssd常见问题集合.html-CzfsvuJk.js" as="script"><link rel="prefetch" href="/assets/2019-04-19-_常用工具_ OpenCV获取网络摄像头实时视频流.html-DiJxdog1.js" as="script"><link rel="prefetch" href="/assets/2020-02-16-_常用工具_ git基础学习笔记.html-2HOKFYL-.js" as="script"><link rel="prefetch" href="/assets/2020-04-07-_常用工具_ shell脚本快速入门笔记.html-BlvZbsz9.js" as="script"><link rel="prefetch" href="/assets/2020-05-07-_常用工具_ live555的搭建.html-CByM_yNJ.js" as="script"><link rel="prefetch" href="/assets/2020-08-11-_常用工具_ OpenCV_contrib库在windows下编译使用指南.html-CG71yzdG.js" as="script"><link rel="prefetch" href="/assets/2021-02-10-_常用工具_ cvat安装与使用指北.html-55sCgitS.js" as="script"><link rel="prefetch" href="/assets/2021-04-23-_常用工具_ dlib编译调用指南.html-B6mS5gSz.js" as="script"><link rel="prefetch" href="/assets/2021-05-22-_常用工具_ mermaid学习笔记.html-EMwYFJ8f.js" as="script"><link rel="prefetch" href="/assets/2021-12-21-_常用工具_ PyAutoGUI使用教程.html-Co80n5_8.js" as="script"><link rel="prefetch" href="/assets/2022-03-20-_常用工具_ 搜索引擎的常用技巧总结.html-CCW2bYzS.js" as="script"><link rel="prefetch" href="/assets/2022-07-13-_常用工具_ C__环境下Qt的安装.html-pBT3jBMy.js" as="script"><link rel="prefetch" href="/assets/2022-07-18-_常用工具_ 基于psutil和GPUtil获取系统状态信息.html-Cb3R2SvJ.js" as="script"><link rel="prefetch" href="/assets/2022-08-12-_常用工具_ Python视频处理库VidGear使用指北.html-DCFR0ls9.js" as="script"><link rel="prefetch" href="/assets/2022-08-19-_常用工具_ Python视频解码库DeFFcode使用指北.html-D6ruVoBU.js" as="script"><link rel="prefetch" href="/assets/2021-08-04-_图像处理_ 基于图像哈希构建图像相似度对比算法.html-BtGBW64D.js" as="script"><link rel="prefetch" href="/assets/2024-10-24-_图像处理_ 基于CleanVision库清洗图像数据集.html-DVLdDgsW.js" as="script"><link rel="prefetch" href="/assets/2017-10-24-_数学理论_ 单一数字评估指标.html-CX07jcXw.js" as="script"><link rel="prefetch" href="/assets/2017-10-25-_数学理论_ 不同分布训练集、验证集、测试集处理.html-TfMq-HDw.js" as="script"><link rel="prefetch" href="/assets/2024-06-01-_机器学习_ 低代码机器学习工具PyCaret库使用指北.html-B2RXnKGq.js" as="script"><link rel="prefetch" href="/assets/2021-06-27-_数据分析与可视化_ 科技论文配色心得.html-Dv_JsaEe.js" as="script"><link rel="prefetch" href="/assets/2017-11-04-_能源化工_ TE田纳西-伊斯曼过程数据集.html-CwkiXFGI.js" as="script"><link rel="prefetch" href="/assets/2020-05-09-_能源化工_ 电力四遥.html-C58YzHzk.js" as="script"><link rel="prefetch" href="/assets/2022-01-25-_生命科学_ 生物基础实验之PCR验证.html-DxSbqfgW.js" as="script"><link rel="prefetch" href="/assets/2022-01-31-_生命科学_ 生物基础实验之DNA提取.html-C69Hrv_f.js" as="script"><link rel="prefetch" href="/assets/2022-03-04-_生命科学_ snapgene 构建载体方法分享.html-Cr8zvrbA.js" as="script"><link rel="prefetch" href="/assets/2022-03-25-_生命科学_ 生物基础实验之三引物检测突变体.html-DNM0z4NV.js" as="script"><link rel="prefetch" href="/assets/2025-09-13-_能源化工_ 面向锂电池RUL预测的开源项目全景速览.html-zyMfrN0H.js" as="script"><link rel="prefetch" href="/assets/2023-07-27-_自然语言处理_ 自然语言处理库spaCy使用指北.html-C4vwNPvx.js" as="script"><link rel="prefetch" href="/assets/2023-08-21-_语音识别_ 基于Python构建简易的音频录制与语音识别应用.html-DmDpPFAb.js" as="script"><link rel="prefetch" href="/assets/2023-09-24-_自然语言处理_ 基于pycorrector实现文本纠错.html-ceBqpBnN.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ kmeans聚类和WGCNA.html-syxazhCS.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 均匀和不均匀造林对生态多样性的影响综述.html-9elHq6Dt.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 枣树的历史与现状研究进展.html-D5A8fuNM.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 森林管理和造林业中复杂观念的转变.html-B-SxI_un.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 深度学习技术在植物领域的研究1.html-DYDGq3Jv.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 深度学习技术在植物领域的研究2.html-Bq3TpFZY.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 物联网技术在现代林业中的应用.html-DB_sF3hw.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 石榴综述论文阅读笔记.html-gBzwfTbt.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 美国造林业：过去30年的惊人变化时期.html-bslHBJpV.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 苗圃营建学习笔记.html-Bgb34Zhf.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 集约经营下人工林造林技术研究进展.html-DCNk-rL2.js" as="script"><link rel="prefetch" href="/assets/2021-09-23-_论文总结_ 农业工程领域中App和Web相关应用论文笔记.html-DcN_RlBr.js" as="script"><link rel="prefetch" href="/assets/2021-09-23-_论文总结_ 智慧农业论文摘要阅读概览.html-KZCsBxvM.js" as="script"><link rel="prefetch" href="/assets/2021-09-23-_论文总结_ 深度学习在农业领域应用论文笔记.html-F7iYbOzR.js" as="script"><link rel="prefetch" href="/assets/2021-10-18-_论文总结_ 育种理论与基因检测.html-Cai4TNJG.js" as="script"><link rel="prefetch" href="/assets/2021-10-19-_论文总结_ 树木的营养生理.html-BHkEph8_.js" as="script"><link rel="prefetch" href="/assets/2021-10-20-_论文总结_ 深度学习在农业领域应用论文笔记2.html-CbEKdkoi.js" as="script"><link rel="prefetch" href="/assets/2021-10-21-_论文总结_ 深度学习在农业领域应用论文笔记3.html-D94zRH_p.js" as="script"><link rel="prefetch" href="/assets/2021-10-27-_论文总结_ 深度学习在农业领域应用论文笔记4.html-CpayBg7q.js" as="script"><link rel="prefetch" href="/assets/2021-10-28-_论文总结_ 深度学习在农业领域应用论文笔记5.html-JYorGcHt.js" as="script"><link rel="prefetch" href="/assets/2021-10-29-_论文总结_ 深度学习在农业领域应用论文笔记6.html-DmNRbpRv.js" as="script"><link rel="prefetch" href="/assets/2021-10-30-_论文总结_ 深度学习在农业领域应用论文笔记7.html-kj-s9dLu.js" as="script"><link rel="prefetch" href="/assets/2021-11-02-_论文总结_ 深度学习在农业领域应用论文笔记8.html-7Yfw8vtG.js" as="script"><link rel="prefetch" href="/assets/2021-11-03-_论文总结_ 深度学习在农业领域应用论文笔记9.html-R76ewZeU.js" as="script"><link rel="prefetch" href="/assets/2021-11-04-_论文总结_ 森林生态系统中的水生生境.html-QYUMpqVO.js" as="script"><link rel="prefetch" href="/assets/2022-04-05-_论文总结_  种群、保护与生态遗传学笔记.html-xh6_Jjh2.js" as="script"><link rel="prefetch" href="/assets/2022-05-01-_论文总结_ Genecology and Adaptation of Forest Trees 林木的基因生态学与适应性.html--2tsc6cW.js" as="script"><link rel="prefetch" href="/assets/2022-05-20-_论文总结_ 中国工科生常见英文写作问题总结.html-B9rAGW49.js" as="script"><link rel="prefetch" href="/assets/2022-05-31-_论文总结_ 科技论文英语写作笔记1.html-BU0HBgDD.js" as="script"><link rel="prefetch" href="/assets/2022-08-01-_论文总结_ 深度学习在农业领域应用论文笔记10.html-C7KOSR1Q.js" as="script"><link rel="prefetch" href="/assets/2023-02-28-_论文总结_ 深度学习在农业领域应用论文笔记11.html-Cpt9M_ek.js" as="script"><link rel="prefetch" href="/assets/2024-02-10-_论文总结_ 深度学习在农业领域应用论文笔记12.html-DTA6KT-m.js" as="script"><link rel="prefetch" href="/assets/2024-09-25-_论文总结_ 深度学习在农业领域应用论文笔记13.html-Ed53nhY8.js" as="script"><link rel="prefetch" href="/assets/2025-01-28-_论文总结_ 深度学习在农业领域应用论文笔记14.html-BtHwvbco.js" as="script"><link rel="prefetch" href="/assets/2023-05-31-_音视频处理_ FFmpeg使用指北1-视频解码.html-zBRgUz6q.js" as="script"><link rel="prefetch" href="/assets/2020-12-13-_讲座论坛_ 碧根果产业现状及产业化开发关键技术.html-BYqCljKq.js" as="script"><link rel="prefetch" href="/assets/2020-12-20-_讲座论坛_ 竹资源培育与中国竹产业.html-DeG66EIN.js" as="script"><link rel="prefetch" href="/assets/2020-12-27-_讲座论坛_ 经济林之核桃类.html-CmjEjsvu.js" as="script"><link rel="prefetch" href="/assets/2021-04-21-_讲座论坛_ 应对气候变化的中国视角.html-CDR4V4GU.js" as="script"><link rel="prefetch" href="/assets/2022-02-28-_讲座论坛_ 国家自然基金申请知识汇总.html-Bq9xmz7B.js" as="script"><link rel="prefetch" href="/assets/2022-12-31-_讲座论坛_ 研究的艺术学习笔记.html-LA_yM-jS.js" as="script"><link rel="prefetch" href="/assets/2020-05-13-_随笔所想_ CSDN认证博客专家申请通过随笔所想.html-Pydba99O.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_随笔所想_ 程序员中年失业随笔所想.html-V93lfugm.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_随笔所想_ UBC学习生活经验分享.html-BzibMr_f.js" as="script"><link rel="prefetch" href="/assets/2021-01-14-_随笔所想_ 2021年新年碎碎念-加油了不起的干饭人!.html-Bedp7o5z.js" as="script"><link rel="prefetch" href="/assets/2021-02-12-_随笔所想_ 牛年碎碎念祝大家牛年大吉.html-_UdPfsQb.js" as="script"><link rel="prefetch" href="/assets/2021-03-31-_随笔所想_ 买房和户型挑选入门.html-CJ2yEzV7.js" as="script"><link rel="prefetch" href="/assets/2021-08-29-_随笔所想_ 学英语打卡2000天碎碎念.html-rul2eo-r.js" as="script"><link rel="prefetch" href="/assets/2021-12-1-_随笔所想_ 沉痛悼念开发技术专家毛星云老师.html-BrCB7hfF.js" as="script"><link rel="prefetch" href="/assets/2024-02-17-_随笔所想_ 劳动合同法学习笔记.html-D0-TsYzr.js" as="script"><link rel="prefetch" href="/assets/2019-03-04-_OpenCV实战_1 基于深度学习识别人脸性别和年龄.html-D3PL3yb2.js" as="script"><link rel="prefetch" href="/assets/2019-03-05-_OpenCV实战_2 人脸识别算法对比.html-BmaWnu3Y.js" as="script"><link rel="prefetch" href="/assets/2019-03-06-_OpenCV实战_3 透明斗篷.html-DsewBnbz.js" as="script"><link rel="prefetch" href="/assets/2019-03-06-_OpenCV实战_4 OpenCV中的颜色空间.html-DTmDZ12I.js" as="script"><link rel="prefetch" href="/assets/2019-03-06-_OpenCV实战_5 基于深度学习的文本检测.html-DKlIzUrn.js" as="script"><link rel="prefetch" href="/assets/2019-03-08-_OpenCV实战_6 基于特征点匹配的视频稳像.html-CvX5aCE3.js" as="script"><link rel="prefetch" href="/assets/2019-03-13-_OpenCV实战_7 使用YOLOv3和OpenCV进行基于深度学习的目标检测.html-D3VpY7A3.js" as="script"><link rel="prefetch" href="/assets/2019-03-15-_OpenCV实战_8 深度学习目标检测网络YOLOv3的训练.html-B03NqM5z.js" as="script"><link rel="prefetch" href="/assets/2019-03-16-_OpenCV实战_10 使用Hu矩进行形状匹配.html-DqzZl6pV.js" as="script"><link rel="prefetch" href="/assets/2019-03-16-_OpenCV实战_9 使用OpenCV寻找平面图形的质心.html-BNiRwt-u.js" as="script"><link rel="prefetch" href="/assets/2019-03-19-_OpenCV实战_11 基于OpenCV的二维码扫描器.html-DiAA9gpH.js" as="script"><link rel="prefetch" href="/assets/2019-03-27-_OpenCV实战_12 使用深度学习和OpenCV进行手部关键点检测.html-DbznQU0Q.js" as="script"><link rel="prefetch" href="/assets/2019-04-02-_OpenCV实战_13 OpenCV中使用Mask R-CNN进行对象检测和实例分割.html-QMQvmuRI.js" as="script"><link rel="prefetch" href="/assets/2019-04-04-_OpenCV实战_14 使用OpenCV实现单目标跟踪.html-DBBfrQND.js" as="script"><link rel="prefetch" href="/assets/2019-04-08-_OpenCV实战_15 基于深度学习的目标跟踪算法GOTURN.html-CNgOVuzV.js" as="script"><link rel="prefetch" href="/assets/2019-04-08-_OpenCV实战_16 使用OpenCV实现多目标跟踪.html-CT7IHFWh.js" as="script"><link rel="prefetch" href="/assets/2019-04-10-_OpenCV实战_17 基于卷积神经网络的OpenCV图像着色.html-D7tpq_Pk.js" as="script"><link rel="prefetch" href="/assets/2019-04-16-_OpenCV实战_18 OpenCV中的单应性矩阵Homography.html-D5rO6ii4.js" as="script"><link rel="prefetch" href="/assets/2019-04-17-_OpenCV实战_19 使用OpenCV实现基于特征的图像对齐.html-BYVZV7Os.js" as="script"><link rel="prefetch" href="/assets/2019-04-22-_OpenCV实战_20 使用OpenCV实现基于增强相关系数最大化的图像对齐.html-6Y3CX1qm.js" as="script"><link rel="prefetch" href="/assets/2019-04-23-_OpenCV实战_21 使用OpenCV的Eigenface.html-FgwEF9b7.js" as="script"><link rel="prefetch" href="/assets/2019-04-24-_OpenCV实战_22 使用EigenFaces进行人脸重建.html-DqdWGBi7.js" as="script"><link rel="prefetch" href="/assets/2019-04-30-_OpenCV实战_23 使用OpenCV获取高动态范围成像HDR.html-DjjhbZR7.js" as="script"><link rel="prefetch" href="/assets/2019-05-05-_OpenCV实战_24 使用OpenCV进行曝光融合.html-ho4KyaKW.js" as="script"><link rel="prefetch" href="/assets/2019-05-05-_OpenCV实战_25 使用OpenCV进行泊松克隆.html-BAh6pVeC.js" as="script"><link rel="prefetch" href="/assets/2019-05-06-_OpenCV实战_26 基于OpenCV实现选择性搜索算法.html-BKjczT4K.js" as="script"><link rel="prefetch" href="/assets/2019-05-07-_OpenCV实战_27 在OpenCV下使用forEach进行并行像素访问.html-JQinZmow.js" as="script"><link rel="prefetch" href="/assets/2019-05-08-_OpenCV实战_28 基于OpenCV的GUI库cvui.html-COEcnbND.js" as="script"><link rel="prefetch" href="/assets/2019-05-09-_OpenCV实战_29 使用OpenCV实现红眼自动去除.html-zn6cWdWX.js" as="script"><link rel="prefetch" href="/assets/2019-05-10-_OpenCV实战_30 使用OpenCV实现图像孔洞填充.html-Cy4TWJbI.js" as="script"><link rel="prefetch" href="/assets/2019-05-23-_OpenCV实战_31 使用OpenCV将一个三角形仿射变换到另一个三角形.html-Dv885qp7.js" as="script"><link rel="prefetch" href="/assets/2019-05-24-_OpenCV实战_32 使用OpenCV进行非真实感渲染.html-lb82waD_.js" as="script"><link rel="prefetch" href="/assets/2019-05-27-_OpenCV实战_33 使用OpenCV进行Hough变换.html-ChLUKP2C.js" as="script"><link rel="prefetch" href="/assets/2019-05-28-_OpenCV实战_34 使用OpenCV进行图像修复.html-yMkksJGy.js" as="script"><link rel="prefetch" href="/assets/2019-07-16-_OpenCV实战_35 使用Tesseract和OpenCV实现文本识别.html-DV9xCA7d.js" as="script"><link rel="prefetch" href="/assets/2019-08-30-_OpenCV实战_36 使用OpenCV在视频中实现简单背景估计.html-DHm7902d.js" as="script"><link rel="prefetch" href="/assets/2020-02-29-_OpenCV实战_37 图像质量评价BRISQUE.html-Dku4ayHq.js" as="script"><link rel="prefetch" href="/assets/2020-03-06-_OpenCV实战_38 基于OpenCV的相机标定.html-vnLywq0y.js" as="script"><link rel="prefetch" href="/assets/2020-03-31-_OpenCV实战_39 在OpenCV中使用ArUco标记的增强现实.html-R3zFR-Pp.js" as="script"><link rel="prefetch" href="/assets/2020-05-07-_OpenCV实战_40 计算机视觉工具对比.html-Bq0NFBcL.js" as="script"><link rel="prefetch" href="/assets/2020-05-10-_OpenCV实战_41 嵌入式计算机视觉设备选择.html-DMrBXVQs.js" as="script"><link rel="prefetch" href="/assets/2020-05-12-_OpenCV实战_42 数码单反相机的技术细节.html-CevtpEWS.js" as="script"><link rel="prefetch" href="/assets/2020-08-14-_OpenCV实战_43 使用OpenCV进行背景分割.html-BOGgkTRX.js" as="script"><link rel="prefetch" href="/assets/2020-08-24-_OpenCV实战_44 使用OpenCV进行图像超分放大.html-Dzakqmxq.js" as="script"><link rel="prefetch" href="/assets/2020-08-27-_OpenCV实战_45 基于OpenCV实现图像哈希算法.html-BQfh4urP.js" as="script"><link rel="prefetch" href="/assets/2020-09-10-_OpenCV实战_46 在OpenCV下应用图像强度变换实现图像对比度均衡.html-CINyImGh.js" as="script"><link rel="prefetch" href="/assets/2020-09-15-_OpenCV实战_47 基于OpenCV实现视觉显著性检测.html-C6aRyyYU.js" as="script"><link rel="prefetch" href="/assets/2020-10-09-_OpenCV实战_48 基于OpenCV实现图像质量评价.html-OKVpDm7m.js" as="script"><link rel="prefetch" href="/assets/2021-02-12-_OpenCV实战_49 对极几何与立体视觉初探.html-DPJE23AT.js" as="script"><link rel="prefetch" href="/assets/2021-02-16-_OpenCV实战_50 用OpenCV制作低成本立体相机.html-Cxjhnz_-.js" as="script"><link rel="prefetch" href="/assets/2021-03-15-_OpenCV实战_51 基于OpenCV实现图像极坐标变换与逆变换.html-D0QukANt.js" as="script"><link rel="prefetch" href="/assets/2022-12-01-_OpenCV实战_52 在OpenCV中使用颜色直方图.html-CG2SIxLC.js" as="script"><link rel="prefetch" href="/assets/index.html-BTcA4Bxk.js" as="script"><link rel="prefetch" href="/assets/2017-11-13-_python_ tensorflow中的argmax()函数.html-jqGHtw7Q.js" as="script"><link rel="prefetch" href="/assets/2019-07-31-_python_ 基于matplotlib实现树形图的绘制.html-y_Fu6q4z.js" as="script"><link rel="prefetch" href="/assets/2019-08-13-_python_ mxnet60分钟入门Gluon教程.html-C3izOpvI.js" as="script"><link rel="prefetch" href="/assets/2019-10-28-_python_ 基于NetworkX实现网络图的绘制.html-B85B9mnv.js" as="script"><link rel="prefetch" href="/assets/2019-10-31-_python_ NetworkX实例.html-C-P02Q9l.js" as="script"><link rel="prefetch" href="/assets/2019-11-15-_python_ 基于matplotlib_venn实现维恩图的绘制.html-BApQDZdL.js" as="script"><link rel="prefetch" href="/assets/2019-12-30-_python_ CairoSVG使用教程.html-CsGrVanu.js" as="script"><link rel="prefetch" href="/assets/2020-03-25-_python_ 个人日常python工具代码.html-Cs6ukmSF.js" as="script"><link rel="prefetch" href="/assets/2020-05-17-_python_ python模块graphviz使用入门.html-BxwNkuxx.js" as="script"><link rel="prefetch" href="/assets/2020-09-01-_python_ 基于matplotlib实现圆环图的绘制.html-C1U82sSJ.js" as="script"><link rel="prefetch" href="/assets/2020-09-01-_python_ 基于matplotlib实现雷达图的绘制.html-B7wJeTdD.js" as="script"><link rel="prefetch" href="/assets/2021-07-20-_python_ Python二维码生成器qrcode库入门.html-BKG4zxHo.js" as="script"><link rel="prefetch" href="/assets/2021-07-21-_python_ Python map函数总结.html-QSw50fiD.js" as="script"><link rel="prefetch" href="/assets/2021-07-23-_python_ 圆形嵌套图Circular Packing.html-CESpqZI0.js" as="script"><link rel="prefetch" href="/assets/2022-04-10-_python_ ​python-pinyin库.html-CwLIzMU-.js" as="script"><link rel="prefetch" href="/assets/2022-07-07-_python_ ​Python数据序列化模块pickle使用笔记.html-Bo_M-BrC.js" as="script"><link rel="prefetch" href="/assets/2022-07-21-_python_ 向量检索库Faiss使用指北.html-BVApop4_.js" as="script"><link rel="prefetch" href="/assets/2022-07-25-_python_ 基于chardet识别字符编码.html-DXFI0DEX.js" as="script"><link rel="prefetch" href="/assets/2022-09-10-_python_ 基于diagrams库绘制系统架构图.html-CLVJiSBR.js" as="script"><link rel="prefetch" href="/assets/2022-09-19-_python_ 基于blind-watermark库添加图片盲水印.html-tv3Igd7H.js" as="script"><link rel="prefetch" href="/assets/2022-10-24-_python_ 基于Gradio可视化部署机器学习应用.html-koDZMQAB.js" as="script"><link rel="prefetch" href="/assets/2022-12-07-_python_ 基于wordcloud库绘制词云图.html-4apqYoMQ.js" as="script"><link rel="prefetch" href="/assets/2023-01-01-_python_ 基于paramiko库操作远程服务器.html-BdYdfOAk.js" as="script"><link rel="prefetch" href="/assets/2023-04-17-_python_ Python枚举模块enum总结.html-9ULEjgoL.js" as="script"><link rel="prefetch" href="/assets/2023-05-10-_python_ Python类型提示总结.html-BtYp1rR7.js" as="script"><link rel="prefetch" href="/assets/2023-11-30-_python_ 基于Tablib库处理表格数据.html-Dfm-uBvv.js" as="script"><link rel="prefetch" href="/assets/2023-12-29-_python_ 基于Dataset库操作数据库.html-DkW8Mw7u.js" as="script"><link rel="prefetch" href="/assets/2024-01-25-_python_ 基于RapidFuzz库实现字符串模糊匹配.html-DRnXkprD.js" as="script"><link rel="prefetch" href="/assets/2024-04-30-_python_ 基于PyWaffle库绘制华夫饼图.html-zyYMz03w.js" as="script"><link rel="prefetch" href="/assets/2024-06-30-_python_ Python日志记录库loguru使用指北.html-kjS_BB37.js" as="script"><link rel="prefetch" href="/assets/2024-07-30-_python_ 启发式算法库scikit-opt使用指北.html-BOjDhgnn.js" as="script"><link rel="prefetch" href="/assets/2024-08-10-_python_ Python并行计算库Joblib使用指北.html-DIUEPaNX.js" as="script"><link rel="prefetch" href="/assets/2024-10-01-_python_ 基于PyOD库实现数据异常检测.html-CC097CUZ.js" as="script"><link rel="prefetch" href="/assets/2024-11-22-_python_ Python异步编程库asyncio使用指北.html-B_0cWEJS.js" as="script"><link rel="prefetch" href="/assets/2024-11-25-_python_ asyncio库常见问题与实践案例.html-D_QfuwdC.js" as="script"><link rel="prefetch" href="/assets/2025-03-24-_python_ 使用Python实现Markdown文档格式转换.html-CxQpLpxu.js" as="script"><link rel="prefetch" href="/assets/2025-04-27-_python_ 基于WatchDog库实现文件系统监控.html-COvJC0Ss.js" as="script"><link rel="prefetch" href="/assets/2025-05-20-_python_ 轻量级定时任务调度库schedule使用指北.html-DyBjaRrp.js" as="script"><link rel="prefetch" href="/assets/2025-06-03-_python_ python抽象基类使用总结.html-BlLZAlWX.js" as="script"><link rel="prefetch" href="/assets/2019-06-25-_python_《Python编程快速上手让繁琐工作自动化》学习笔记1.html-DGHFS5Ab.js" as="script"><link rel="prefetch" href="/assets/2019-06-26-_python_《Python编程快速上手让繁琐工作自动化》学习笔记2.html-BQU5YkIN.js" as="script"><link rel="prefetch" href="/assets/2019-06-28-_python_《Python编程快速上手让繁琐工作自动化》学习笔记3.html-sb_d6c4t.js" as="script"><link rel="prefetch" href="/assets/2019-07-05-_python_《Python编程快速上手让繁琐工作自动化》学习笔记4.html-Cz-cFtKH.js" as="script"><link rel="prefetch" href="/assets/2019-07-27-_python_《Python编程快速上手让繁琐工作自动化》学习笔记5.html-BcCWigf5.js" as="script"><link rel="prefetch" href="/assets/2019-07-31-_python_《Python编程快速上手让繁琐工作自动化》学习笔记6.html-CxAvT260.js" as="script"><link rel="prefetch" href="/assets/2019-08-02-_python_《Python编程快速上手让繁琐工作自动化》学习笔记7.html-Bd__BauB.js" as="script"><link rel="prefetch" href="/assets/2019-05-28-_seaborn_ seaborn学习笔记0 seaborn学习笔记章节.html-BKmjaivD.js" as="script"><link rel="prefetch" href="/assets/2019-05-29-_seaborn_ seaborn学习笔记1 箱形图Boxplot.html-BHGvXgcX.js" as="script"><link rel="prefetch" href="/assets/2019-05-30-_seaborn_ seaborn学习笔记2 散点图Scatterplot.html-DEfnyVmW.js" as="script"><link rel="prefetch" href="/assets/2019-05-30-_seaborn_ seaborn学习笔记3 直方图Histogramplot.html-Bf_8T9Sf.js" as="script"><link rel="prefetch" href="/assets/2019-05-31-_seaborn_ seaborn学习笔记4 核密度图DENSITYPLOT.html-BHISg8ci.js" as="script"><link rel="prefetch" href="/assets/2019-05-31-_seaborn_ seaborn学习笔记5 小提琴图VIOLINPLOT.html-DSjwonRv.js" as="script"><link rel="prefetch" href="/assets/2019-05-31-_seaborn_ seaborn学习笔记6 热图HEATMAPPLOT.html-Bl-tgVq8.js" as="script"><link rel="prefetch" href="/assets/2019-06-01-_seaborn_ seaborn学习笔记7 常用参数调整Adjustment of Common Parameters.html-Dap2B8DV.js" as="script"><link rel="prefetch" href="/assets/2019-06-01-_seaborn_ seaborn学习笔记8 避免过度绘图Avoid Overplotting.html-Gj228ZtT.js" as="script"><link rel="prefetch" href="/assets/2019-06-05-_seaborn_ seaborn学习笔记10 绘图实例(2) Drawing example(2).html-BHUz7Y3f.js" as="script"><link rel="prefetch" href="/assets/2019-06-05-_seaborn_ seaborn学习笔记9 绘图实例(1) Drawing example(1).html-Da9-YEY9.js" as="script"><link rel="prefetch" href="/assets/2019-06-06-_seaborn_ seaborn学习笔记11 绘图实例(3) Drawing example(3).html-BhY1L-oF.js" as="script"><link rel="prefetch" href="/assets/2019-06-06-_seaborn_ seaborn学习笔记12 绘图实例(4) Drawing example(4).html-CgH7oQ68.js" as="script"><link rel="prefetch" href="/assets/2020-03-21-_R语言_ ggplot2入门笔记1—ggplot2简要教程.html-BkIFnj3H.js" as="script"><link rel="prefetch" href="/assets/2020-03-21-_R语言_ ggplot2入门笔记2—通用教程ggplot2简介.html-Dxgeb3BU.js" as="script"><link rel="prefetch" href="/assets/2020-03-21-_R语言_ ggplot2入门笔记3—通用教程如何自定义ggplot2.html-C7K9BANM.js" as="script"><link rel="prefetch" href="/assets/2020-03-21-_R语言_ ggplot2入门笔记4—前50个ggplot2可视化效果.html-3w6uUuP2.js" as="script"><link rel="prefetch" href="/assets/index.html-BPACOkBF.js" as="script"><link rel="prefetch" href="/assets/2019-07-31-_R语言_ R语言PCA分析教程 Principal Component Methods in R.html-B67zgQoI.js" as="script"><link rel="prefetch" href="/assets/2020-01-10-_R语言_ WGCNA入门教程.html-CGsGNuY4.js" as="script"><link rel="prefetch" href="/assets/2021-02-05-_R语言_ R语言快速入门教程.html-Cg5UdVUf.js" as="script"><link rel="prefetch" href="/assets/2020-09-05-_R语言_ 基于R语言实现树形图的绘制.html-BTuFdYnr.js" as="script"><link rel="prefetch" href="/assets/2020-09-05-_R语言_ 基于R语言实现环状条形图的绘制.html-D5ZIJ9_P.js" as="script"><link rel="prefetch" href="/assets/2018-12-11-_图像处理_ YUV图像处理入门1.html-Xp3GSjrr.js" as="script"><link rel="prefetch" href="/assets/2018-12-11-_图像处理_ YUV图像处理入门2.html-DRmLIZwP.js" as="script"><link rel="prefetch" href="/assets/2018-12-11-_图像处理_ YUV图像处理入门3.html-BBMa1CoV.js" as="script"><link rel="prefetch" href="/assets/2018-12-11-_图像处理_ YUV图像处理入门4.html-BCaWuZY9.js" as="script"><link rel="prefetch" href="/assets/2018-12-11-_图像处理_ YUV图像处理入门5.html-Cie563qY.js" as="script"><link rel="prefetch" href="/assets/index.html-D6Ed7Nn9.js" as="script"><link rel="prefetch" href="/assets/2017-12-10-_机器学习_ 集成学习简单投票法概率.html-Cj2OH0oQ.js" as="script"><link rel="prefetch" href="/assets/2018-04-17-_机器学习_ sklearn聚类.html-DhzRgBhb.js" as="script"><link rel="prefetch" href="/assets/2018-04-19-_机器学习_ sklearn决策树、随机森林、隐马尔可夫模型.html-CgnkM8gE.js" as="script"><link rel="prefetch" href="/assets/2018-04-19-_机器学习_ sklearn朴素贝叶斯算法.html-tgbw3-Ts.js" as="script"><link rel="prefetch" href="/assets/2018-04-21-_机器学习_ sklearn支持向量机.html-CJ7cLHM1.js" as="script"><link rel="prefetch" href="/assets/2020-07-25-_机器学习_ Yellowbrick使用笔记1-快速入门.html-Gk_E54Qs.js" as="script"><link rel="prefetch" href="/assets/2020-07-25-_机器学习_ Yellowbrick使用笔记2-模型选择.html-BPg5tTR1.js" as="script"><link rel="prefetch" href="/assets/2020-07-25-_机器学习_ Yellowbrick使用笔记3-特征分析可视化.html-CDa0oWeR.js" as="script"><link rel="prefetch" href="/assets/2020-07-25-_机器学习_ Yellowbrick使用笔记4-目标可视化文件.html-Bw_-DNTe.js" as="script"><link rel="prefetch" href="/assets/2020-07-25-_机器学习_ Yellowbrick使用笔记5-回归可视化.html-DxzXxLaX.js" as="script"><link rel="prefetch" href="/assets/2020-07-25-_机器学习_ Yellowbrick使用笔记6-分类可视化.html-Cmjb1hmC.js" as="script"><link rel="prefetch" href="/assets/2020-07-25-_机器学习_ Yellowbrick使用笔记7-聚类可视化.html-Bgv80CZ4.js" as="script"><link rel="prefetch" href="/assets/2020-07-25-_机器学习_ Yellowbrick使用笔记8-模型选择可视化.html-dTnTCdgg.js" as="script"><link rel="prefetch" href="/assets/2020-07-09-_机器学习_ 特征选择笔记1-删除低方差的特征.html-B9FpDM9Y.js" as="script"><link rel="prefetch" href="/assets/2020-07-09-_机器学习_ 特征选择笔记2-单变量特征选择.html-Bh5a6thm.js" as="script"><link rel="prefetch" href="/assets/2020-07-09-_机器学习_ 特征选择笔记3-递归式特征消除.html-CJZHKbq1.js" as="script"><link rel="prefetch" href="/assets/2020-07-09-_机器学习_ 特征选择笔记4-使用SelectFromModel特征选择.html-B4FT9Bxd.js" as="script"><link rel="prefetch" href="/assets/2021-11-21-_数据与分析可视化_ D3入门教程1-d3基础知识.html-BzNK2Q6k.js" as="script"><link rel="prefetch" href="/assets/2021-11-28-_数据与分析可视化_ D3入门教程2-在d3中构建形状.html-D7gME7nf.js" as="script"><link rel="prefetch" href="/assets/2021-12-05-_数据与分析可视化_ D3入门教程3-d3中的数据操作.html-CIB5g6oj.js" as="script"><link rel="prefetch" href="/assets/2023-03-16-_数据分析与可视化_ Python绘制数据地图1-GeoPandas入门指北.html-B3tNJOlS.js" as="script"><link rel="prefetch" href="/assets/2023-04-09-_数据分析与可视化_ Python绘制数据地图2-GeoPandas地图可视化.html-CLL6DM20.js" as="script"><link rel="prefetch" href="/assets/2023-06-16-_数据分析与可视化_ Python绘制数据地图3-GeoPandas使用要点.html-OsayE9M1.js" as="script"><link rel="prefetch" href="/assets/2023-08-03-_数据分析与可视化_ Python绘制数据地图4-MovingPandas入门指北.html-DV7v0aex.js" as="script"><link rel="prefetch" href="/assets/2023-08-11-_数据分析与可视化_ Python绘制数据地图5-MovingPandas绘图实例.html-BU-WWqQY.js" as="script"><link rel="prefetch" href="/assets/2021-11-14-_数据分析与可视化_ 数据绘图要点1-注重数据排序.html-C1bb1hPA.js" as="script"><link rel="prefetch" href="/assets/2021-11-18-_数据分析与可视化_ 数据绘图要点2-Y轴的开始与结束.html-DOWBUUyf.js" as="script"><link rel="prefetch" href="/assets/2021-11-24-_数据分析与可视化_ 数据绘图要点3-意大利面条图.html-B1zC_pow.js" as="script"><link rel="prefetch" href="/assets/2021-12-01-_数据分析与可视化_ 数据绘图要点4-饼图的问题.html-KPBS7y3t.js" as="script"><link rel="prefetch" href="/assets/2021-12-09-_数据分析与可视化_ 数据绘图要点5-误差线的问题.html-y3YYxnRp.js" as="script"><link rel="prefetch" href="/assets/2021-12-19-_数据分析与可视化_ 数据绘图要点6-数据组过多.html-9dXnhZIF.js" as="script"><link rel="prefetch" href="/assets/2021-12-25-_数据分析与可视化_ 数据绘图要点7-过度绘图.html-TM9OCkb7.js" as="script"><link rel="prefetch" href="/assets/2021-12-29-_数据分析与可视化_ 数据绘图要点8-环状条形图的使用.html-BX02DCmF.js" as="script"><link rel="prefetch" href="/assets/2022-01-01-_数据分析与可视化_ 数据绘图要点9-颜色的选择.html-BYTAfyMi.js" as="script"><link rel="prefetch" href="/assets/2022-01-06-_数据分析与可视化_ 数据绘图要点10-图例的构建.html-C3SamlfR.js" as="script"><link rel="prefetch" href="/assets/2022-01-12-_数据分析与可视化_ 数据绘图要点11-雷达图的注意事项.html-wCEoSgzv.js" as="script"><link rel="prefetch" href="/assets/2022-01-18-_数据分析与可视化_ 数据绘图要点12-图表注释的重要性.html-CPAQCTBy.js" as="script"><link rel="prefetch" href="/assets/2024-12-31-_深度学习_ 大模型学习1-大语言模型基础知识.html-A3V1z6MJ.js" as="script"><link rel="prefetch" href="/assets/2025-02-28-_深度学习_ 大模型学习2-提示词工程指北.html-DdUnt2Go.js" as="script"><link rel="prefetch" href="/assets/2025-07-23-_深度学习_ 大模型学习3下-模型训练与微调.html-DWgZj0Rk.js" as="script"><link rel="prefetch" href="/assets/2025-08-08-_深度学习_ 大模型学习4-RAG技术全景解析.html-Djny-pEp.js" as="script"><link rel="prefetch" href="/assets/2025-10-01-_深度学习_ 大模型学习5-高效微调框架Unsloth使用指北.html-cmfD5908.js" as="script"><link rel="prefetch" href="/assets/2023-06-28-_数据分析与可视化_ 基于matplotlib-scalebar库绘制比例尺.html-B435zg7c.js" as="script"><link rel="prefetch" href="/assets/2023-07-10-_数据分析与可视化_ 基于matplotlib和plottable库绘制精美表格.html-DKUVAC3s.js" as="script"><link rel="prefetch" href="/assets/2023-10-24-_数据分析与可视化_ 基于Python绘制简单动图.html-DPEF3R_f.js" as="script"><link rel="prefetch" href="/assets/2017-10-11-_深度学习_ 网易云课堂深度学习工程师微专业相关资料.html-DMSXLfQp.js" as="script"><link rel="prefetch" href="/assets/2017-10-12-_深度学习_ 深度学习快速入门资料.html-tCXi8tDq.js" as="script"><link rel="prefetch" href="/assets/2017-10-13-_深度学习_ 卷积神经网络快速入门.html-CxAyolQz.js" as="script"><link rel="prefetch" href="/assets/2017-11-25-_深度学习_ 深度学习中卷积操作和数学中卷积操作的异同.html-CienO7SI.js" as="script"><link rel="prefetch" href="/assets/2018-07-17-_深度学习_ tf.keras入门1-基本函数介绍.html-C7JzbfZI.js" as="script"><link rel="prefetch" href="/assets/2018-07-18-_深度学习_ tf.keras入门2-分类.html-Bmr2f5nh.js" as="script"><link rel="prefetch" href="/assets/2018-07-18-_深度学习_ tf.keras入门3-回归.html-CTs3xRg3.js" as="script"><link rel="prefetch" href="/assets/2018-07-18-_深度学习_ tf.keras入门4-过拟合和欠拟合.html-BI03ql7t.js" as="script"><link rel="prefetch" href="/assets/2018-07-18-_深度学习_ tf.keras入门5-模型保存和载入.html-BcWUrr2W.js" as="script"><link rel="prefetch" href="/assets/2018-07-27-_深度学习_ 经典深度学习模型及其微调（Caffe)总结.html-CU3hbKXC.js" as="script"><link rel="prefetch" href="/assets/2019-07-23-_深度学习_ ncnn安装和调用基础教程.html-TNxXLZlb.js" as="script"><link rel="prefetch" href="/assets/2019-08-10-_深度学习_ caffe分类模型训练、结果可视化、部署及量化笔记.html-Db2FzpB6.js" as="script"><link rel="prefetch" href="/assets/2019-09-30-_深度学习_ ncnn编译使用.html-DNYZDjxl.js" as="script"><link rel="prefetch" href="/assets/2020-08-07-_深度学习_ ImageAI库使用笔记.html-4bqbWsj_.js" as="script"><link rel="prefetch" href="/assets/2020-10-24-_深度学习_ imgaug库使用笔记.html-BRCNT-vV.js" as="script"><link rel="prefetch" href="/assets/2020-11-19-_深度学习_ 深度学习优化器选择学习笔记.html-hSGrGHNI.js" as="script"><link rel="prefetch" href="/assets/2020-12-09-_深度学习_ Pytorch模型转换为onnx模型笔记.html-GIaiYZF3.js" as="script"><link rel="prefetch" href="/assets/2021-01-14-_深度学习_ ubuntu18.04配置深度学习环境笔记.html-C_bB3eG4.js" as="script"><link rel="prefetch" href="/assets/2021-02-02-_深度学习_ imgaug边界框增强笔记.html-DV2tLfbO.js" as="script"><link rel="prefetch" href="/assets/2021-06-09-_深度学习_ CCPD车牌数据集介绍.html-D1K9tXqC.js" as="script"><link rel="prefetch" href="/assets/2022-01-14-_深度学习_ fast-reid入门教程.html-xtG3sk--.js" as="script"><link rel="prefetch" href="/assets/2022-02-26-_深度学习_ Python人脸识别库face_recognition使用教程.html-BYO1wt9z.js" as="script"><link rel="prefetch" href="/assets/2022-07-02-_深度学习_ Python人脸识别库Deepface使用教程.html-Bl7gcsfV.js" as="script"><link rel="prefetch" href="/assets/2022-11-24-_深度学习_ 搭建行人重识别系统心得.html-C7OQqCKj.js" as="script"><link rel="prefetch" href="/assets/2023-01-03-_深度学习_ 基于切片辅助超推理库SAHI优化小目标识别.html-DY3_E3kf.js" as="script"><link rel="prefetch" href="/assets/2024-03-18-_深度学习_ 计算机视觉低代码工具Supervision库使用指北.html-BIAtWAxH.js" as="script"><link rel="prefetch" href="/assets/2024-08-28-_深度学习_ 时间序列分析工具TSLiB库使用指北.html-B6I3H7zT.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门1-创建线程的三种不同方式.html-CBo-_kZQ.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门10-packaged_task示例.html-B-ku7h_r.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门2-连接和分离线程.html-Cnx5Ze9P.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门3-小心地将参数传递给线程.html-gbsFy2TE.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门4-数据共享和资源竞争.html-BFr8_xhz.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门5-使用互斥锁解决资源竞争.html-CHIXvMZ4.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门6-事件处理的需求.html-BcRlP0D2.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门7-条件变量介绍.html-B7LkF5eK.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门8-从线程返回值.html-w4X5gK_F.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门9-async教程和示例.html-DdIexDYv.js" as="script"><link rel="prefetch" href="/assets/2021-10-24-_编程基础_ 常用html标签使用介绍.html-CzFHHWSa.js" as="script"><link rel="prefetch" href="/assets/2017-11-02-_编程基础_ C_自定义类调用窗体控件.html-BvCUvkOG.js" as="script"><link rel="prefetch" href="/assets/2020-05-09-_编程基础_ C和C__内置宏说明.html-B4mRqriL.js" as="script"><link rel="prefetch" href="/assets/2020-06-17-_编程基础_ Python格式化字符串常量f-string总结.html-BcQcOeN2.js" as="script"><link rel="prefetch" href="/assets/2020-06-20-_编程基础_ Python谷歌翻译库googletrans总结.html-Dq9pFpo5.js" as="script"><link rel="prefetch" href="/assets/2020-06-21-_编程基础_ Python数据生成库Faker总结.html-7XG77yjW.js" as="script"><link rel="prefetch" href="/assets/2020-06-21-_编程基础_ Python配置文件读取库ConfigParser总结.html-CvYVaHgB.js" as="script"><link rel="prefetch" href="/assets/2020-06-23-_编程基础_ Python日志记录库logging总结.html-Bqzj2_sZ.js" as="script"><link rel="prefetch" href="/assets/2020-06-24-_编程基础_ Python随机数生成模块总结.html-CBMysNef.js" as="script"><link rel="prefetch" href="/assets/2020-06-25-_编程基础_ Python lambda函数总结.html-LUd_wsN2.js" as="script"><link rel="prefetch" href="/assets/2020-06-25-_编程基础_ Python装饰器入门总结.html-CU3E7Zd6.js" as="script"><link rel="prefetch" href="/assets/2020-06-26-_编程基础_ Python列表解析总结.html-GXor5jNF.js" as="script"><link rel="prefetch" href="/assets/2020-08-01-_编程基础_ Python中的绝对导入与相对导入.html-kNnv7Ut_.js" as="script"><link rel="prefetch" href="/assets/2020-08-01-_编程基础_ Python模块和包使用笔记.html-ITKoq9mC.js" as="script"><link rel="prefetch" href="/assets/2020-08-02-_编程基础_ Python对象的浅拷贝与深拷贝笔记.html-9-m2IYtU.js" as="script"><link rel="prefetch" href="/assets/2020-10-14-_编程基础_ Python中args和kwargs参数的使用.html-BinXsG2D.js" as="script"><link rel="prefetch" href="/assets/2020-10-31-_编程基础_ Python命令行解析库argparse学习笔记.html-B1cw6MfU.js" as="script"><link rel="prefetch" href="/assets/2021-08-16-_编程基础_ Python字符串替换笔记.html-BGPZiiX4.js" as="script"><link rel="prefetch" href="/assets/2023-09-05-_编程基础_ Python内置模块collections使用笔记.html-BuCKTf2a.js" as="script"><link rel="prefetch" href="/assets/404.html-BYYzuw5P.js" as="script"><link rel="prefetch" href="/assets/index.html-TBiKUGij.js" as="script"><link rel="prefetch" href="/assets/index.html-DWYtpWLO.js" as="script"><link rel="prefetch" href="/assets/index.html-BikacvY6.js" as="script"><link rel="prefetch" href="/assets/index.html-ByPCBolu.js" as="script"><link rel="prefetch" href="/assets/index.html-DeS58vav.js" as="script"><link rel="prefetch" href="/assets/index.html-B-JD5iHi.js" as="script"><link rel="prefetch" href="/assets/index.html-Cmvyhm9w.js" as="script"><link rel="prefetch" href="/assets/index.html-B6DbwoQi.js" as="script"><link rel="prefetch" href="/assets/index.html-DasxH7-c.js" as="script"><link rel="prefetch" href="/assets/index.html-C93Vvn-d.js" as="script"><link rel="prefetch" href="/assets/index.html-DQmAQ0-3.js" as="script"><link rel="prefetch" href="/assets/index.html-CC_spg8Y.js" as="script"><link rel="prefetch" href="/assets/index.html-DpuJFRFF.js" as="script"><link rel="prefetch" href="/assets/index.html-6MM5_2YQ.js" as="script"><link rel="prefetch" href="/assets/index.html-Bv3cHg-6.js" as="script"><link rel="prefetch" href="/assets/index.html-Dvp5QHpZ.js" as="script"><link rel="prefetch" href="/assets/index.html-ByEtp_Vn.js" as="script"><link rel="prefetch" href="/assets/index.html-Cw2ZKOZL.js" as="script"><link rel="prefetch" href="/assets/index.html-CttppXHk.js" as="script"><link rel="prefetch" href="/assets/index.html-44IeLgtb.js" as="script"><link rel="prefetch" href="/assets/index.html-CjbAxN5n.js" as="script"><link rel="prefetch" href="/assets/index.html-DN4YuGyd.js" as="script"><link rel="prefetch" href="/assets/index.html-CAY4mMBc.js" as="script"><link rel="prefetch" href="/assets/index.html-BJFd8D2I.js" as="script"><link rel="prefetch" href="/assets/index.html-B2ix7lKa.js" as="script"><link rel="prefetch" href="/assets/index.html-C0UQgP5o.js" as="script"><link rel="prefetch" href="/assets/index.html-Dqtkg7iw.js" as="script"><link rel="prefetch" href="/assets/index.html-BiDM662o.js" as="script"><link rel="prefetch" href="/assets/index.html-DgLisJo1.js" as="script"><link rel="prefetch" href="/assets/index.html-Cdybs9RS.js" as="script"><link rel="prefetch" href="/assets/index.html-BaXf_Qqo.js" as="script"><link rel="prefetch" href="/assets/index.html-CBXCldUz.js" as="script"><link rel="prefetch" href="/assets/index.html-BO7d7TVG.js" as="script"><link rel="prefetch" href="/assets/index.html-BT47VLuH.js" as="script"><link rel="prefetch" href="/assets/index.html-x6CV7jsj.js" as="script"><link rel="prefetch" href="/assets/index.html-CeqXQ4P7.js" as="script"><link rel="prefetch" href="/assets/index.html-Cd54Piak.js" as="script"><link rel="prefetch" href="/assets/index.html-29kt5_vZ.js" as="script"><link rel="prefetch" href="/assets/index.html-X3M-7zu0.js" as="script"><link rel="prefetch" href="/assets/index.html-qNpJ21EC.js" as="script"><link rel="prefetch" href="/assets/index.html-DcAVvim4.js" as="script"><link rel="prefetch" href="/assets/index.html-5B7DTk8H.js" as="script"><link rel="prefetch" href="/assets/index.html-IEdRiRUz.js" as="script"><link rel="prefetch" href="/assets/index.html-CkOikixg.js" as="script"><link rel="prefetch" href="/assets/index.html-BfRucus6.js" as="script"><link rel="prefetch" href="/assets/index.html-CrIcC2u9.js" as="script"><link rel="prefetch" href="/assets/index.html-BoNNh7wo.js" as="script"><link rel="prefetch" href="/assets/index.html-DsQjal0q.js" as="script"><link rel="prefetch" href="/assets/index.html-DeadEzfs.js" as="script"><link rel="prefetch" href="/assets/index.html-BA4Fp4vV.js" as="script"><link rel="prefetch" href="/assets/index.html-mYavIapQ.js" as="script"><link rel="prefetch" href="/assets/index.html-COCraTji.js" as="script"><link rel="prefetch" href="/assets/index.html-D2ThWCet.js" as="script"><link rel="prefetch" href="/assets/index.html-DaP9upC4.js" as="script"><link rel="prefetch" href="/assets/index.html-BIDlCWzz.js" as="script"><link rel="prefetch" href="/assets/index.html-BXrUalCa.js" as="script"><link rel="prefetch" href="/assets/index.html-DNGpJ6Ge.js" as="script"><link rel="prefetch" href="/assets/index.html-B0FAAJiH.js" as="script"><link rel="prefetch" href="/assets/index.html-PtShpXcj.js" as="script"><link rel="prefetch" href="/assets/index.html-C-6g6-2M.js" as="script"><link rel="prefetch" href="/assets/index.html-DWEKowDr.js" as="script"><link rel="prefetch" href="/assets/index.html-CfWldkVZ.js" as="script"><link rel="prefetch" href="/assets/index.html-DZw-fmg3.js" as="script"><link rel="prefetch" href="/assets/index.html-Dr4HWio7.js" as="script"><link rel="prefetch" href="/assets/index.html-CKv4Bk1L.js" as="script"><link rel="prefetch" href="/assets/index.html-3KPpCg6h.js" as="script"><link rel="prefetch" href="/assets/index.html-1mstDZ3_.js" as="script"><link rel="prefetch" href="/assets/index.html-Du_kFe4D.js" as="script"><link rel="prefetch" href="/assets/index.html-b_OIUjUv.js" as="script"><link rel="prefetch" href="/assets/index.html-Dvm83MRw.js" as="script"><link rel="prefetch" href="/assets/index.html-BCNR2zTc.js" as="script"><link rel="prefetch" href="/assets/index.html-C7oLbglm.js" as="script"><link rel="prefetch" href="/assets/flowchart-CAFN9Lqb.js" as="script"><link rel="prefetch" href="/assets/mermaid.esm.min-Ccs_en86.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CMg0yb1C.js" as="script"><link rel="prefetch" href="/assets/browser-CYdOP0d3.js" as="script"><link rel="prefetch" href="/assets/SearchResult-C7Jx2tmp.js" as="script"><link rel="prefetch" href="/assets/setupDevtools-7MC2TMWH-Bn-9v1Gv.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="博客主页" iconsizing="height"><!--[--><i class="vp-icon fas fa-home" sizing="height"></i><!--]-->博客主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link route-link-active auto-link" href="/blog/" aria-label="个人博客" iconsizing="height"><!--[--><i class="vp-icon fas fa-blog" sizing="height"></i><!--]-->个人博客<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="关于"><!--[--><i class="vp-icon fas fa-user-plus" sizing="height"></i>关于<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/intro.html" aria-label="关于我" iconsizing="both"><!--[--><i class="vp-icon fas fa-user fa-fw" sizing="both"></i><!--]-->关于我<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/about.html" aria-label="关于本站" iconsizing="both"><!--[--><i class="vp-icon fas fa-circle-info fa-fw" sizing="both"></i><!--]-->关于本站<!----></a></li></ul></button></div></div></nav><!--]--></div><div class="vp-navbar-center"><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://blog.csdn.net/LuohenYJ" target="_blank" title="开往我的csdn" rel="noopener noreferrer" aria-label="travelling"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" fill="currentColor" style="width:1.25rem;height:1.25rem;vertical-align:middle"><path d="M658.836 519.32c-22.121 0-40.145 18.431-40.145 40.957 0 22.528 18.023 40.962 40.145 40.962 22.117 0 40.141-18.434 40.141-40.962 0-22.526-18.024-40.957-40.141-40.957zM364.742 519.32c-22.121 0-40.141 18.431-40.141 40.957 0.41 22.528 18.02 40.962 40.141 40.962 22.117 0 40.141-18.434 40.141-40.962 0-22.526-18.024-40.957-40.141-40.957z" p-id="8700"></path><path d="M512 0C229.23 0 0 229.23 0 512s229.23 512 512 512 512-229.23 512-512S794.77 0 512 0z m133.727 804.81c0 7.375-6.145 13.52-13.516 13.52H391.773c-7.371 0-13.515-6.145-13.515-13.52v-13.516c0-7.371 6.144-13.517 13.515-13.517h240.438c7.371 0 13.516 6.146 13.516 13.517v13.516z m120.832 37.273c-12.289 6.965-27.441 2.867-34.406-9.418l-54.887-96.668c-4.504 0.82-9.422 1.23-13.926 1.23H361.054c-4.914 0-9.421-0.41-13.925-1.23l-54.887 96.668c-6.965 12.285-22.527 16.383-34.406 9.418-12.289-6.961-16.383-22.938-9.422-35.223l51.199-90.113c-27.031-19.66-43.418-52.43-40.957-88.883l19.25-293.273c3.277-49.152 34.406-88.066 87.246-88.066h80.281c0-37.684 29.899-67.993 66.762-67.993 36.868 0 66.766 30.309 66.766 67.993h93.391c53.246 0 70.449 38.914 73.727 88.066l19.25 293.273c2.461 36.453-13.926 69.223-40.957 88.883l51.199 90.113c6.964 12.696 2.867 28.262-9.012 35.223z" p-id="8701"></path><path d="M672.352 314.931H351.633c-14.747 0-26.622 12.285-26.622 27.441v108.953c0 15.157 11.875 27.446 26.622 27.446h320.719c14.746 0 26.625-12.289 26.625-27.446V342.372c0-15.156-11.879-27.441-26.625-27.441z" p-id="8702"></svg></a></div><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/luohenyueji" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-outlook-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon" name="outlook"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="vp-outlook-dropdown"><!----></div></button></div><!--[--><button type="button" class="slimsearch-button" aria-label="搜索"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="slimsearch-placeholder">搜索</div><div class="slimsearch-key-hints"><kbd class="slimsearch-key">Ctrl</kbd><kbd class="slimsearch-key">K</kbd></div></button><!--]--><!--]--></div><div class="vp-navbar-end"><!--[--><a class="route-link vp-brand" href="/" aria-label="带我回家"><img class="vp-nav-logo" src="/logo.png" alt><!----><span class="vp-site-name hide-in-pad">落痕月极的博客</span></a><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="博客主页" iconsizing="both"><!--[--><i class="vp-icon fas fa-home fa-fw" sizing="both"></i><!--]-->博客主页<!----></a></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><i class="vp-icon fas fa-blog fa-fw" sizing="both"></i><span class="vp-sidebar-title">博客</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">编程基础</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">常用工具</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">机器学习</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">讲座论坛</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">论文总结</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">能源化工与仪器科学</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">深度学习</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">大模型</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/2024-12-31-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html" aria-label="[深度学习] 大模型学习1-大语言模型基础知识" iconsizing="both"><!---->[深度学习] 大模型学习1-大语言模型基础知识<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/2025-02-28-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A02-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8C%97.html" aria-label="[深度学习] 大模型学习2-提示词工程指北" iconsizing="both"><!---->[深度学习] 大模型学习2-提示词工程指北<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/2025-07-21-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03%E4%B8%8A-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83.html" aria-label="[深度学习] 大模型学习3上-模型训练与微调" iconsizing="both"><!---->[深度学习] 大模型学习3上-模型训练与微调<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/2025-07-23-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03%E4%B8%8B-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83.html" aria-label="[深度学习] 大模型学习3下-模型训练与微调" iconsizing="both"><!---->[深度学习] 大模型学习3下-模型训练与微调<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/2025-08-08-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A04-RAG%E6%8A%80%E6%9C%AF%E5%85%A8%E6%99%AF%E8%A7%A3%E6%9E%90.html" aria-label="[深度学习] 大模型学习4-RAG技术全景解析" iconsizing="both"><!---->[深度学习] 大模型学习4-RAG技术全景解析<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/2025-10-01-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A05-%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83%E6%A1%86%E6%9E%B6Unsloth%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8C%97.html" aria-label="[深度学习] 大模型学习5-高效微调框架Unsloth使用指北" iconsizing="both"><!---->[深度学习] 大模型学习5-高效微调框架Unsloth使用指北<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">深度学习笔记</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">数据分析与可视化</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">数学理论</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">随笔所想</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">图像处理</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">音视频处理</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">自然语言处理与语音识别</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">OpenCV</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Python</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">R语言</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->[深度学习] 大模型学习3上-模型训练与微调</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="/" target="_blank" rel="noopener noreferrer">落痕月极</a></span><span property="author" content="落痕月极"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025年7月22日</span><meta property="datePublished" content="2025-07-21T20:28:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 31 分钟</span><meta property="timeRequired" content="PT31M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color4 clickable" role="navigation">深度学习</span><!--]--><meta property="articleSection" content="深度学习"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color4 clickable" role="navigation">深度学习</span><span class="page-tag-item color2 clickable" role="navigation">自然语言处理与语音识别</span><!--]--><meta property="keywords" content="深度学习,自然语言处理与语音识别"></span></div><hr></div><div class="vp-toc-placeholder"><aside id="toc" vp-toc><!----><!--[--><div class="vp-toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_1-大语言模型概览">1 大语言模型概览</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-1-深度学习模型概览">1.1 深度学习模型概览</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-2-大语言模型训练方式概览">1.2 大语言模型训练方式概览</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-3-大语言模型推理的一般过程">1.3 大语言模型推理的一般过程</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_2-大语言模型结构介绍">2 大语言模型结构介绍</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-1-transformer结构">2.1 Transformer结构</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-2-大语言模型基础结构介绍">2.2 大语言模型基础结构介绍</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_4-参考">4 参考</a></li><!----><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!--]--><!----></aside></div><!----><div class="theme-hope-content" vp-content><h1 id="深度学习-大模型学习3上-模型训练与微调" tabindex="-1"><a class="header-anchor" href="#深度学习-大模型学习3上-模型训练与微调"><span>[深度学习] 大模型学习3上-模型训练与微调</span></a></h1><p>在文章<a href="https://blog.csdn.net/LuohenYJ/article/details/144858528" target="_blank" rel="noopener noreferrer">大语言模型基础知识</a>里，模型训练与微调作为大语言模型（Large Language Model，LLM）应用构建的主要方式被简要提及，本系列文章将从技术原理、实施流程及应用场景等维度展开深度解析。相关知识的进一步参考见：<a href="https://modelscope.cn/learn/399?pid=342" target="_blank" rel="noopener noreferrer">LLM训练理论和实战</a>。本文作为系列的上半部分，内容涵盖第1章大语言模型概览和第2章大语言模型结构介绍。下半部分将聚焦于大语言模型的构建实践。</p><h2 id="_1-大语言模型概览" tabindex="-1"><a class="header-anchor" href="#_1-大语言模型概览"><span>1 大语言模型概览</span></a></h2><h3 id="_1-1-深度学习模型概览" tabindex="-1"><a class="header-anchor" href="#_1-1-深度学习模型概览"><span>1.1 深度学习模型概览</span></a></h3><h4 id="_1-1-1-什么是模型" tabindex="-1"><a class="header-anchor" href="#_1-1-1-什么是模型"><span>1.1.1 什么是模型</span></a></h4><p>在深度学习领域，模型是一个核心概念。它本质上是由大量数学公式构成的计算系统，虽然听起来复杂，但我们可以通过一个简化的比喻来理解它的基本原理。更通俗易懂的解释可参考：<a href="https://zhuanlan.zhihu.com/p/61492295" target="_blank" rel="noopener noreferrer">深入浅出地理解神经网络</a>。</p><p><strong>线性模型</strong></p><p>假设你有一个<strong>魔法盒子</strong>，它能根据输入的数字生成新的数字。最初的盒子遵循简单规则：&quot;将输入数字乘以1，再加上1&quot;，用数学公式表示即为线性模型：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">y </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">*</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">x </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这个过程类似模型的<strong>推理阶段</strong>：</p><ul><li>输入1时：<code>y = 1×1 + 1 = 2</code></li><li>输入2时：<code>y = 1×2 + 1 = 3</code></li></ul><p><strong>线性模型的局限性</strong></p><p>这种魔法盒子，也就是简单的线性模型只能做简单的运算，遇到复杂问题就会卡壳。例如提问&quot;安徽的省会城市是哪里？&quot;，它无法处理的原因在于：</p><ol><li>输入单一：仅能处理数值计算，无法理解文本、图像等复杂信息；</li><li>规则僵化：公式逻辑固定，无法学习非线性的复杂关系（如&quot;城市-属性&quot;的映射）。</li></ol><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习3-模型训练与微调/img/img00.jpg" alt="https://medium.com/data-science-at-microsoft/how-large-language-models-work-91c362f5b78f" tabindex="0" loading="lazy"><figcaption>https://medium.com/data-science-at-microsoft/how-large-language-models-work-91c362f5b78f</figcaption></figure><p><strong>复杂模型</strong></p><p>为了让魔法盒子具备&quot;理解复杂问题&quot;的能力，需要引入<strong>非线性变换</strong>。这种方式即在原来的公式后面加上一个特殊的 &quot;开关&quot;，这个开关可以把直线变成曲线。用符号<code>σ</code>表示：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">y </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> σ</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">*</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">x </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这个曲线有什么用呢？它可以让魔法盒子&quot;理解&quot;复杂的问题。比如：</p><ul><li>当输入x很小时，输出y几乎是0;</li><li>当输入x很大时，输出y几乎是1;</li><li>当输入x在中间时，输出y会从0慢慢变成1。</li></ul><p>这种特性让魔法盒子可以学习到 &quot;阈值&quot; 的概念。它让简单的盒子变得更加智能，能够处理复杂的问题！比如：</p><ul><li>当学习时间很短时，成绩几乎没有提高;</li><li>当学习时间足够长时，成绩会快速提高;</li><li>当学习时间已经很长时，再增加时间对成绩的提升就很小了。</li></ul><p>通过这种单一非线性变换可拟合简单的分段规律（如学习时间与成绩的关系），而多层非线性变换（如深度神经网络）可通过叠加多个 &quot;开关&quot;，拟合任意复杂的函数关系（如图像中的边缘识别、语音中的语义理解等）。大语言模型（如GPT-4）则由数千亿个神经元相互连接构成。</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习3-模型训练与微调/img/img01.jpg" alt="https://link.springer.com/article/10.1007/s10845-022-01963-8" tabindex="0" loading="lazy"><figcaption>https://link.springer.com/article/10.1007/s10845-022-01963-8</figcaption></figure><h4 id="_1-1-2-模型训练的原理" tabindex="-1"><a class="header-anchor" href="#_1-1-2-模型训练的原理"><span>1.1.2 模型训练的原理</span></a></h4><p>模型的学习过程可类比学生备考，分为三个核心步骤：</p><ol><li><p>喂数据：海量题库输入<br> 提供大量&quot;问题-答案&quot;对，例如：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">训练数据：</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  {</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;问题&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;安徽的省会城市是哪里?&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;答案&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;合肥&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">},</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  {</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;问题&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;23+20等于多少？&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;答案&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;43&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">},</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  {</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;问题&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;苹果的英文?&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;答案&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;apple&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>调参数 模型用当前参数预测答案，若出错（如把&quot;合肥&quot;猜成&quot;南京&quot;），就通过<strong>梯度下降算法</strong>调整参数，类似走山路时根据坡度（梯度）调整方向，逐步找到误差最小的&quot;最低点&quot;。 这一过程在数学中被称为拟合。</p></li><li><p>反复练习：百万次迭代优化 经过数百万次训练，模型能从&quot;死记硬背&quot;进化到&quot;举一反三&quot;。学会&quot;合肥是安徽的省会&quot;后，能推理出&quot;安徽的省会是合肥&quot;。</p></li></ol><p>更多相关资料可参考<a href="https://blog.csdn.net/qq_51580006/article/details/147456916" target="_blank" rel="noopener noreferrer">自然语言处理的深度学习模型综述</a>。人类思维与模型工作机制对比如下：</p><table><thead><tr><th>人类思维过程</th><th>模型工作机制</th></tr></thead><tbody><tr><td>用眼睛看到&quot;苹果&quot; → 视网膜成像</td><td>输入层将图像转为像素级数字向量（如3×224×224的矩阵）</td></tr><tr><td>大脑皮层识别形状 → 提取轮廓特征</td><td>模型内部通过非线性变换（如卷积）提取边缘、颜色等特征</td></tr><tr><td>记忆中搜索&quot;苹果&quot;的含义 → 关联知识库</td><td>权重参数存储知识（如&quot;苹果=apple&quot;的映射关系）</td></tr><tr><td>说出&quot;apple&quot; → 声带肌肉协调输出</td><td>输出层将抽象特征转化为文本序列（如&quot;a&quot;,&quot;p&quot;,&quot;p&quot;,&quot;l&quot;,&quot;e&quot;）</td></tr></tbody></table><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习3-模型训练与微调/img/img02.jpg" alt="https://datascientest.com/en/natural-language-processing-definition-and-principles" tabindex="0" loading="lazy"><figcaption>https://datascientest.com/en/natural-language-processing-definition-and-principles</figcaption></figure><h3 id="_1-2-大语言模型训练方式概览" tabindex="-1"><a class="header-anchor" href="#_1-2-大语言模型训练方式概览"><span>1.2 大语言模型训练方式概览</span></a></h3><h4 id="_1-2-1-模型预训练与微调的一般过程" tabindex="-1"><a class="header-anchor" href="#_1-2-1-模型预训练与微调的一般过程"><span>1.2.1 模型预训练与微调的一般过程</span></a></h4><p>上述模型训练范式基于输入输出数据对驱动模型学习，属于经典的有监督学习方法。其核心是依赖预先标注的输出数据，通过构建输入与输出的映射关系，引导模型参数优化，以实现预期的预测性能。</p><p>随着互联网技术的快速发展，数据规模呈爆炸式增长，尤其是文本数据具有海量、易获取的特点。在此背景下，自监督学习范式应运而生并逐渐发展。自监督学习打破了有监督学习对标注数据的依赖，仅需输入数据即可进行模型训练。它借助大规模无标注文本数据，通过设计掩码语言建模、句子顺序预测等自监督任务，使模型从数据中挖掘潜在结构和规律，实现有效的特征学习。</p><p>在实际应用中，大语言模型普遍采用预训练和微调的两阶段训练策略。这一策略的灵感可类比于人类的学习过程：首先，通过广泛阅读各类书籍，构建起通用的语言理解能力和知识体系；随后，针对特定学科进行专项训练，以深化对特定领域知识的掌握。</p><p>具体到大语言模型，在预训练阶段，模型会在海量互联网文本上进行无监督学习，捕捉语言的语法、语义、句法等通用规律，进而具备强大的语言表征能力。在微调阶段，则利用特定领域的标注数据对预训练模型进行针对性调整，使模型能够快速适应特定任务需求。关于大语言模型的更进一步理解，详见：<a href="https://zhuanlan.zhihu.com/p/27724018379" target="_blank" rel="noopener noreferrer">轻松理解大模型</a>。</p><h4 id="_1-2-2-大语言模型训练流程概览" tabindex="-1"><a class="header-anchor" href="#_1-2-2-大语言模型训练流程概览"><span>1.2.2 大语言模型训练流程概览</span></a></h4><p>前文提到的模型训练分为预训练和微调两个阶段，但实际大语言模型的训练流程更为复杂。这种复杂性源于现实训练数据的多样性，通常可分为以下三类：</p><ol><li><p>第一组（未标注答案的数据，无监督数据）：</p><ul><li>样本特征：原始文本语料，无人工标注</li><li>示例： <ul><li>自然语言文本：&quot;白日依山尽，黄河入海流&quot;</li><li>日常对话：&quot;今天我看了电影&quot;</li><li>社交语境：&quot;我和她一起吃饭&quot;</li></ul></li></ul></li><li><p>第二组（已标注问题与答案的数据，监督数据）：</p><ul><li>样本特征：包含人工构造的输入-输出对</li><li>示例： <ul><li>问答对： 问：如何保持健康的生活习惯？ 答：规律作息结合均衡饮食</li></ul><ul><li>解题指导： 问：计算正方形周长的公式是？A. 边长×4；B. 边长×边长 答：A</li></ul></li></ul></li><li><p>第三组（包含正确与错误答案的数据，对比数据）：</p><ul><li>道德决策，发现他人遇到危险时该怎么做？ <ul><li>正确答案：立即拨打急救电话并寻求专业帮助</li><li>错误答案：围观拍照而不采取行动</li></ul></li><li>数字伦理：如何合理使用网络资源？ <ul><li>正确答案：遵守网络礼仪，尊重知识产权</li><li>错误答案：未经授权转载他人原创内容</li><li>错误答案：随意转发</li></ul></li></ul></li></ol><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习3-模型训练与微调/img/img03.jpg" alt="https://docs.v1.argilla.io/en/v1.26.0/conceptual_guides/llm/rlhf.html" tabindex="0" loading="lazy"><figcaption>https://docs.v1.argilla.io/en/v1.26.0/conceptual_guides/llm/rlhf.html</figcaption></figure><p>这三类数据对应大语言模型训练的不同范式，按训练流程顺序分为：</p><ol><li>预训练阶段</li></ol><ul><li>数据：常见的无监督数据</li><li>方法：自监督学习（如掩码语言建模）</li><li>目标：让大语言模型掌握语言的统计规律、语法结构和基础语义理解能力，形成通用的语言表示能力</li><li>计算需求：通常需要数千张GPU，处理TB级数据</li></ul><ol start="2"><li>微调阶段</li></ol><ul><li>数据：较为稀缺的监督数据</li><li>方法：指令微调</li><li>目标：使模型具备特定下游任务（如文本生成、分类等）的精确执行能力</li><li>计算需求：根据数据规模（从千级到千万级样本）需数十至数百张GPU</li></ul><ol start="3"><li>人类对齐阶段</li></ol><ul><li>数据：最为稀缺的对比数据</li><li>方法：基于人类反馈的强化学习</li><li>目标：建立价值对齐机制，确保输出符合安全性、无害性、有用性标准</li><li>计算需求：通常需要数百张至数千张GPU，技术门槛显著高于微调</li></ul><p>人类对齐通常包含奖励模型训练和强化学习优化两个阶段：</p><ul><li>在奖励建模阶段，通过人类对同一提示下多模型回复的优劣排序，训练能够自动评估任意提示与回复对的奖励模型，其输出分数反映回复符合人类偏好的程度</li><li>强化学习阶段以指令监督微调（Supervised Fine-Tuning，SFT）模型为初始策略，输入多样化新提示生成回复，再由奖励模型评分，最终通过强化学习算法引导 SFT 模型优化策略，使其生成高奖励值的回复</li></ul><p>类比于人类的语言学习，大语言模型的构建过程如下：</p><ul><li>预训练 → 语言能力筑基（如词汇掌握、语法构建）</li><li>监督微调 → 专项技能训练（如数学解题、文本摘要）</li><li>人类对齐 → 价值观校准（如伦理判断、风险规避）</li></ul><p>请注意，上述分类方式将奖励模型训练归入强化学习阶段，因为二者都服务于“人类偏好对齐”目标。但部分文章将该流程分为四个阶段，即将人类对齐拆分为奖励模型训练和强化学习两个独立阶段。</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习3-模型训练与微调/img/img04.jpg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>一般我们将经过预训练，或结合通用数据微调的模型称作基座模型（base model），其特点是具备基础的语言理解与生成能力，但通常未针对具体应用场景进行优化。经过人类对齐的模型则被称为对话模型（chat model），这类模型可直接用于通用问答，也可通过少量数据微调适配特定领域场景。</p><h3 id="_1-3-大语言模型推理的一般过程" tabindex="-1"><a class="header-anchor" href="#_1-3-大语言模型推理的一般过程"><span>1.3 大语言模型推理的一般过程</span></a></h3><p>在大语言模型模型的推理过程中，核心任务是将输入序列（如一个句子）转化为输出序列（如另一个句子）。以处理输入句子<code>早上喝咖啡</code>为例，其核心步骤涉及文本的数字化表示与语义建模：</p><ol><li><p>词元化与索引映射（建立词表）：</p><ul><li>首先需构建一个包含常用语言单元（字、词或子词）的词表（Vocabulary），并为每个单元分配唯一索引。例如，一个30,000词的词表中，“早”、“上”、“喝”、“咖啡”可能分别对应索引 <code>[15, 28, 102, 3567]</code></li><li>类比理解：这类似于查阅字典时，每个词条对应一个唯一的页码编号和释义。词表索引相当于“页码”，而后续步骤将赋予其丰富的“语义释义”</li></ul></li><li><p>低维索引→高维语义向量映射（词嵌入）：</p><ul><li>单纯的数字索引（如 <code>[15, 28, 102, 3567]</code>）维度低且缺乏语义信息。模型通过<strong>词嵌入层（Embedding Layer）</strong> 将每个索引转换为稠密的高维向量（如1024维）</li><li><strong>示例转换：</strong><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">15</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">28</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">102</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">3567</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 原始词元索引</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">↓ 词嵌入层</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  [</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.21</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.05</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.87</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.33</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">],  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># “早”的1024维语义向量</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  [</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.45</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.12</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.91</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.18</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">],  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># “上”的1024维语义向量</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  [</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.32</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.76</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.04</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.55</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># “喝”的的1024维语义向量</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  [</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.67</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.22</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.11</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.79</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]   </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># “咖啡”的1024维语义向量</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 形成 4x1024 的语义矩阵</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li>这些高维向量（称为<strong>词嵌入</strong>）通过数值分布编码丰富的语义和语法关系（如“咖啡”与“茶”的向量距离通常比“咖啡”与“跑步”更近），是深度语言模型理解文本的基础</li></ul></li><li><p>语义建模与概率分布生成：</p><ul><li>获得词嵌入矩阵后，模型通过复杂的神经网络架构（如Transformer的注意力机制、多层感知机）进行深度计算</li><li>最终输出层产生一个维度与词表大小（30,000）匹配的向量，每个位置对应词表中一个词元的未归一化得分（logits）<div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2.1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1.5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">5.8</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.7</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1.2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 30,000个logits</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li><li>为了生成可读的输出，模型应用Softmax函数 将这些logits转换为概率分布： <ul><li>Softmax确保所有输出值在(0,1)区间内，且总和为1</li><li>选择概率最高的索引（如索引<code>735</code>对应“很”），通过词表反查得到输出词元</li></ul></li><li>示例推理：输入“早上喝咖啡”，模型可能输出概率最高的词元是“很”，形成“早上喝咖啡很”</li></ul></li><li><p>自回归生成：序列的迭代生成</p><ul><li>上述步骤仅生成单个词元。生成完整序列（如“早上喝咖啡很提神”）采用自回归（Autoregressive）方式： <ol><li>输入扩展：将上一步生成的词元（如“很”）拼接到当前输入末尾，形成新输入序列“早上喝咖啡很”</li><li>迭代计算：将新序列输入模型，预测下一个词元的概率分布（如可能输出“提”）</li><li>终止条件：重复步骤2-3，直至模型生成特定的结束符（如 <code>&lt;eos&gt;</code>）</li></ol></li><li>类比理解：此过程类似于“传话游戏”，每次基于已生成的全部内容预测下一个最可能的词，直至传达结束信号</li></ul></li></ol><p>上述描述聚焦于模型的推理过程（即根据输入生成输出）。相比之下，模型的训练过程是：给定一个输入序列及其对应的目标序列（如下一个词或整个后续句子），通过调整模型参数，使模型预测目标序列的概率最大化。在训练数据中，<code>&lt;eos&gt;</code>等特殊标记也会被放置在句子末尾，以便模型学习识别序列结束的位置。关于大语言模型推理过程的详细介绍，可参见：<a href="https://zhuanlan.zhihu.com/p/23556533098" target="_blank" rel="noopener noreferrer">图解大模型的推理</a>。</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习3-模型训练与微调/img/img05.jpg" alt="https://blog.epsilla.com/unlocking-the-magic-of-large-language-models-llms-how-ai-understands-and-generates-text-3de89ccbb210" tabindex="0" loading="lazy"><figcaption>https://blog.epsilla.com/unlocking-the-magic-of-large-language-models-llms-how-ai-understands-and-generates-text-3de89ccbb210</figcaption></figure><h2 id="_2-大语言模型结构介绍" tabindex="-1"><a class="header-anchor" href="#_2-大语言模型结构介绍"><span>2 大语言模型结构介绍</span></a></h2><h3 id="_2-1-transformer结构" tabindex="-1"><a class="header-anchor" href="#_2-1-transformer结构"><span>2.1 Transformer结构</span></a></h3><h4 id="_2-1-1-注意力机制" tabindex="-1"><a class="header-anchor" href="#_2-1-1-注意力机制"><span>2.1.1 注意力机制</span></a></h4><p>在2017年之后，Transformer结构模型几乎横扫一切统治了NLP领域，后面的CV领域和Audio领域也大放异彩。</p><p>注意力机制的本质是模拟人类的选择性关注。想象你在嘈杂的咖啡馆里和朋友聊天：周围有音乐声、餐具碰撞声、其他人的谈话声，但你的大脑会自动聚焦在朋友的话语上，忽略其他无关信息。这种聚焦重要信息、过滤次要信息的能力，就是注意力机制的核心思想。</p><p>在自然语言处理中（比如翻译句子），传统模型可能逐字处理信息，难以区分词的重要性。而注意力机制让模型能计算句子中每个词（作为查询）与其他所有词（作为键）的「相关性分数」（注意力分数），给关键信息更高的关注度。举个例子：翻译句子I love Paris, the capital of France时，模型处理Paris时，会通过注意力机制关注到France，因为它们语义关联紧密，从而更准确地翻译出巴黎是法国的首都。</p><p>Transformer的自注意力机制具体实现如下：</p><ol><li>每个词的输入向量会通过三个不同的线性变换，生成对应的查询向量（Query）、键向量（Key）和值向量（Value）： <ul><li>Query：用来询问其他词是否重要</li><li>Key：用来查询自己是否值得被关注</li><li>Value：词本身的信息</li></ul></li><li>计算注意力分数，即相似度（关注度）： <ul><li>使用当前词的Query向量与序列中所有词的Key向量计算点积，得到原始注意力分数。结果越大说明关联越强（类似你和朋友说话时，对方的关键词会吸引你的注意力）</li></ul></li><li>加权求和： <ul><li>对原始注意力分数应用softmax函数进行归一化，得到和为1的注意力权重。用此权重对序列中所有词的Value向量进行加权求和，得到当前词的输出向量。该向量融合了全局信息，但重点突出相关信息（关注度高的词贡献更大）</li></ul></li><li>多层堆叠： <ul><li>多个包含自注意力机制和前馈神经网络的 Transformer 层依次堆叠。每一层的输出作为下一层的输入。通过多层处理，向量序列逐步提取并融合更复杂、更抽象的语义信息</li></ul></li></ol><p>为何大语言模型普遍采用Transformer？，对比CNN和LSTM主要以下区别:</p><ol><li><p>CNN:</p><ul><li>优势/原因: 强归纳偏置（局部连接、平移不变性）→ 擅长捕捉局部特征，小数据高效</li><li>劣势/被取代原因: 难以建模长距离全局依赖 → 在大数据/复杂任务下成为瓶颈，性能被 Transformer 超越</li></ul></li><li><p>LSTM/RNN:</p><ul><li>优势/原因: 专为序列设计，能处理顺序信息</li><li>劣势/被取代原因: <ul><li>存在长程依赖问题（早期信息易丢失）</li><li>本质串行计算 → 训练效率极低，无法充分利用现代硬件并行能力，阻碍模型规模化</li></ul></li></ul></li><li><p>Transformer:</p><ul><li>前提/原因: 弱归纳偏置 → 依赖海量数据才能发挥优势</li><li>核心优势/被采用原因: <ul><li>强大的并行计算： 自注意力层可完全并行 → 极大加速训练和推理</li><li>优秀的可扩展性： 结构规整 → 天然适合分布式训练和超大模型</li><li>全局注意力机制： 直接建模序列中任意元素间的长距离依赖关系</li><li>位置编码： 有效注入序列顺序信息，弥补注意力自身的位置不敏感性</li></ul></li></ul></li></ol><p>在大数据与强大算力的支撑下，Transformer凭借极高的训练效率和强大的全局建模能力（即注意力机制），克服了CNN在全局依赖建模上的短板以及LSTM的串行计算瓶颈，成为构建超大规模语言模型的最优架构。关于注意力机制的更详细介绍，可参见：<a href="https://zhuanlan.zhihu.com/p/1904841905101078831" target="_blank" rel="noopener noreferrer">Transform的注意力机制</a>。</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习3-模型训练与微调/img/img06.gif" alt="https://www.byhand.ai/p/8-can-you-calculate-a-transformer" tabindex="0" loading="lazy"><figcaption>https://www.byhand.ai/p/8-can-you-calculate-a-transformer</figcaption></figure><h4 id="_2-1-2-transformer结构介绍" tabindex="-1"><a class="header-anchor" href="#_2-1-2-transformer结构介绍"><span>2.1.2 Transformer结构介绍</span></a></h4><p><strong>编码器和解码器</strong></p><p>Transformer核心由编码器（Encoder）和解码器（Decoder） 两部分组成。Transformer结构的具体介绍见：<a href="https://poloclub.github.io/transformer-explainer/" target="_blank" rel="noopener noreferrer">transformer-explainer</a>。</p><p>编码器（Encoder）的作用：信息的“理解者”</p><ul><li>核心目标： 将输入的信息理解并转化为机器能处理的语义向量。这个向量包含了输入内容的整体含义</li><li>工作流程（类比“翻译前的准备”）： <ul><li>第一步：分词与编码 输入句子（如“我喜欢苹果”）首先被拆分成词元（如“我”、“喜欢”、“苹果”），然后转化为机器可识别的数字编码（例如，通过嵌入层将词元映射为稠密向量）</li><li>第二步：位置编码（Positional Encoding） 由于词语的顺序至关重要（例如“苹果喜欢我”与原句意思截然不同），位置编码会给每个词元添加其在句子中位置的信息（类似于为每个单词标记序号）</li><li>第三步：自注意力机制（Self-Attention） 让模型学习“哪些词元之间是相关的”。例如，在处理“我喜欢苹果”时，模型会计算“我”与“喜欢”、“喜欢”与“苹果”之间的关联强度，就像人在阅读时会自然地将主语、谓语、宾语联系起来</li><li>第四步：前馈神经网络（Feed Forward Network） 对经过自注意力处理的信息进行进一步加工和非线性变换，强化关键语义（例如突出“喜欢”这个动作），最终输出一个代表整句话含义的“语义向量”</li></ul></li></ul><p>解码器 (Decoder)：信息的 “生成者”。</p><ul><li><p>核心目标 根据编码器输出的 “语义向量”，逐步生成目标内容（如翻译成另一种语言的句子）</p></li><li><p>工作流程 (按时间步 <code>t</code> 分解)：</p><ol><li><p>初始化 (时间步 <code>t=1</code>):</p><ul><li>输入 1 (解码器自身输入): 起始标记 <code>&lt;start&gt;</code> + 对应的位置编码</li><li>输入 2 (外部上下文)：编码器输出的完整语义向量 (Encoder Output)</li><li>处理: <ul><li>解码器首先对 <code>&lt;start&gt;</code> + 位置编码进行掩码自注意力 (Masked Self-Attention)。因为是第一步，只有 <code>&lt;start&gt;</code> 自己，掩码确保它只能关注自己（无未来信息可掩蔽）</li><li>然后进行交叉注意力 (Cross-Attention)：将掩码自注意力层的输出作为 <em>Query</em>，将 <em>Encoder Output</em> 同时作为 <em>Key</em> 和 <em>Value</em>。这允许解码器聚焦于输入序列中与生成第一个目标词最相关的部分</li><li>交叉注意力的输出经过前馈神经网络 (FFN)</li><li>FFN 的输出送入输出层 (线性层 + Softmax)，生成一个概率分布，预测第一个目标词 (如翻译中的 &quot;I&quot;)</li></ul></li><li>输出: 预测出的第一个词 <code>Y₁</code> (&quot;I&quot;)</li></ul></li><li><p>后续时间步 (<code>t=2, 3, ..., T</code>):</p><ul><li>输入 1 (解码器自身输入):之前所有已生成的词 (<code>&lt;start&gt;</code>, <code>Y₁</code>, <code>Y₂</code>, ..., <code>Y_{t-1}</code>) + 对应的位置编码。这就是所谓的&quot;自回归&quot;：把上一步的输出作为下一步输入的一部分</li><li>输入 2 (外部上下文): 编码器输出的完整语义向量 (Encoder Output)。(与 <code>t=1</code> 时相同，在整个解码过程中保持不变)</li><li>处理: <ul><li>掩码自注意力 (Masked Self-Attention): 对当前输入序列 (<code>&lt;start&gt;</code>, <code>Y₁</code>, ..., <code>Y_{t-1}</code> + 位置编码) 进行处理。关键：掩码 (<code>Look-Ahead Mask</code>) 在此阶段严格生效。 当计算位置 <code>t</code> 的表示时，掩码会阻止模型“看到”位置 <code>t</code> 及之后的所有位置（即未来的词）。它只能关注 <code>&lt;start&gt;</code> 和 <code>Y₁</code> 到 <code>Y_{t-1}</code> 这些已经生成出来的词。这确保了生成过程的因果性</li><li>交叉注意力 (Cross-Attention): 将掩码自注意力层的输出作为 <em>Query</em>，将 <em>Encoder Output</em> 作为 <em>Key</em> 和 <em>Value</em>。这一步是解码器的核心。它让解码器在考虑当前已生成的目标序列上下文 (<code>Query</code>) 的同时，动态地、有选择性地去“回顾”和“查询”编码器提供的源序列信息 (<code>Key/Value</code>)</li><li>交叉注意力的输出经过前馈神经网络 (FFN)</li><li>FFN 的输出送入输出层 (线性层 + Softmax)，生成一个概率分布，预测当前时间步 <code>t</code> 的目标词 <code>Y_t</code> (例如 <code>t=2</code> 时预测 &quot;like&quot;，<code>t=3</code> 时预测 &quot;apple&quot;)</li></ul></li><li>输出: 预测出的当前词 <code>Y_t</code></li></ul></li><li><p>终止条件:</p><ul><li>重复步骤 2，将新预测出的词 <code>Y_t</code> 加入到输入序列中，预测下一个词 <code>Y_{t+1}</code></li><li>这个过程一直持续，直到输出层预测出结束标记 <code>&lt;end&gt;</code>，或者达到预设的最大生成长度</li></ul></li></ol></li></ul><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习3-模型训练与微调/img/img07.jpg" alt="https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452/" tabindex="0" loading="lazy"><figcaption>https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452/</figcaption></figure><p>假设我们要将英语句子 &quot;I like apple&quot; 翻译成中文 &quot;我喜欢苹果&quot;。下面是 Transformer 解码器的工作流程：</p><ol><li><p>初始化 (t=1)</p><ul><li>输入 1：<code>&lt;start&gt;</code> + 位置编码（表示这是序列的第一个位置）</li><li>输入 2：编码器输出的语义向量（包含 &quot;I like apple&quot; 的完整信息）</li><li>处理： <ul><li>掩码自注意力：<code>&lt;start&gt;</code> 只能关注自己</li><li>交叉注意力：解码器查询编码器输出，发现最相关的是表示 &quot;I&quot; 的部分</li><li>FFN 和输出层：生成概率分布，预测第一个中文词 &quot;我&quot;</li></ul></li><li>输出：<code>Y₁</code> = &quot;我&quot;</li></ul></li><li><p>时间步 t=2</p><ul><li>输入 1：<code>&lt;start&gt;</code> + &quot;我&quot; + 对应的位置编码</li><li>输入 2：与 t=1 相同的编码器输出</li><li>处理： <ul><li>掩码自注意力：&quot;我&quot; 可以关注 <code>&lt;start&gt;</code>，但不能关注未来的词</li><li>交叉注意力：解码器根据已生成的 &quot;我&quot;，查询编码器输出中与 &quot;like&quot; 相关的部分</li><li>FFN 和输出层：预测第二个中文词 &quot;喜欢&quot;</li></ul></li><li>输出：<code>Y₂</code> = &quot;喜欢&quot;</li></ul></li><li><p>时间步 t=3</p><ul><li>输入 1：<code>&lt;start&gt;</code> + &quot;我&quot; + &quot;喜欢&quot; + 位置编码</li><li>输入 2：编码器输出</li><li>处理： <ul><li>掩码自注意力：&quot;喜欢&quot; 可以关注 <code>&lt;start&gt;</code> 和 &quot;我&quot;</li><li>交叉注意力：解码器根据 &quot;我喜欢&quot;，查询编码器输出中与 &quot;apple&quot; 相关的部分</li><li>FFN 和输出层：预测第三个中文词 &quot;苹果&quot;</li></ul></li><li>输出：<code>Y₃</code> = &quot;苹果&quot;</li></ul></li><li><p>时间步 t=4</p><ul><li>输入 1：<code>&lt;start&gt;</code> + &quot;我&quot; + &quot;喜欢&quot; + &quot;苹果&quot; + 位置编码</li><li>处理： <ul><li>掩码自注意力和交叉注意力处理整个序列</li><li>输出层：预测出结束标记 <code>&lt;end&gt;</code></li></ul></li><li>输出：<code>Y₄</code> = <code>&lt;end&gt;</code></li></ul></li></ol><p>结果：解码器生成的完整序列是 <code>我 喜欢 苹果 &lt;end&gt;</code>，成功完成了翻译任务。</p><p>编码器与解码器的配合：以机器翻译为例：</p><ol><li>编码器先“理解”原句： <ul><li>输入“我喜欢苹果”，输出一个包含其语义的向量。</li><li>编码器的作用类似于“读者”：它“读懂”输入语句，并将其核心含义浓缩成一个“含义包”。</li></ul></li><li>解码器根据语义“生成”译文： <ul><li>解码器接收这个语义向量，并逐个词地生成目标语言句子（如“I like apples”）。</li><li>在生成过程中，解码器会持续参考编码器提供的语义信息以及自身已生成的词语。</li><li>解码器的作用类似于“作者”：它基于“含义包”，用目标语言“写出”句子。在“写作”时，它需要一边思考前面已经“写”了什么（自回归），一边对照原句的语义。</li></ul></li></ol><p><strong>Transformer模型变体</strong></p><p>可以看出，Transformer这种编码器-解码器结构非常适合一类任务：这类任务需要借助编码器理解完整输入，并通过解码器生成完整输出。解码器中的掩码自注意力与交叉注意力是生成任务的核心。但该结构相对复杂，参数量较大，对于仅需理解输入（如分类任务）或仅需生成输出（如语言建模）的场景而言，部分结构显得冗余。因此，模型结构开始从Encoder-Decoder向单一结构演变。</p><ol><li>纯编码器模型（Encoder-only）</li></ol><ul><li>代表模型：BERT、RoBERTa</li><li>任务需求：主要用于语言理解任务，如文本分类、命名实体识别、情感分析、抽取式问答、自然语言推理等。这类任务的核心是对输入文本进行深度理解并做出判断或抽取特定信息，通常无需生成新的文本序列</li><li>结构：移除解码器简化了模型结构，通过双向自注意力机制（用于同时考虑该位置之前和之后的所有 token 信息）减少了参数量和计算量</li><li>缺陷： <ul><li>不适合生成任务：缺乏自回归生成机制和单向掩码自注意力，无法直接用于文本生成（如翻译、摘要、对话）</li><li>预训练任务限制：典型预训练任务（如MLM）是破坏输入再重建，而非预测下一个词，其学习目标与生成任务存在差异</li></ul></li><li>任务适应方式：基于编码器输出，通过在编码器顶部添加任务特定的输出层，并针对下游任务进行微调，实现对不同理解类任务的适配</li><li>任务执行流程（以文本分类为例） <ol><li>输入处理：将文本转换为token序列（如“这部电影很精彩”→[CLS, 这部，电影，很，精彩，SEP]），并添加位置编码和段编码（若有多个文本输入）</li><li>编码器层处理：通过多层双向自注意力和前馈神经网络，逐层融合全局上下文信息，生成每个token的语义向量</li><li>特征提取与预测：取特殊token[CLS]的向量作为整个文本的表征，输入分类层（如全连接层+Softmax），输出类别概率（如“积极”“消极”情感标签）</li></ol></li></ul><ol start="2"><li>纯解码器模型（Decoder-only）</li></ol><ul><li>代表模型：GPT系列、Llama系列等</li><li>任务需求：核心优势在于自回归文本生成，例如续写、创意写作、机器翻译、摘要生成、对话生成等</li><li>结构：移除编码器，仅保留解码器模块（保留或等效实现带掩码的自注意力），通过前文预测下一个token，天然适配文本生成场景</li><li>缺陷： <ul><li>单向上下文局限（标准模型）：标准带掩码的自注意力为单向（仅能关注左侧），对当前词的理解不如双向编码器全面。（注意：大语言模型通过极长上下文窗口和模型规模部分弥补了这一局限，理解能力随训练逐渐增强。）</li><li>生成时的计算效率问题：自回归生成需串行处理（逐词生成），无法像编码器那样并行处理整个输入序列，解码速度可能较慢</li><li>幻觉风险：强大的生成能力可能伴随生成事实性不准确但逻辑自洽内容的风险</li></ul></li><li>任务适应方式：通过提示工程或针对特定生成任务微调模型参数，实现对下游生成任务的适配，无需额外添加复杂结构</li><li>任务执行流程（以文本生成为例） <ol><li>初始输入：给定提示词（如“请写一首关于春天的诗：”），转换为token序列，作为生成的初始上下文</li><li>自回归生成循环： <ul><li>输入当前token序列，通过解码器层计算每个位置的编码向量（仅关注左侧上下文）。</li><li>对最后一个token的编码向量输入Softmax层，预测下一个token的概率分布（如“春”“天”“来”等），选择概率最高的token（或通过采样策略）添加到序列末尾</li><li>重复上述过程，直到生成结束符（如“[END]”）或达到最大长度</li></ul></li></ol></li></ul><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习3-模型训练与微调/img/img08.jpg" alt="https://arxiv.org/abs/2306.11489" tabindex="0" loading="lazy"><figcaption>https://arxiv.org/abs/2306.11489</figcaption></figure><p>总之，生成能力是大语言模型的核心能力。与完整的Encoder-Decoder结构相比，纯解码器结构更为简单，这不仅降低了设计的复杂性，还提高了效率。</p><p>纯编码器没有成为主流，主要是因为它存在生成能力缺失这一硬伤，同时通用性也有所不足：编码器模型通常需要针对特定的下游任务进行微调，缺乏纯解码器大语言模型那种仅通过提示就能解决众多任务的 “通用智能” 感。</p><p>不过，纯解码器结构的劣势也得到了弥补。在模型和数据规模不断扩大的过程中，纯解码器结构展现出了惊人的性能提升和涌现能力，借助规模优势，弥补了理论层面的理解劣势。与此同时，指令微调解锁了它的通用性，将其强大的生成基础能力转化为能够遵循指令、完成多样化任务的智能体。</p><p>关于这三种结构对比的详细内容，可参考：<a href="https://zhuanlan.zhihu.com/p/642923989" target="_blank" rel="noopener noreferrer">LLM的3种架构</a></p><h3 id="_2-2-大语言模型基础结构介绍" tabindex="-1"><a class="header-anchor" href="#_2-2-大语言模型基础结构介绍"><span>2.2 大语言模型基础结构介绍</span></a></h3><p>自GPT-3之后，OpenAI在其大语言模型的发展方向上转向了闭源策略，不再发布开源模型，例如GPT-3.5以及后续的GPT-4系列。因此，外界对于ChatGPT和GPT-4所采用的具体模型架构细节（如层数、隐藏层维度、注意力头数等）以及潜在的优化技术缺乏官方确认的清晰了解。在此背景下，Meta开源的大语言模型LLaMA系列成为了代表性的开源大语言模型。</p><p>LLaMA的整体架构依然基于Transformer解码器结构，但在具体实现细节上进行了多项关键改进：</p><ol><li>前置层归一化（Pre-Layer Normalization）：该策略旨在提高训练稳定性和收敛速度，缓解梯度问题</li><li>RMSNorm归一化函数：替代了原始的LayerNorm。RMSNorm仅使用均方根进行缩放，计算更简单高效，效果接近LayerNorm，同时降低了计算开销</li><li>SwiGLU激活函数：结合了门控机制和Swish激活函数的优势，被证明比标准ReLU或GeLU能提供更强的表达能力和性能，尤其在较大模型上</li><li>旋转位置编码（RoPE）：用于更有效地编码序列位置信息。RoPE将位置信息通过旋转操作融入键（Key）和查询（Query）向量的点积运算中，能更好地建模相对位置关系，且对序列长度具有外推性，优于传统的绝对或相对位置编码</li></ol><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习3-模型训练与微调/img/img09.jpg" alt="https://zhuanlan.zhihu.com/p/1900694724261684865" tabindex="0" loading="lazy"><figcaption>https://zhuanlan.zhihu.com/p/1900694724261684865</figcaption></figure><p>尽管在架构层面进行了这些优化，但LLaMA的核心训练机制（利用大规模文本数据以自回归方式完成语言建模任务）本质上仍与原始Transformer的训练流程相同。关于LLM结构改进的详细信息，可参考<a href="https://zhuanlan.zhihu.com/p/1900694724261684865" target="_blank" rel="noopener noreferrer">LLM架构全景</a>。</p><h2 id="_4-参考" tabindex="-1"><a class="header-anchor" href="#_4-参考"><span>4 参考</span></a></h2><ul><li><a href="https://blog.csdn.net/LuohenYJ/article/details/144858528" target="_blank" rel="noopener noreferrer">大语言模型基础知识</a></li><li><a href="https://modelscope.cn/learn/399?pid=342#4ever-bi-710" target="_blank" rel="noopener noreferrer">LLM训练理论和实战</a></li><li><a href="https://zhuanlan.zhihu.com/p/61492295" target="_blank" rel="noopener noreferrer">深入浅出地理解神经网络</a></li><li><a href="https://blog.csdn.net/qq_51580006/article/details/147456916" target="_blank" rel="noopener noreferrer">自然语言处理的深度学习模型综述</a></li><li><a href="https://zhuanlan.zhihu.com/p/27724018379" target="_blank" rel="noopener noreferrer">轻松理解大模型</a></li><li><a href="https://zhuanlan.zhihu.com/p/23556533098" target="_blank" rel="noopener noreferrer">图解大模型的推理</a></li><li><a href="https://zhuanlan.zhihu.com/p/1904841905101078831" target="_blank" rel="noopener noreferrer">Transform的注意力机制</a></li><li><a href="https://poloclub.github.io/transformer-explainer/" target="_blank" rel="noopener noreferrer">transformer-explainer</a></li><li><a href="https://zhuanlan.zhihu.com/p/642923989" target="_blank" rel="noopener noreferrer">LLM的3种架构</a></li><li><a href="https://zhuanlan.zhihu.com/p/1900694724261684865" target="_blank" rel="noopener noreferrer">LLM架构全景</a></li></ul></div><!----><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/2025-02-28-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A02-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8C%97.html" aria-label="[深度学习] 大模型学习2-提示词工程指北" iconsizing="both"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><!---->[深度学习] 大模型学习2-提示词工程指北</div></a><a class="route-link auto-link next" href="/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/2025-07-23-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03%E4%B8%8B-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83.html" aria-label="[深度学习] 大模型学习3下-模型训练与微调" iconsizing="both"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">[深度学习] 大模型学习3下-模型训练与微调<!----></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><!----><div class="vp-copyright">Copyright © 2025 落痕月极 </div></footer></div><!--]--><!--[--><!----><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-BNuIUq7T.js" defer></script>
  </body>
</html>

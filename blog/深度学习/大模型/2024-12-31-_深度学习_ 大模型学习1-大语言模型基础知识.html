<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.19" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.71" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://luohenyueji.github.io/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/2024-12-31-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html"><meta property="og:site_name" content="落痕月极的博客"><meta property="og:title" content="[深度学习] 大模型学习1-大语言模型基础知识"><meta property="og:description" content="[深度学习] 大模型学习1-大语言模型基础知识 大语言模型（Large Language Model，LLM）是一类基于Transformer架构的深度学习模型，主要用于处理与自然语言相关的各种任务。简单来说，当用户输入文本时，模型会生成相应的回复或结果。它能够完成许多任务，如文本续写、分类、摘要、改写、翻译等。常见的LLM包括GPT、LLaMA等。本..."><meta property="og:type" content="article"><meta property="og:image" content="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img0.gif"><meta property="og:locale" content="zh-CN"><meta property="article:tag" content="深度学习"><meta property="article:tag" content="自然语言处理与语音识别"><meta property="article:published_time" content="2024-12-31T22:21:03.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"[深度学习] 大模型学习1-大语言模型基础知识","image":["https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img0.gif","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img1.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img2.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img3.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img4.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img5.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img6.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img7.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img8.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img9.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img10.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img11.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img12.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img13.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img14.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img15.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img16.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img17.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img18.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img19.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img20.jpg","https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/img/img21.jpg"],"datePublished":"2024-12-31T22:21:03.000Z","dateModified":null,"author":[{"@type":"Person","name":"落痕月极","url":"/"}]}</script><link rel="icon" href="/logo.png"><title>[深度学习] 大模型学习1-大语言模型基础知识 | 落痕月极的博客</title><meta name="description" content="[深度学习] 大模型学习1-大语言模型基础知识 大语言模型（Large Language Model，LLM）是一类基于Transformer架构的深度学习模型，主要用于处理与自然语言相关的各种任务。简单来说，当用户输入文本时，模型会生成相应的回复或结果。它能够完成许多任务，如文本续写、分类、摘要、改写、翻译等。常见的LLM包括GPT、LLaMA等。本...">
    <link rel="preload" href="/assets/style-7oyYUlCQ.css" as="style"><link rel="stylesheet" href="/assets/style-7oyYUlCQ.css">
    <link rel="modulepreload" href="/assets/app-TQoR7mvJ.js"><link rel="modulepreload" href="/assets/2024-12-31-_深度学习_ 大模型学习1-大语言模型基础知识.html-UO1H3yB2.js">
    <link rel="prefetch" href="/assets/about.html-Bv4OMF4V.js" as="script"><link rel="prefetch" href="/assets/intro.html-GhW_fejM.js" as="script"><link rel="prefetch" href="/assets/index.html-CGRrU302.js" as="script"><link rel="prefetch" href="/assets/index.html-BYQA0UjX.js" as="script"><link rel="prefetch" href="/assets/index.html-BJFWIelr.js" as="script"><link rel="prefetch" href="/assets/2019-01-21-_常用工具_ 深度学习Caffe处理工具.html-jeUcp7ZJ.js" as="script"><link rel="prefetch" href="/assets/2019-03-12-_常用工具_ Caffe ssd常见问题集合.html-2k94RG80.js" as="script"><link rel="prefetch" href="/assets/2019-04-19-_常用工具_ OpenCV获取网络摄像头实时视频流.html-uqAFRMMn.js" as="script"><link rel="prefetch" href="/assets/2020-02-16-_常用工具_ git基础学习笔记.html-BQx0sFy3.js" as="script"><link rel="prefetch" href="/assets/2020-04-07-_常用工具_ shell脚本快速入门笔记.html-DE4Btr2o.js" as="script"><link rel="prefetch" href="/assets/2020-05-07-_常用工具_ live555的搭建.html-D2e55bNn.js" as="script"><link rel="prefetch" href="/assets/2020-08-11-_常用工具_ OpenCV_contrib库在windows下编译使用指南.html-D7e20CnM.js" as="script"><link rel="prefetch" href="/assets/2021-02-10-_常用工具_ cvat安装与使用指北.html-Ctd9Vxg6.js" as="script"><link rel="prefetch" href="/assets/2021-04-23-_常用工具_ dlib编译调用指南.html-UA0xvpcf.js" as="script"><link rel="prefetch" href="/assets/2021-05-22-_常用工具_ mermaid学习笔记.html-JMgab1Mp.js" as="script"><link rel="prefetch" href="/assets/2021-12-21-_常用工具_ PyAutoGUI使用教程.html-uCeYGbG7.js" as="script"><link rel="prefetch" href="/assets/2022-03-20-_常用工具_ 搜索引擎的常用技巧总结.html-b7EAavUk.js" as="script"><link rel="prefetch" href="/assets/2022-07-13-_常用工具_ C__环境下Qt的安装.html-Bfq7pxn9.js" as="script"><link rel="prefetch" href="/assets/2022-07-18-_常用工具_ 基于psutil和GPUtil获取系统状态信息.html-MIpZEZm1.js" as="script"><link rel="prefetch" href="/assets/2022-08-12-_常用工具_ Python视频处理库VidGear使用指北.html-Csf5g-jS.js" as="script"><link rel="prefetch" href="/assets/2022-08-19-_常用工具_ Python视频解码库DeFFcode使用指北.html-94A0zxLB.js" as="script"><link rel="prefetch" href="/assets/2021-08-04-_图像处理_ 基于图像哈希构建图像相似度对比算法.html-xNHoZHUj.js" as="script"><link rel="prefetch" href="/assets/2024-10-24-_图像处理_ 基于CleanVision库清洗图像数据集.html-DU0JNqGm.js" as="script"><link rel="prefetch" href="/assets/2017-10-24-_数学理论_ 单一数字评估指标.html-lB58aQsH.js" as="script"><link rel="prefetch" href="/assets/2017-10-25-_数学理论_ 不同分布训练集、验证集、测试集处理.html-DWCOMcUq.js" as="script"><link rel="prefetch" href="/assets/2021-06-27-_数据分析与可视化_ 科技论文配色心得.html-CSL5DaBZ.js" as="script"><link rel="prefetch" href="/assets/2024-06-01-_机器学习_ 低代码机器学习工具PyCaret库使用指北.html-BxE5qUJJ.js" as="script"><link rel="prefetch" href="/assets/2017-11-04-_能源化工_ TE田纳西-伊斯曼过程数据集.html-BlevXEde.js" as="script"><link rel="prefetch" href="/assets/2020-05-09-_能源化工_ 电力四遥.html-Aqmz8KWq.js" as="script"><link rel="prefetch" href="/assets/2022-01-25-_生命科学_ 生物基础实验之PCR验证.html-Cf48S7Tp.js" as="script"><link rel="prefetch" href="/assets/2022-01-31-_生命科学_ 生物基础实验之DNA提取.html-CMm3Fj9M.js" as="script"><link rel="prefetch" href="/assets/2022-03-04-_生命科学_ snapgene 构建载体方法分享.html-DcgHj_DY.js" as="script"><link rel="prefetch" href="/assets/2022-03-25-_生命科学_ 生物基础实验之三引物检测突变体.html-D8ld0esj.js" as="script"><link rel="prefetch" href="/assets/2025-09-13-_能源化工_ 面向锂电池RUL预测的开源项目全景速览.html-CPl6hFrL.js" as="script"><link rel="prefetch" href="/assets/2023-07-27-_自然语言处理_ 自然语言处理库spaCy使用指北.html-W_AM8IRD.js" as="script"><link rel="prefetch" href="/assets/2023-08-21-_语音识别_ 基于Python构建简易的音频录制与语音识别应用.html-LZTFfiq_.js" as="script"><link rel="prefetch" href="/assets/2023-09-24-_自然语言处理_ 基于pycorrector实现文本纠错.html-CeDMbs3p.js" as="script"><link rel="prefetch" href="/assets/2020-12-13-_讲座论坛_ 碧根果产业现状及产业化开发关键技术.html-Po4arisQ.js" as="script"><link rel="prefetch" href="/assets/2020-12-20-_讲座论坛_ 竹资源培育与中国竹产业.html-BftECXVH.js" as="script"><link rel="prefetch" href="/assets/2020-12-27-_讲座论坛_ 经济林之核桃类.html-BUboL3QK.js" as="script"><link rel="prefetch" href="/assets/2021-04-21-_讲座论坛_ 应对气候变化的中国视角.html-nPp4c0Zw.js" as="script"><link rel="prefetch" href="/assets/2022-02-28-_讲座论坛_ 国家自然基金申请知识汇总.html-D6Cpjuns.js" as="script"><link rel="prefetch" href="/assets/2022-12-31-_讲座论坛_ 研究的艺术学习笔记.html-DTNXP0eA.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ kmeans聚类和WGCNA.html-DBbVrkAC.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 均匀和不均匀造林对生态多样性的影响综述.html-CtIHqxXt.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 枣树的历史与现状研究进展.html-dvwP-5dp.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 森林管理和造林业中复杂观念的转变.html-D8K3IVXv.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 深度学习技术在植物领域的研究1.html-67LAM6qY.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 深度学习技术在植物领域的研究2.html-CdLHBx5z.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 物联网技术在现代林业中的应用.html-Du0OfvoC.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 石榴综述论文阅读笔记.html-BZltJSHA.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 美国造林业：过去30年的惊人变化时期.html-g_JviFCB.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 苗圃营建学习笔记.html-SsPswjSn.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_论文总结_ 集约经营下人工林造林技术研究进展.html-CoQ7kKCT.js" as="script"><link rel="prefetch" href="/assets/2021-09-23-_论文总结_ 农业工程领域中App和Web相关应用论文笔记.html-9uyXXUqJ.js" as="script"><link rel="prefetch" href="/assets/2021-09-23-_论文总结_ 智慧农业论文摘要阅读概览.html-sGO1qlrt.js" as="script"><link rel="prefetch" href="/assets/2021-09-23-_论文总结_ 深度学习在农业领域应用论文笔记.html-D-ggSKfy.js" as="script"><link rel="prefetch" href="/assets/2021-10-18-_论文总结_ 育种理论与基因检测.html-DoMhjk7t.js" as="script"><link rel="prefetch" href="/assets/2021-10-19-_论文总结_ 树木的营养生理.html-DkhAlSQD.js" as="script"><link rel="prefetch" href="/assets/2021-10-20-_论文总结_ 深度学习在农业领域应用论文笔记2.html-D-UY96Hg.js" as="script"><link rel="prefetch" href="/assets/2021-10-21-_论文总结_ 深度学习在农业领域应用论文笔记3.html-zwWD4fyb.js" as="script"><link rel="prefetch" href="/assets/2021-10-27-_论文总结_ 深度学习在农业领域应用论文笔记4.html-BC2xyfv8.js" as="script"><link rel="prefetch" href="/assets/2021-10-28-_论文总结_ 深度学习在农业领域应用论文笔记5.html-DgR32ufz.js" as="script"><link rel="prefetch" href="/assets/2021-10-29-_论文总结_ 深度学习在农业领域应用论文笔记6.html-Bj-f5KJR.js" as="script"><link rel="prefetch" href="/assets/2021-10-30-_论文总结_ 深度学习在农业领域应用论文笔记7.html-D6zZ5qx4.js" as="script"><link rel="prefetch" href="/assets/2021-11-02-_论文总结_ 深度学习在农业领域应用论文笔记8.html-CpppUHX-.js" as="script"><link rel="prefetch" href="/assets/2021-11-03-_论文总结_ 深度学习在农业领域应用论文笔记9.html-CNzzEsbn.js" as="script"><link rel="prefetch" href="/assets/2021-11-04-_论文总结_ 森林生态系统中的水生生境.html-Dv_nPbu7.js" as="script"><link rel="prefetch" href="/assets/2022-04-05-_论文总结_  种群、保护与生态遗传学笔记.html-DLsAIZZl.js" as="script"><link rel="prefetch" href="/assets/2022-05-01-_论文总结_ Genecology and Adaptation of Forest Trees 林木的基因生态学与适应性.html-DS-h_KBD.js" as="script"><link rel="prefetch" href="/assets/2022-05-20-_论文总结_ 中国工科生常见英文写作问题总结.html-DaweUXHj.js" as="script"><link rel="prefetch" href="/assets/2022-05-31-_论文总结_ 科技论文英语写作笔记1.html-CjPtpK76.js" as="script"><link rel="prefetch" href="/assets/2022-08-01-_论文总结_ 深度学习在农业领域应用论文笔记10.html-jhpO-sB5.js" as="script"><link rel="prefetch" href="/assets/2023-02-28-_论文总结_ 深度学习在农业领域应用论文笔记11.html-DbkdLxCy.js" as="script"><link rel="prefetch" href="/assets/2024-02-10-_论文总结_ 深度学习在农业领域应用论文笔记12.html-m7G5e43Z.js" as="script"><link rel="prefetch" href="/assets/2024-09-25-_论文总结_ 深度学习在农业领域应用论文笔记13.html-qN3JzAMs.js" as="script"><link rel="prefetch" href="/assets/2025-01-28-_论文总结_ 深度学习在农业领域应用论文笔记14.html-2VNnf0jp.js" as="script"><link rel="prefetch" href="/assets/2020-05-13-_随笔所想_ CSDN认证博客专家申请通过随笔所想.html-BFOTL3UN.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_随笔所想_ 程序员中年失业随笔所想.html-LolEqxAP.js" as="script"><link rel="prefetch" href="/assets/2020-12-07-_随笔所想_ UBC学习生活经验分享.html-CNQ2oFSh.js" as="script"><link rel="prefetch" href="/assets/2021-01-14-_随笔所想_ 2021年新年碎碎念-加油了不起的干饭人!.html-Cur8s9F3.js" as="script"><link rel="prefetch" href="/assets/2021-02-12-_随笔所想_ 牛年碎碎念祝大家牛年大吉.html-CXjxQyrU.js" as="script"><link rel="prefetch" href="/assets/2021-03-31-_随笔所想_ 买房和户型挑选入门.html-CwVkrJel.js" as="script"><link rel="prefetch" href="/assets/2021-08-29-_随笔所想_ 学英语打卡2000天碎碎念.html-CXqxAVh9.js" as="script"><link rel="prefetch" href="/assets/2021-12-1-_随笔所想_ 沉痛悼念开发技术专家毛星云老师.html-Bv4kBmuo.js" as="script"><link rel="prefetch" href="/assets/2024-02-17-_随笔所想_ 劳动合同法学习笔记.html-Bm8yioGV.js" as="script"><link rel="prefetch" href="/assets/2023-05-31-_音视频处理_ FFmpeg使用指北1-视频解码.html-5Is3UyRR.js" as="script"><link rel="prefetch" href="/assets/2019-03-04-_OpenCV实战_1 基于深度学习识别人脸性别和年龄.html-pbb0p4Ex.js" as="script"><link rel="prefetch" href="/assets/2019-03-05-_OpenCV实战_2 人脸识别算法对比.html-BYDodIsr.js" as="script"><link rel="prefetch" href="/assets/2019-03-06-_OpenCV实战_3 透明斗篷.html-D3PS0mO0.js" as="script"><link rel="prefetch" href="/assets/2019-03-06-_OpenCV实战_4 OpenCV中的颜色空间.html-DBpU-q1i.js" as="script"><link rel="prefetch" href="/assets/2019-03-06-_OpenCV实战_5 基于深度学习的文本检测.html-MpOrfF8N.js" as="script"><link rel="prefetch" href="/assets/2019-03-08-_OpenCV实战_6 基于特征点匹配的视频稳像.html-nFcOVNmO.js" as="script"><link rel="prefetch" href="/assets/2019-03-13-_OpenCV实战_7 使用YOLOv3和OpenCV进行基于深度学习的目标检测.html-DAZ9QXWa.js" as="script"><link rel="prefetch" href="/assets/2019-03-15-_OpenCV实战_8 深度学习目标检测网络YOLOv3的训练.html--HO0VS4K.js" as="script"><link rel="prefetch" href="/assets/2019-03-16-_OpenCV实战_10 使用Hu矩进行形状匹配.html-wt8JOGWs.js" as="script"><link rel="prefetch" href="/assets/2019-03-16-_OpenCV实战_9 使用OpenCV寻找平面图形的质心.html-CR3xBAvU.js" as="script"><link rel="prefetch" href="/assets/2019-03-19-_OpenCV实战_11 基于OpenCV的二维码扫描器.html-BxVvecWI.js" as="script"><link rel="prefetch" href="/assets/2019-03-27-_OpenCV实战_12 使用深度学习和OpenCV进行手部关键点检测.html-CWMA2MAK.js" as="script"><link rel="prefetch" href="/assets/2019-04-02-_OpenCV实战_13 OpenCV中使用Mask R-CNN进行对象检测和实例分割.html-Gcudcabj.js" as="script"><link rel="prefetch" href="/assets/2019-04-04-_OpenCV实战_14 使用OpenCV实现单目标跟踪.html-BUnMjovB.js" as="script"><link rel="prefetch" href="/assets/2019-04-08-_OpenCV实战_15 基于深度学习的目标跟踪算法GOTURN.html-CSnVmgwX.js" as="script"><link rel="prefetch" href="/assets/2019-04-08-_OpenCV实战_16 使用OpenCV实现多目标跟踪.html-BL6bE8y9.js" as="script"><link rel="prefetch" href="/assets/2019-04-10-_OpenCV实战_17 基于卷积神经网络的OpenCV图像着色.html-UkgPadAQ.js" as="script"><link rel="prefetch" href="/assets/2019-04-16-_OpenCV实战_18 OpenCV中的单应性矩阵Homography.html-B0_as9f1.js" as="script"><link rel="prefetch" href="/assets/2019-04-17-_OpenCV实战_19 使用OpenCV实现基于特征的图像对齐.html-CfVQJGtB.js" as="script"><link rel="prefetch" href="/assets/2019-04-22-_OpenCV实战_20 使用OpenCV实现基于增强相关系数最大化的图像对齐.html-rSH1S58g.js" as="script"><link rel="prefetch" href="/assets/2019-04-23-_OpenCV实战_21 使用OpenCV的Eigenface.html-Bpq-pmz8.js" as="script"><link rel="prefetch" href="/assets/2019-04-24-_OpenCV实战_22 使用EigenFaces进行人脸重建.html-lzxbeSD1.js" as="script"><link rel="prefetch" href="/assets/2019-04-30-_OpenCV实战_23 使用OpenCV获取高动态范围成像HDR.html-BLh8BDKZ.js" as="script"><link rel="prefetch" href="/assets/2019-05-05-_OpenCV实战_24 使用OpenCV进行曝光融合.html-B-8B8P1u.js" as="script"><link rel="prefetch" href="/assets/2019-05-05-_OpenCV实战_25 使用OpenCV进行泊松克隆.html-BiByA5Qt.js" as="script"><link rel="prefetch" href="/assets/2019-05-06-_OpenCV实战_26 基于OpenCV实现选择性搜索算法.html-kApGwdd-.js" as="script"><link rel="prefetch" href="/assets/2019-05-07-_OpenCV实战_27 在OpenCV下使用forEach进行并行像素访问.html-Ccg8kb3S.js" as="script"><link rel="prefetch" href="/assets/2019-05-08-_OpenCV实战_28 基于OpenCV的GUI库cvui.html-Bz6MGpOc.js" as="script"><link rel="prefetch" href="/assets/2019-05-09-_OpenCV实战_29 使用OpenCV实现红眼自动去除.html-enIGbQLB.js" as="script"><link rel="prefetch" href="/assets/2019-05-10-_OpenCV实战_30 使用OpenCV实现图像孔洞填充.html-BViVs52N.js" as="script"><link rel="prefetch" href="/assets/2019-05-23-_OpenCV实战_31 使用OpenCV将一个三角形仿射变换到另一个三角形.html-PjMXNViO.js" as="script"><link rel="prefetch" href="/assets/2019-05-24-_OpenCV实战_32 使用OpenCV进行非真实感渲染.html-B9lN1sXG.js" as="script"><link rel="prefetch" href="/assets/2019-05-27-_OpenCV实战_33 使用OpenCV进行Hough变换.html-Di7cpBel.js" as="script"><link rel="prefetch" href="/assets/2019-05-28-_OpenCV实战_34 使用OpenCV进行图像修复.html-Cu2xCoJV.js" as="script"><link rel="prefetch" href="/assets/2019-07-16-_OpenCV实战_35 使用Tesseract和OpenCV实现文本识别.html-DUZkAOyC.js" as="script"><link rel="prefetch" href="/assets/2019-08-30-_OpenCV实战_36 使用OpenCV在视频中实现简单背景估计.html-Doz-l9Hl.js" as="script"><link rel="prefetch" href="/assets/2020-02-29-_OpenCV实战_37 图像质量评价BRISQUE.html-DTURayFu.js" as="script"><link rel="prefetch" href="/assets/2020-03-06-_OpenCV实战_38 基于OpenCV的相机标定.html-CtAodbd4.js" as="script"><link rel="prefetch" href="/assets/2020-03-31-_OpenCV实战_39 在OpenCV中使用ArUco标记的增强现实.html-GrGAxbE_.js" as="script"><link rel="prefetch" href="/assets/2020-05-07-_OpenCV实战_40 计算机视觉工具对比.html-Xg1smH74.js" as="script"><link rel="prefetch" href="/assets/2020-05-10-_OpenCV实战_41 嵌入式计算机视觉设备选择.html-DSpIWAi1.js" as="script"><link rel="prefetch" href="/assets/2020-05-12-_OpenCV实战_42 数码单反相机的技术细节.html-GTmOlvyT.js" as="script"><link rel="prefetch" href="/assets/2020-08-14-_OpenCV实战_43 使用OpenCV进行背景分割.html-Du7zin47.js" as="script"><link rel="prefetch" href="/assets/2020-08-24-_OpenCV实战_44 使用OpenCV进行图像超分放大.html-CLTjA_pQ.js" as="script"><link rel="prefetch" href="/assets/2020-08-27-_OpenCV实战_45 基于OpenCV实现图像哈希算法.html-C6DjR2dc.js" as="script"><link rel="prefetch" href="/assets/2020-09-10-_OpenCV实战_46 在OpenCV下应用图像强度变换实现图像对比度均衡.html-BlOXCV71.js" as="script"><link rel="prefetch" href="/assets/2020-09-15-_OpenCV实战_47 基于OpenCV实现视觉显著性检测.html-ByFMgzO7.js" as="script"><link rel="prefetch" href="/assets/2020-10-09-_OpenCV实战_48 基于OpenCV实现图像质量评价.html-DfUk15_y.js" as="script"><link rel="prefetch" href="/assets/2021-02-12-_OpenCV实战_49 对极几何与立体视觉初探.html-CpMT76Uk.js" as="script"><link rel="prefetch" href="/assets/2021-02-16-_OpenCV实战_50 用OpenCV制作低成本立体相机.html-DgwwbZq8.js" as="script"><link rel="prefetch" href="/assets/2021-03-15-_OpenCV实战_51 基于OpenCV实现图像极坐标变换与逆变换.html-BQle2yke.js" as="script"><link rel="prefetch" href="/assets/2022-12-01-_OpenCV实战_52 在OpenCV中使用颜色直方图.html-czQ3_CbF.js" as="script"><link rel="prefetch" href="/assets/index.html-j0l7WbOp.js" as="script"><link rel="prefetch" href="/assets/2017-11-13-_python_ tensorflow中的argmax()函数.html-DB_kOkP_.js" as="script"><link rel="prefetch" href="/assets/2019-07-31-_python_ 基于matplotlib实现树形图的绘制.html-C4gN6PKL.js" as="script"><link rel="prefetch" href="/assets/2019-08-13-_python_ mxnet60分钟入门Gluon教程.html-DDg72DNE.js" as="script"><link rel="prefetch" href="/assets/2019-10-28-_python_ 基于NetworkX实现网络图的绘制.html-DzWNghZs.js" as="script"><link rel="prefetch" href="/assets/2019-10-31-_python_ NetworkX实例.html-6bSUWSVI.js" as="script"><link rel="prefetch" href="/assets/2019-11-15-_python_ 基于matplotlib_venn实现维恩图的绘制.html-DSBGEH1Y.js" as="script"><link rel="prefetch" href="/assets/2019-12-30-_python_ CairoSVG使用教程.html-BBYWxDDr.js" as="script"><link rel="prefetch" href="/assets/2020-03-25-_python_ 个人日常python工具代码.html-C6JFIsOT.js" as="script"><link rel="prefetch" href="/assets/2020-05-17-_python_ python模块graphviz使用入门.html-BGwKkNYE.js" as="script"><link rel="prefetch" href="/assets/2020-09-01-_python_ 基于matplotlib实现圆环图的绘制.html-CDNV9JaM.js" as="script"><link rel="prefetch" href="/assets/2020-09-01-_python_ 基于matplotlib实现雷达图的绘制.html-CWSlDmh9.js" as="script"><link rel="prefetch" href="/assets/2021-07-20-_python_ Python二维码生成器qrcode库入门.html-CUPA9YYW.js" as="script"><link rel="prefetch" href="/assets/2021-07-21-_python_ Python map函数总结.html-BkKGcbEl.js" as="script"><link rel="prefetch" href="/assets/2021-07-23-_python_ 圆形嵌套图Circular Packing.html-aiBkA8dJ.js" as="script"><link rel="prefetch" href="/assets/2022-04-10-_python_ ​python-pinyin库.html-B8GsN0Sf.js" as="script"><link rel="prefetch" href="/assets/2022-07-07-_python_ ​Python数据序列化模块pickle使用笔记.html-BC-RuIPb.js" as="script"><link rel="prefetch" href="/assets/2022-07-21-_python_ 向量检索库Faiss使用指北.html-DfvAGoi8.js" as="script"><link rel="prefetch" href="/assets/2022-07-25-_python_ 基于chardet识别字符编码.html-DcpyMMzH.js" as="script"><link rel="prefetch" href="/assets/2022-09-10-_python_ 基于diagrams库绘制系统架构图.html-b7veaNHi.js" as="script"><link rel="prefetch" href="/assets/2022-09-19-_python_ 基于blind-watermark库添加图片盲水印.html-CDV3LWQW.js" as="script"><link rel="prefetch" href="/assets/2022-10-24-_python_ 基于Gradio可视化部署机器学习应用.html-BN4p8SHb.js" as="script"><link rel="prefetch" href="/assets/2022-12-07-_python_ 基于wordcloud库绘制词云图.html-BtJpfdQy.js" as="script"><link rel="prefetch" href="/assets/2023-01-01-_python_ 基于paramiko库操作远程服务器.html-CgeQjCty.js" as="script"><link rel="prefetch" href="/assets/2023-04-17-_python_ Python枚举模块enum总结.html-DxJkZ08V.js" as="script"><link rel="prefetch" href="/assets/2023-05-10-_python_ Python类型提示总结.html-UNLMhKP5.js" as="script"><link rel="prefetch" href="/assets/2023-11-30-_python_ 基于Tablib库处理表格数据.html-BgUEpN8j.js" as="script"><link rel="prefetch" href="/assets/2023-12-29-_python_ 基于Dataset库操作数据库.html-BU56yzu6.js" as="script"><link rel="prefetch" href="/assets/2024-01-25-_python_ 基于RapidFuzz库实现字符串模糊匹配.html-ChVod94Z.js" as="script"><link rel="prefetch" href="/assets/2024-04-30-_python_ 基于PyWaffle库绘制华夫饼图.html-BEAlHLB4.js" as="script"><link rel="prefetch" href="/assets/2024-06-30-_python_ Python日志记录库loguru使用指北.html-oo2DYeXy.js" as="script"><link rel="prefetch" href="/assets/2024-07-30-_python_ 启发式算法库scikit-opt使用指北.html-B2S85Cor.js" as="script"><link rel="prefetch" href="/assets/2024-08-10-_python_ Python并行计算库Joblib使用指北.html-BTn29TNW.js" as="script"><link rel="prefetch" href="/assets/2024-10-01-_python_ 基于PyOD库实现数据异常检测.html-CgaVID9q.js" as="script"><link rel="prefetch" href="/assets/2024-11-22-_python_ Python异步编程库asyncio使用指北.html-Bgeyduo9.js" as="script"><link rel="prefetch" href="/assets/2024-11-25-_python_ asyncio库常见问题与实践案例.html-CVAquxYR.js" as="script"><link rel="prefetch" href="/assets/2025-03-24-_python_ 使用Python实现Markdown文档格式转换.html-TB04R6Fz.js" as="script"><link rel="prefetch" href="/assets/2025-04-27-_python_ 基于WatchDog库实现文件系统监控.html-CmNjNtKC.js" as="script"><link rel="prefetch" href="/assets/2025-05-20-_python_ 轻量级定时任务调度库schedule使用指北.html-D7mkdCiT.js" as="script"><link rel="prefetch" href="/assets/2025-06-03-_python_ python抽象基类使用总结.html-pStZuM38.js" as="script"><link rel="prefetch" href="/assets/2019-06-25-_python_《Python编程快速上手让繁琐工作自动化》学习笔记1.html-DWmrRoR4.js" as="script"><link rel="prefetch" href="/assets/2019-06-26-_python_《Python编程快速上手让繁琐工作自动化》学习笔记2.html-Jrzj8rLf.js" as="script"><link rel="prefetch" href="/assets/2019-06-28-_python_《Python编程快速上手让繁琐工作自动化》学习笔记3.html-CIdhHmEc.js" as="script"><link rel="prefetch" href="/assets/2019-07-05-_python_《Python编程快速上手让繁琐工作自动化》学习笔记4.html-9CkXJZjo.js" as="script"><link rel="prefetch" href="/assets/2019-07-27-_python_《Python编程快速上手让繁琐工作自动化》学习笔记5.html-DYkLtKlb.js" as="script"><link rel="prefetch" href="/assets/2019-07-31-_python_《Python编程快速上手让繁琐工作自动化》学习笔记6.html-CYFTDljp.js" as="script"><link rel="prefetch" href="/assets/2019-08-02-_python_《Python编程快速上手让繁琐工作自动化》学习笔记7.html-BMZSkSzb.js" as="script"><link rel="prefetch" href="/assets/2019-05-28-_seaborn_ seaborn学习笔记0 seaborn学习笔记章节.html-CnoDvY5G.js" as="script"><link rel="prefetch" href="/assets/2019-05-29-_seaborn_ seaborn学习笔记1 箱形图Boxplot.html-CvDLZrb0.js" as="script"><link rel="prefetch" href="/assets/2019-05-30-_seaborn_ seaborn学习笔记2 散点图Scatterplot.html-C8DnflV-.js" as="script"><link rel="prefetch" href="/assets/2019-05-30-_seaborn_ seaborn学习笔记3 直方图Histogramplot.html-DopGa9fN.js" as="script"><link rel="prefetch" href="/assets/2019-05-31-_seaborn_ seaborn学习笔记4 核密度图DENSITYPLOT.html-mAbd0owK.js" as="script"><link rel="prefetch" href="/assets/2019-05-31-_seaborn_ seaborn学习笔记5 小提琴图VIOLINPLOT.html-CjYheinM.js" as="script"><link rel="prefetch" href="/assets/2019-05-31-_seaborn_ seaborn学习笔记6 热图HEATMAPPLOT.html-DBsXYFlC.js" as="script"><link rel="prefetch" href="/assets/2019-06-01-_seaborn_ seaborn学习笔记7 常用参数调整Adjustment of Common Parameters.html-DjvdSvg1.js" as="script"><link rel="prefetch" href="/assets/2019-06-01-_seaborn_ seaborn学习笔记8 避免过度绘图Avoid Overplotting.html-CgrElsCU.js" as="script"><link rel="prefetch" href="/assets/2019-06-05-_seaborn_ seaborn学习笔记10 绘图实例(2) Drawing example(2).html-BX_NXh6R.js" as="script"><link rel="prefetch" href="/assets/2019-06-05-_seaborn_ seaborn学习笔记9 绘图实例(1) Drawing example(1).html-DVaZHItT.js" as="script"><link rel="prefetch" href="/assets/2019-06-06-_seaborn_ seaborn学习笔记11 绘图实例(3) Drawing example(3).html-BT87wiZZ.js" as="script"><link rel="prefetch" href="/assets/2019-06-06-_seaborn_ seaborn学习笔记12 绘图实例(4) Drawing example(4).html-_tyWGbbU.js" as="script"><link rel="prefetch" href="/assets/2020-03-21-_R语言_ ggplot2入门笔记1—ggplot2简要教程.html-C_WOojq5.js" as="script"><link rel="prefetch" href="/assets/2020-03-21-_R语言_ ggplot2入门笔记2—通用教程ggplot2简介.html-kqG_HnRr.js" as="script"><link rel="prefetch" href="/assets/2020-03-21-_R语言_ ggplot2入门笔记3—通用教程如何自定义ggplot2.html-DDzdl4_B.js" as="script"><link rel="prefetch" href="/assets/2020-03-21-_R语言_ ggplot2入门笔记4—前50个ggplot2可视化效果.html-Brf6GNZO.js" as="script"><link rel="prefetch" href="/assets/index.html-Ds4WvDKC.js" as="script"><link rel="prefetch" href="/assets/2019-07-31-_R语言_ R语言PCA分析教程 Principal Component Methods in R.html-B5kkhrrd.js" as="script"><link rel="prefetch" href="/assets/2020-01-10-_R语言_ WGCNA入门教程.html-CkuOlJsA.js" as="script"><link rel="prefetch" href="/assets/2021-02-05-_R语言_ R语言快速入门教程.html-C7ia8JPJ.js" as="script"><link rel="prefetch" href="/assets/2020-09-05-_R语言_ 基于R语言实现树形图的绘制.html-B8YZMF2Z.js" as="script"><link rel="prefetch" href="/assets/2020-09-05-_R语言_ 基于R语言实现环状条形图的绘制.html-Bmv8PiZb.js" as="script"><link rel="prefetch" href="/assets/2018-12-11-_图像处理_ YUV图像处理入门1.html-CSMQsqUo.js" as="script"><link rel="prefetch" href="/assets/2018-12-11-_图像处理_ YUV图像处理入门2.html-DZFDwCay.js" as="script"><link rel="prefetch" href="/assets/2018-12-11-_图像处理_ YUV图像处理入门3.html-Ox20A9pK.js" as="script"><link rel="prefetch" href="/assets/2018-12-11-_图像处理_ YUV图像处理入门4.html-DcI2V7Mc.js" as="script"><link rel="prefetch" href="/assets/2018-12-11-_图像处理_ YUV图像处理入门5.html-YIObW1xA.js" as="script"><link rel="prefetch" href="/assets/index.html-BMDoqoA4.js" as="script"><link rel="prefetch" href="/assets/2021-11-21-_数据与分析可视化_ D3入门教程1-d3基础知识.html-KUuyOMx3.js" as="script"><link rel="prefetch" href="/assets/2021-11-28-_数据与分析可视化_ D3入门教程2-在d3中构建形状.html-B1CmNEk_.js" as="script"><link rel="prefetch" href="/assets/2021-12-05-_数据与分析可视化_ D3入门教程3-d3中的数据操作.html-DK7ysaE_.js" as="script"><link rel="prefetch" href="/assets/2023-03-16-_数据分析与可视化_ Python绘制数据地图1-GeoPandas入门指北.html-Dr3gFWEf.js" as="script"><link rel="prefetch" href="/assets/2023-04-09-_数据分析与可视化_ Python绘制数据地图2-GeoPandas地图可视化.html-DDa4X9Lf.js" as="script"><link rel="prefetch" href="/assets/2023-06-16-_数据分析与可视化_ Python绘制数据地图3-GeoPandas使用要点.html-BCR4Mc1r.js" as="script"><link rel="prefetch" href="/assets/2023-08-03-_数据分析与可视化_ Python绘制数据地图4-MovingPandas入门指北.html-7xsY7QZg.js" as="script"><link rel="prefetch" href="/assets/2023-08-11-_数据分析与可视化_ Python绘制数据地图5-MovingPandas绘图实例.html-_aLxoHRt.js" as="script"><link rel="prefetch" href="/assets/2023-06-28-_数据分析与可视化_ 基于matplotlib-scalebar库绘制比例尺.html-Cv_JDnUv.js" as="script"><link rel="prefetch" href="/assets/2023-07-10-_数据分析与可视化_ 基于matplotlib和plottable库绘制精美表格.html-D_cVRq_p.js" as="script"><link rel="prefetch" href="/assets/2023-10-24-_数据分析与可视化_ 基于Python绘制简单动图.html-gVBHHdIC.js" as="script"><link rel="prefetch" href="/assets/2021-11-14-_数据分析与可视化_ 数据绘图要点1-注重数据排序.html-D6yDi7zB.js" as="script"><link rel="prefetch" href="/assets/2021-11-18-_数据分析与可视化_ 数据绘图要点2-Y轴的开始与结束.html-DRSbrmSx.js" as="script"><link rel="prefetch" href="/assets/2021-11-24-_数据分析与可视化_ 数据绘图要点3-意大利面条图.html-Cglj8SC7.js" as="script"><link rel="prefetch" href="/assets/2021-12-01-_数据分析与可视化_ 数据绘图要点4-饼图的问题.html-DpFD1p6k.js" as="script"><link rel="prefetch" href="/assets/2021-12-09-_数据分析与可视化_ 数据绘图要点5-误差线的问题.html-C25WBa8A.js" as="script"><link rel="prefetch" href="/assets/2021-12-19-_数据分析与可视化_ 数据绘图要点6-数据组过多.html-HfUEA1OU.js" as="script"><link rel="prefetch" href="/assets/2021-12-25-_数据分析与可视化_ 数据绘图要点7-过度绘图.html-B7pZs2qM.js" as="script"><link rel="prefetch" href="/assets/2021-12-29-_数据分析与可视化_ 数据绘图要点8-环状条形图的使用.html-C3fwD9w8.js" as="script"><link rel="prefetch" href="/assets/2022-01-01-_数据分析与可视化_ 数据绘图要点9-颜色的选择.html-DRQSebtT.js" as="script"><link rel="prefetch" href="/assets/2022-01-06-_数据分析与可视化_ 数据绘图要点10-图例的构建.html-BSweTIIx.js" as="script"><link rel="prefetch" href="/assets/2022-01-12-_数据分析与可视化_ 数据绘图要点11-雷达图的注意事项.html-tGrwr_Ls.js" as="script"><link rel="prefetch" href="/assets/2022-01-18-_数据分析与可视化_ 数据绘图要点12-图表注释的重要性.html-bXs2VdS1.js" as="script"><link rel="prefetch" href="/assets/2017-12-10-_机器学习_ 集成学习简单投票法概率.html-RGp5CCpy.js" as="script"><link rel="prefetch" href="/assets/2018-04-17-_机器学习_ sklearn聚类.html-BQGCw2mj.js" as="script"><link rel="prefetch" href="/assets/2018-04-19-_机器学习_ sklearn决策树、随机森林、隐马尔可夫模型.html-4zHKcwfN.js" as="script"><link rel="prefetch" href="/assets/2018-04-19-_机器学习_ sklearn朴素贝叶斯算法.html-UFQsnaE_.js" as="script"><link rel="prefetch" href="/assets/2018-04-21-_机器学习_ sklearn支持向量机.html-DdhifKEq.js" as="script"><link rel="prefetch" href="/assets/2020-07-25-_机器学习_ Yellowbrick使用笔记1-快速入门.html-DFqsijkZ.js" as="script"><link rel="prefetch" href="/assets/2020-07-25-_机器学习_ Yellowbrick使用笔记2-模型选择.html-DUm-Kb5i.js" as="script"><link rel="prefetch" href="/assets/2020-07-25-_机器学习_ Yellowbrick使用笔记3-特征分析可视化.html-i_-gEZtr.js" as="script"><link rel="prefetch" href="/assets/2020-07-25-_机器学习_ Yellowbrick使用笔记4-目标可视化文件.html-PS_ZbJED.js" as="script"><link rel="prefetch" href="/assets/2020-07-25-_机器学习_ Yellowbrick使用笔记5-回归可视化.html-DTFDnP-_.js" as="script"><link rel="prefetch" href="/assets/2020-07-25-_机器学习_ Yellowbrick使用笔记6-分类可视化.html-32dDTPn7.js" as="script"><link rel="prefetch" href="/assets/2020-07-25-_机器学习_ Yellowbrick使用笔记7-聚类可视化.html-Br1HE9LY.js" as="script"><link rel="prefetch" href="/assets/2020-07-25-_机器学习_ Yellowbrick使用笔记8-模型选择可视化.html-ChpwlcWq.js" as="script"><link rel="prefetch" href="/assets/2020-07-09-_机器学习_ 特征选择笔记1-删除低方差的特征.html-Duzlgo2l.js" as="script"><link rel="prefetch" href="/assets/2020-07-09-_机器学习_ 特征选择笔记2-单变量特征选择.html-D2w_3-O-.js" as="script"><link rel="prefetch" href="/assets/2020-07-09-_机器学习_ 特征选择笔记3-递归式特征消除.html-BH08ZVxA.js" as="script"><link rel="prefetch" href="/assets/2020-07-09-_机器学习_ 特征选择笔记4-使用SelectFromModel特征选择.html-BexfLlYF.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门1-创建线程的三种不同方式.html-B6R4X8rv.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门10-packaged_task示例.html-BrokG8Kg.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门2-连接和分离线程.html-LtU6bTBC.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门3-小心地将参数传递给线程.html-CrwGKjCD.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门4-数据共享和资源竞争.html-jQ_j7vzE.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门5-使用互斥锁解决资源竞争.html-BTCqN1HH.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门6-事件处理的需求.html-B2bnynyq.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门7-条件变量介绍.html-DIILD4V4.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门8-从线程返回值.html-BrkqnNKB.js" as="script"><link rel="prefetch" href="/assets/2020-05-29-_编程基础_ C__多线程入门9-async教程和示例.html-CpcIly5w.js" as="script"><link rel="prefetch" href="/assets/2021-10-24-_编程基础_ 常用html标签使用介绍.html-BQmmK9cS.js" as="script"><link rel="prefetch" href="/assets/2017-11-02-_编程基础_ C_自定义类调用窗体控件.html-DxYfFpk0.js" as="script"><link rel="prefetch" href="/assets/2020-05-09-_编程基础_ C和C__内置宏说明.html-BYDMPuIo.js" as="script"><link rel="prefetch" href="/assets/2020-06-17-_编程基础_ Python格式化字符串常量f-string总结.html-BZ3k-U28.js" as="script"><link rel="prefetch" href="/assets/2020-06-20-_编程基础_ Python谷歌翻译库googletrans总结.html-BsN5kir2.js" as="script"><link rel="prefetch" href="/assets/2020-06-21-_编程基础_ Python数据生成库Faker总结.html-BmjmH-wB.js" as="script"><link rel="prefetch" href="/assets/2020-06-21-_编程基础_ Python配置文件读取库ConfigParser总结.html-CaPdaD0-.js" as="script"><link rel="prefetch" href="/assets/2020-06-23-_编程基础_ Python日志记录库logging总结.html-Q7sbxkrF.js" as="script"><link rel="prefetch" href="/assets/2020-06-24-_编程基础_ Python随机数生成模块总结.html-DNO9pgZ5.js" as="script"><link rel="prefetch" href="/assets/2020-06-25-_编程基础_ Python lambda函数总结.html-uLbonhat.js" as="script"><link rel="prefetch" href="/assets/2020-06-25-_编程基础_ Python装饰器入门总结.html-DdGcGt5Z.js" as="script"><link rel="prefetch" href="/assets/2020-06-26-_编程基础_ Python列表解析总结.html-B_1y0unr.js" as="script"><link rel="prefetch" href="/assets/2020-08-01-_编程基础_ Python中的绝对导入与相对导入.html-BVOqhdUt.js" as="script"><link rel="prefetch" href="/assets/2020-08-01-_编程基础_ Python模块和包使用笔记.html-a7W3E7FN.js" as="script"><link rel="prefetch" href="/assets/2020-08-02-_编程基础_ Python对象的浅拷贝与深拷贝笔记.html-CBcMf4FU.js" as="script"><link rel="prefetch" href="/assets/2020-10-14-_编程基础_ Python中args和kwargs参数的使用.html-BLpu4PKr.js" as="script"><link rel="prefetch" href="/assets/2020-10-31-_编程基础_ Python命令行解析库argparse学习笔记.html-FEHx_ob3.js" as="script"><link rel="prefetch" href="/assets/2021-08-16-_编程基础_ Python字符串替换笔记.html-j0T7ETpj.js" as="script"><link rel="prefetch" href="/assets/2023-09-05-_编程基础_ Python内置模块collections使用笔记.html-DHfInrFh.js" as="script"><link rel="prefetch" href="/assets/2025-02-28-_深度学习_ 大模型学习2-提示词工程指北.html-jT_DHJTZ.js" as="script"><link rel="prefetch" href="/assets/2025-07-21-_深度学习_ 大模型学习3上-模型训练与微调.html-CICF4DAO.js" as="script"><link rel="prefetch" href="/assets/2025-07-23-_深度学习_ 大模型学习3下-模型训练与微调.html-CAZTjrWc.js" as="script"><link rel="prefetch" href="/assets/2025-08-08-_深度学习_ 大模型学习4-RAG技术全景解析.html-lhenMyEq.js" as="script"><link rel="prefetch" href="/assets/2017-10-11-_深度学习_ 网易云课堂深度学习工程师微专业相关资料.html-BabEy_XI.js" as="script"><link rel="prefetch" href="/assets/2017-10-12-_深度学习_ 深度学习快速入门资料.html-DVyMenRS.js" as="script"><link rel="prefetch" href="/assets/2017-10-13-_深度学习_ 卷积神经网络快速入门.html-BDsdWcMa.js" as="script"><link rel="prefetch" href="/assets/2017-11-25-_深度学习_ 深度学习中卷积操作和数学中卷积操作的异同.html-CHWvVHwR.js" as="script"><link rel="prefetch" href="/assets/2018-07-17-_深度学习_ tf.keras入门1-基本函数介绍.html-M1ukFlO0.js" as="script"><link rel="prefetch" href="/assets/2018-07-18-_深度学习_ tf.keras入门2-分类.html-BFaluU0L.js" as="script"><link rel="prefetch" href="/assets/2018-07-18-_深度学习_ tf.keras入门3-回归.html-DBH_z0P0.js" as="script"><link rel="prefetch" href="/assets/2018-07-18-_深度学习_ tf.keras入门4-过拟合和欠拟合.html-BW2HUorc.js" as="script"><link rel="prefetch" href="/assets/2018-07-18-_深度学习_ tf.keras入门5-模型保存和载入.html-OSqEYmn6.js" as="script"><link rel="prefetch" href="/assets/2018-07-27-_深度学习_ 经典深度学习模型及其微调（Caffe)总结.html-j6fY5-s9.js" as="script"><link rel="prefetch" href="/assets/2019-07-23-_深度学习_ ncnn安装和调用基础教程.html-tO0KhwK7.js" as="script"><link rel="prefetch" href="/assets/2019-08-10-_深度学习_ caffe分类模型训练、结果可视化、部署及量化笔记.html-Dk-zGI7K.js" as="script"><link rel="prefetch" href="/assets/2019-09-30-_深度学习_ ncnn编译使用.html-BrdZkDSi.js" as="script"><link rel="prefetch" href="/assets/2020-08-07-_深度学习_ ImageAI库使用笔记.html-0QeSb0_u.js" as="script"><link rel="prefetch" href="/assets/2020-10-24-_深度学习_ imgaug库使用笔记.html-hnHYgD-V.js" as="script"><link rel="prefetch" href="/assets/2020-11-19-_深度学习_ 深度学习优化器选择学习笔记.html-TYXP47yp.js" as="script"><link rel="prefetch" href="/assets/2020-12-09-_深度学习_ Pytorch模型转换为onnx模型笔记.html-dkWC9qWF.js" as="script"><link rel="prefetch" href="/assets/2021-01-14-_深度学习_ ubuntu18.04配置深度学习环境笔记.html-DjjOsAla.js" as="script"><link rel="prefetch" href="/assets/2021-02-02-_深度学习_ imgaug边界框增强笔记.html-IG6UiIso.js" as="script"><link rel="prefetch" href="/assets/2021-06-09-_深度学习_ CCPD车牌数据集介绍.html-D8LGVkQw.js" as="script"><link rel="prefetch" href="/assets/2022-01-14-_深度学习_ fast-reid入门教程.html-Y66hhv41.js" as="script"><link rel="prefetch" href="/assets/2022-02-26-_深度学习_ Python人脸识别库face_recognition使用教程.html-C0tH7_3P.js" as="script"><link rel="prefetch" href="/assets/2022-07-02-_深度学习_ Python人脸识别库Deepface使用教程.html-DNhDXX2S.js" as="script"><link rel="prefetch" href="/assets/2022-11-24-_深度学习_ 搭建行人重识别系统心得.html-CCIU11uj.js" as="script"><link rel="prefetch" href="/assets/2023-01-03-_深度学习_ 基于切片辅助超推理库SAHI优化小目标识别.html-DXPrJRsK.js" as="script"><link rel="prefetch" href="/assets/2024-03-18-_深度学习_ 计算机视觉低代码工具Supervision库使用指北.html-ZiRqUrdy.js" as="script"><link rel="prefetch" href="/assets/2024-08-28-_深度学习_ 时间序列分析工具TSLiB库使用指北.html-DjAY9Pmy.js" as="script"><link rel="prefetch" href="/assets/404.html-DL5E4Myf.js" as="script"><link rel="prefetch" href="/assets/index.html-spHAIfzD.js" as="script"><link rel="prefetch" href="/assets/index.html-D9_FOkE-.js" as="script"><link rel="prefetch" href="/assets/index.html-Ck2MGrT2.js" as="script"><link rel="prefetch" href="/assets/index.html-D6pywdou.js" as="script"><link rel="prefetch" href="/assets/index.html-DNATGme7.js" as="script"><link rel="prefetch" href="/assets/index.html-CTjf2JE2.js" as="script"><link rel="prefetch" href="/assets/index.html-BAVlAddV.js" as="script"><link rel="prefetch" href="/assets/index.html-pBpMib9a.js" as="script"><link rel="prefetch" href="/assets/index.html-DFZFAfLF.js" as="script"><link rel="prefetch" href="/assets/index.html-BQIdzVf2.js" as="script"><link rel="prefetch" href="/assets/index.html-DrJGFe_1.js" as="script"><link rel="prefetch" href="/assets/index.html-BOf2mMBV.js" as="script"><link rel="prefetch" href="/assets/index.html-CavossQ6.js" as="script"><link rel="prefetch" href="/assets/index.html-Cxc8Z56E.js" as="script"><link rel="prefetch" href="/assets/index.html-BxCRNUcX.js" as="script"><link rel="prefetch" href="/assets/index.html-sDoceBvy.js" as="script"><link rel="prefetch" href="/assets/index.html-DgkjKjBp.js" as="script"><link rel="prefetch" href="/assets/index.html-C4ctd7U5.js" as="script"><link rel="prefetch" href="/assets/index.html-PHzpoq_d.js" as="script"><link rel="prefetch" href="/assets/index.html-Ch815_W0.js" as="script"><link rel="prefetch" href="/assets/index.html-Qwyf6Sea.js" as="script"><link rel="prefetch" href="/assets/index.html-D3rLxY-q.js" as="script"><link rel="prefetch" href="/assets/index.html-eQQIo8_p.js" as="script"><link rel="prefetch" href="/assets/index.html-DPPgXLJX.js" as="script"><link rel="prefetch" href="/assets/index.html-PKycps04.js" as="script"><link rel="prefetch" href="/assets/index.html-DZfITK7i.js" as="script"><link rel="prefetch" href="/assets/index.html-DU8KOPkh.js" as="script"><link rel="prefetch" href="/assets/index.html-DEMlaehV.js" as="script"><link rel="prefetch" href="/assets/index.html-CrbabEKh.js" as="script"><link rel="prefetch" href="/assets/index.html-0_x3k21m.js" as="script"><link rel="prefetch" href="/assets/index.html-Bop2sxTg.js" as="script"><link rel="prefetch" href="/assets/index.html-TVo87Ywn.js" as="script"><link rel="prefetch" href="/assets/index.html-BhSjY7kx.js" as="script"><link rel="prefetch" href="/assets/index.html-B9WB-CtF.js" as="script"><link rel="prefetch" href="/assets/index.html-BS80GROF.js" as="script"><link rel="prefetch" href="/assets/index.html-CGz5mcco.js" as="script"><link rel="prefetch" href="/assets/index.html-BL-bl4RJ.js" as="script"><link rel="prefetch" href="/assets/index.html-CMCN_d9B.js" as="script"><link rel="prefetch" href="/assets/index.html-0mZTM0NG.js" as="script"><link rel="prefetch" href="/assets/index.html-BfcTqBBv.js" as="script"><link rel="prefetch" href="/assets/index.html-BZ9YcUIK.js" as="script"><link rel="prefetch" href="/assets/index.html-CBXkPQmq.js" as="script"><link rel="prefetch" href="/assets/index.html-D1v5XdAN.js" as="script"><link rel="prefetch" href="/assets/index.html-BWEGyzdm.js" as="script"><link rel="prefetch" href="/assets/index.html-CkTfgQ7S.js" as="script"><link rel="prefetch" href="/assets/index.html-D2BfPvvI.js" as="script"><link rel="prefetch" href="/assets/index.html-DsiiflnX.js" as="script"><link rel="prefetch" href="/assets/index.html-9eUixL2x.js" as="script"><link rel="prefetch" href="/assets/index.html-Bm3VySph.js" as="script"><link rel="prefetch" href="/assets/index.html-OjXnoQ6J.js" as="script"><link rel="prefetch" href="/assets/index.html-BbvRnWMi.js" as="script"><link rel="prefetch" href="/assets/index.html-DsCTkVyK.js" as="script"><link rel="prefetch" href="/assets/index.html-CngpDADv.js" as="script"><link rel="prefetch" href="/assets/index.html-RXjDRkHg.js" as="script"><link rel="prefetch" href="/assets/index.html-0JDkPf8v.js" as="script"><link rel="prefetch" href="/assets/index.html-B4thG9KU.js" as="script"><link rel="prefetch" href="/assets/index.html-Bh53xR-_.js" as="script"><link rel="prefetch" href="/assets/index.html-BqF0hLtp.js" as="script"><link rel="prefetch" href="/assets/index.html-BabG9mRO.js" as="script"><link rel="prefetch" href="/assets/index.html-BglY9gmt.js" as="script"><link rel="prefetch" href="/assets/index.html-CshLgANX.js" as="script"><link rel="prefetch" href="/assets/index.html-DNcsZCaI.js" as="script"><link rel="prefetch" href="/assets/index.html-yaoziJf4.js" as="script"><link rel="prefetch" href="/assets/index.html-BOG1lyKW.js" as="script"><link rel="prefetch" href="/assets/index.html-DVFnrhfv.js" as="script"><link rel="prefetch" href="/assets/index.html-C6lHMvkW.js" as="script"><link rel="prefetch" href="/assets/index.html-Bc-BDgyC.js" as="script"><link rel="prefetch" href="/assets/index.html-CFLlLqnW.js" as="script"><link rel="prefetch" href="/assets/index.html-BQWyDiXK.js" as="script"><link rel="prefetch" href="/assets/index.html-BB2KvgmW.js" as="script"><link rel="prefetch" href="/assets/index.html-HbDmAKCs.js" as="script"><link rel="prefetch" href="/assets/index.html-BHQISjH8.js" as="script"><link rel="prefetch" href="/assets/flowchart-CAFN9Lqb.js" as="script"><link rel="prefetch" href="/assets/mermaid.esm.min--lFWVmKn.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CMg0yb1C.js" as="script"><link rel="prefetch" href="/assets/browser-CYdOP0d3.js" as="script"><link rel="prefetch" href="/assets/SearchResult-iwP-VDpG.js" as="script"><link rel="prefetch" href="/assets/setupDevtools-7MC2TMWH-DN4UOMwf.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="博客主页" iconsizing="height"><!--[--><i class="vp-icon fas fa-home" sizing="height"></i><!--]-->博客主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link route-link-active auto-link" href="/blog/" aria-label="个人博客" iconsizing="height"><!--[--><i class="vp-icon fas fa-blog" sizing="height"></i><!--]-->个人博客<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="关于"><!--[--><i class="vp-icon fas fa-user-plus" sizing="height"></i>关于<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/intro.html" aria-label="关于我" iconsizing="both"><!--[--><i class="vp-icon fas fa-user fa-fw" sizing="both"></i><!--]-->关于我<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/about.html" aria-label="关于本站" iconsizing="both"><!--[--><i class="vp-icon fas fa-circle-info fa-fw" sizing="both"></i><!--]-->关于本站<!----></a></li></ul></button></div></div></nav><!--]--></div><div class="vp-navbar-center"><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://blog.csdn.net/LuohenYJ" target="_blank" title="开往我的csdn" rel="noopener noreferrer" aria-label="travelling"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" fill="currentColor" style="width:1.25rem;height:1.25rem;vertical-align:middle"><path d="M658.836 519.32c-22.121 0-40.145 18.431-40.145 40.957 0 22.528 18.023 40.962 40.145 40.962 22.117 0 40.141-18.434 40.141-40.962 0-22.526-18.024-40.957-40.141-40.957zM364.742 519.32c-22.121 0-40.141 18.431-40.141 40.957 0.41 22.528 18.02 40.962 40.141 40.962 22.117 0 40.141-18.434 40.141-40.962 0-22.526-18.024-40.957-40.141-40.957z" p-id="8700"></path><path d="M512 0C229.23 0 0 229.23 0 512s229.23 512 512 512 512-229.23 512-512S794.77 0 512 0z m133.727 804.81c0 7.375-6.145 13.52-13.516 13.52H391.773c-7.371 0-13.515-6.145-13.515-13.52v-13.516c0-7.371 6.144-13.517 13.515-13.517h240.438c7.371 0 13.516 6.146 13.516 13.517v13.516z m120.832 37.273c-12.289 6.965-27.441 2.867-34.406-9.418l-54.887-96.668c-4.504 0.82-9.422 1.23-13.926 1.23H361.054c-4.914 0-9.421-0.41-13.925-1.23l-54.887 96.668c-6.965 12.285-22.527 16.383-34.406 9.418-12.289-6.961-16.383-22.938-9.422-35.223l51.199-90.113c-27.031-19.66-43.418-52.43-40.957-88.883l19.25-293.273c3.277-49.152 34.406-88.066 87.246-88.066h80.281c0-37.684 29.899-67.993 66.762-67.993 36.868 0 66.766 30.309 66.766 67.993h93.391c53.246 0 70.449 38.914 73.727 88.066l19.25 293.273c2.461 36.453-13.926 69.223-40.957 88.883l51.199 90.113c6.964 12.696 2.867 28.262-9.012 35.223z" p-id="8701"></path><path d="M672.352 314.931H351.633c-14.747 0-26.622 12.285-26.622 27.441v108.953c0 15.157 11.875 27.446 26.622 27.446h320.719c14.746 0 26.625-12.289 26.625-27.446V342.372c0-15.156-11.879-27.441-26.625-27.441z" p-id="8702"></svg></a></div><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/luohenyueji" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-outlook-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon" name="outlook"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="vp-outlook-dropdown"><!----></div></button></div><!--[--><button type="button" class="slimsearch-button" aria-label="搜索"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="slimsearch-placeholder">搜索</div><div class="slimsearch-key-hints"><kbd class="slimsearch-key">Ctrl</kbd><kbd class="slimsearch-key">K</kbd></div></button><!--]--><!--]--></div><div class="vp-navbar-end"><!--[--><a class="route-link vp-brand" href="/" aria-label="带我回家"><img class="vp-nav-logo" src="/logo.png" alt><!----><span class="vp-site-name hide-in-pad">落痕月极的博客</span></a><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="博客主页" iconsizing="both"><!--[--><i class="vp-icon fas fa-home fa-fw" sizing="both"></i><!--]-->博客主页<!----></a></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><i class="vp-icon fas fa-blog fa-fw" sizing="both"></i><span class="vp-sidebar-title">博客</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">编程基础</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">常用工具</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">机器学习</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">讲座论坛</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">论文总结</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">能源化工与仪器科学</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">深度学习</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">大模型</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/2024-12-31-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A01-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html" aria-label="[深度学习] 大模型学习1-大语言模型基础知识" iconsizing="both"><!---->[深度学习] 大模型学习1-大语言模型基础知识<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/2025-02-28-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A02-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8C%97.html" aria-label="[深度学习] 大模型学习2-提示词工程指北" iconsizing="both"><!---->[深度学习] 大模型学习2-提示词工程指北<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/2025-07-21-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03%E4%B8%8A-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83.html" aria-label="[深度学习] 大模型学习3上-模型训练与微调" iconsizing="both"><!---->[深度学习] 大模型学习3上-模型训练与微调<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/2025-07-23-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A03%E4%B8%8B-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83.html" aria-label="[深度学习] 大模型学习3下-模型训练与微调" iconsizing="both"><!---->[深度学习] 大模型学习3下-模型训练与微调<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/2025-08-08-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A04-RAG%E6%8A%80%E6%9C%AF%E5%85%A8%E6%99%AF%E8%A7%A3%E6%9E%90.html" aria-label="[深度学习] 大模型学习4-RAG技术全景解析" iconsizing="both"><!---->[深度学习] 大模型学习4-RAG技术全景解析<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">深度学习笔记</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">数据分析与可视化</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">数学理论</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">随笔所想</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">图像处理</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">音视频处理</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">自然语言处理与语音识别</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">OpenCV</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Python</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">R语言</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->[深度学习] 大模型学习1-大语言模型基础知识</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="/" target="_blank" rel="noopener noreferrer">落痕月极</a></span><span property="author" content="落痕月极"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025年1月1日</span><meta property="datePublished" content="2024-12-31T22:21:03.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 55 分钟</span><meta property="timeRequired" content="PT55M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color4 clickable" role="navigation">深度学习</span><!--]--><meta property="articleSection" content="深度学习"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color4 clickable" role="navigation">深度学习</span><span class="page-tag-item color2 clickable" role="navigation">自然语言处理与语音识别</span><!--]--><meta property="keywords" content="深度学习,自然语言处理与语音识别"></span></div><hr></div><div class="vp-toc-placeholder"><aside id="toc" vp-toc><!----><!--[--><div class="vp-toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_1-llm基础知识">1 LLM基础知识</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-1-llm介绍">1.1 LLM介绍</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-2-llm训练范式">1.2 LLM训练范式</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-3-transformer结构解析">1.3 Transformer结构解析</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-4-llm扩展应用">1.4 LLM扩展应用</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_2-llm训练概览">2 LLM训练概览</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-1-llm推理过程">2.1 LLM推理过程</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-2-llm应用构建">2.2 LLM应用构建</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-3-llm评估">2.3 LLM评估</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-4-llm量化、部署、优化">2.4 LLM量化、部署、优化</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_3-总结">3 总结</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_4-参考">4 参考</a></li><!----><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!--]--><!----></aside></div><!----><div class="theme-hope-content" vp-content><h1 id="深度学习-大模型学习1-大语言模型基础知识" tabindex="-1"><a class="header-anchor" href="#深度学习-大模型学习1-大语言模型基础知识"><span>[深度学习] 大模型学习1-大语言模型基础知识</span></a></h1><p>大语言模型（Large Language Model，LLM）是一类基于Transformer架构的深度学习模型，主要用于处理与自然语言相关的各种任务。简单来说，当用户输入文本时，模型会生成相应的回复或结果。它能够完成许多任务，如文本续写、分类、摘要、改写、翻译等。常见的LLM包括GPT、LLaMA等。本文将重点介绍LLM的基本原理和应用。详细内容可参考<a href="https://github.com/modelscope/modelscope-classroom" target="_blank" rel="noopener noreferrer">modelscope-classroom</a>进行深入学习。</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img0.gif" alt="https://github.com/onejune2018/Awesome-LLM-Eval" tabindex="0" loading="lazy"><figcaption>https://github.com/onejune2018/Awesome-LLM-Eval</figcaption></figure><h2 id="_1-llm基础知识" tabindex="-1"><a class="header-anchor" href="#_1-llm基础知识"><span>1 LLM基础知识</span></a></h2><h3 id="_1-1-llm介绍" tabindex="-1"><a class="header-anchor" href="#_1-1-llm介绍"><span>1.1 LLM介绍</span></a></h3><p><strong>LLM发展历程</strong></p><p>2022年11月30日，OpenAI推出的ChatGPT在LLM技术领域取得了创新突破，迅速引起了全球业界的广泛关注，并在短短两个月内成功吸引了超过一亿用户。作为一款基于LLM的应用，ChatGPT以其强大的文本生成、对话交互和信息提取能力，成为人工智能领域的一个重要里程碑，推动了人机交互的边界。然而，由于OpenAI未公开其底层技术并封闭源代码，这引发了全球AI开发者对开源技术的强烈需求。</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img1.jpg" alt="https://www.appeconomyinsights.com/p/threads-fastest-growing-app-in-history" tabindex="0" loading="lazy"><figcaption>https://www.appeconomyinsights.com/p/threads-fastest-growing-app-in-history</figcaption></figure><p>随着LLM技术的飞速发展，Meta推出的LLaMA模型、Mistral AI发布的Mistral模型以及BigScience团队推出的BLOOM模型等多个开源LLM相继问世。这些模型在性能上已接近甚至媲美商业化LLM，进一步推动了LLM技术的广泛应用与创新。以下是几款代表性LLM系列的发展时间线，展现了这一领域的迅猛进步：</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img2.jpg" alt="https://arxiv.org/pdf/2306.13549" tabindex="0" loading="lazy"><figcaption>https://arxiv.org/pdf/2306.13549</figcaption></figure><p>到2024年底，在众多LLM中，闭源模型中表现最为出色的是GPT-4，而在开源模型中，LLama 3.3和LLama 3.2最为推荐。尽管LLama 3.2在各类基准测试中优于GPT-4，但在实际应用中，GPT-4的表现仍然更为卓越：</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img3.jpg" alt="https://onegen.ai/llama-3-2-models-comparison-use-cases-and-fine-tuning/" tabindex="0" loading="lazy"><figcaption>https://onegen.ai/llama-3-2-models-comparison-use-cases-and-fine-tuning/</figcaption></figure><p><strong>LLM的“大”体现在哪些方面？</strong></p><ol><li>庞大的参数量：LLM的“大”首先体现在参数数量上。例如，OpenAI的GPT-3有1750亿个参数，GPT-4更为庞大。参数越多，模型的语言理解和任务处理能力越强。</li><li>海量的训练数据：LLM依赖海量数据进行训练，包括书籍、新闻、网页内容和社交媒体等。这些多样化的数据帮助模型掌握丰富的语言模式，具备强大的理解和生成能力。</li><li>广泛的任务适应性：模型在多种数据上训练，赋予其从自然语言理解到翻译、摘要、情感分析等多任务的处理能力，使其具备显著的通用性。</li><li>巨大的计算资源需求：LLM的训练与推理依赖大量高性能计算资源，如GPU和专用加速器。随着模型规模的增加，计算需求呈指数级增长。</li></ol><p><strong>LLM为什么要基于Transformer架构？</strong></p><p>在Transformer架构出现之前，自然语言模型主要依赖循环神经网络（RNN），但RNN的顺序处理方式限制了计算的并行性，且在处理长序列时，信息容易丢失或遗忘。</p><p>Transformer通过引入自注意力机制和位置编码，克服了传统模型在捕捉长距离依赖和并行计算方面的局限。自注意力机制允许模型同时关注输入序列中的所有词，捕捉更远距离的依赖关系，避免了RNN及其变体LSTM模型中存在的顺序处理瓶颈。因此，Transformer成为大规模预训练模型的基础架构，并在多个任务中展现了出色的性能。</p><h3 id="_1-2-llm训练范式" tabindex="-1"><a class="header-anchor" href="#_1-2-llm训练范式"><span>1.2 LLM训练范式</span></a></h3><p><strong>LLM训练阶段</strong></p><p>LLM的训练可分为以下四个关键阶段：</p><ol><li><p>预训练（Unsupervised Pretraining）：构建基座模型。</p><ul><li>数据来源：广泛采集的书籍、新闻、科研论文、社交媒体等多领域文本数据，作为模型训练的素材。</li><li>学习目标：利用无监督学习技术，使模型能够根据上下文预测下一个词。</li><li>训练过程：不依赖标注数据，通过不断优化模型预测与实际结果之间的差异，随着数据量的增加，逐步提升模型的性能。</li></ul></li><li><p>有监督微调（Supervised Fine-Tuning，SFT）：打造对话模型。</p><ul><li>数据来源：采用人工标注的对话数据，以提高模型在对话任务中的表现。</li><li>学习目标：通过有针对性的训练，增强模型与用户互动的能力。</li><li>训练过程：使用少量但高质量的对话数据进行微调，显著提高模型的对话能力。</li></ul></li><li><p>奖励模型训练（Reward Model Training）：培养能够评估回答的模型。</p><ul><li>数据来源：生成多个候选答案，并依据人工评分和排序进行评估。</li><li>学习目标：培养奖励模型，利用评分数据来评估和优化模型生成的答案质量。</li><li>训练过程：奖励模型根据人工评分提供反馈，引导模型生成更符合人类预期的答案，这个过程也常被称为人类对齐训练（alignment）。</li></ul></li><li><p>强化学习训练（Reinforcement Learning with Human Feedback，RLHF）：进一步提升对话模型的回答质量。</p><ul><li>数据来源：利用第三步训练好的奖励模型，通过强化学习进一步优化第二步训练好的对话模型。</li><li>学习目标：依据奖励模型的反馈调整生成策略，提高模型回答的质量。</li><li>训练过程：模型根据奖励评分调整其策略，并结合用户反馈，进一步改进生成答案的质量。</li></ul></li></ol><p>这一过程可以用<a href="https://arxiv.org/abs/2307.09288" target="_blank" rel="noopener noreferrer">Llama 2</a>论文中的示例图片更为直观地展示：</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img4.jpg" alt="https://arxiv.org/abs/2307.09288" tabindex="0" loading="lazy"><figcaption>https://arxiv.org/abs/2307.09288</figcaption></figure><p><strong>基座模型和对话模型</strong></p><p>在LLM的训练过程中，主要有两种模型类型：基座模型（Base模型）和对话模型（Chat模型）。两者的工作方式相似，都是通过预测文本的后续内容来进行训练。Base模型经过了预训练，可能进行了部分通用指令的微调；而Chat模型则在Base模型的基础上，进一步通过大量通用数据的微调和人类反馈的训练来优化性能。虽然“指令模型”（Instruction Model）这一术语有时也被提及，但它与Chat模型本质上是相同的，都是通过指令微调和强化学习对Base模型进行优化，以提高其理解和生成能力。</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img5.jpg" alt="https://journals.sagepub.com/doi/full/10.1177/17562848241227031" tabindex="0" loading="lazy"><figcaption>https://journals.sagepub.com/doi/full/10.1177/17562848241227031</figcaption></figure><p>开源LLM的研究机构通常会同时发布Base模型和Chat模型，以满足不同的需求。例如，Llama 2（Base模型）和Llama 2-Chat（Chat模型）。Base模型主要侧重于泛化能力，通常仅经过预训练，具备基本的文本补全功能，但缺乏对话上下文的理解，因此在与人类对话时，回答往往显得较为生硬、感觉在背书。而Chat模型则在Base模型的基础上进行优化和调整，增强了对话能力和自然语言理解，生成的回答更加自然。两者具体对比如下：</p><table><thead><tr><th>维度</th><th>Base模型</th><th>Chat模型</th></tr></thead><tbody><tr><td>训练方式</td><td>预训练</td><td>预训练+监督微调（SFT）+强化学习（RLHF）</td></tr><tr><td>数据来源</td><td>大量未标注文本数据</td><td>标注好的对话数据集、人类对齐</td></tr><tr><td>模型特性</td><td>庞大的参数规模，具备广泛的语言特征</td><td>强大的对话生成和理解能力，能够生成连贯且有意义的回复</td></tr><tr><td>应用场景</td><td>适用于多种NLP任务，如文本生成、语义理解、翻译等</td><td>专门用于构建聊天机器人、虚拟助理等对话系统</td></tr><tr><td>优势</td><td>泛化能力强，适用于多种任务</td><td>对话能力强，能够生成符合人类偏好的回复</td></tr><tr><td>不足</td><td>可能需要进一步的微调才能适应特定任务</td><td>相对于Base模型，训练过程更复杂</td></tr></tbody></table><h3 id="_1-3-transformer结构解析" tabindex="-1"><a class="header-anchor" href="#_1-3-transformer结构解析"><span>1.3 Transformer结构解析</span></a></h3><p>LLM通过预测下一个词生成高质量文本，这得益于强大的Transformer架构。Transformer的基本结构包括输入嵌入、编码器、解码器和输出层。编码器和解码器通过多层堆叠的自注意力机制和前馈神经网络相互作用，进而实现复杂的序列处理任务。自注意力机制使得Transformer能够在全局范围内捕捉词语之间的依赖关系，这是其处理长序列和大量数据的关键优势。</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img6.jpg" alt="https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder" tabindex="0" loading="lazy"><figcaption>https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder</figcaption></figure><p><strong>Transformer编码器</strong></p><p>Transformer的编码器部分主要包括以下几个步骤：</p><ol><li>输入token化：将输入文本拆分为可以被计算机处理的token，每个token对应词汇表中的一个索引。</li><li>嵌入层：将这些token转换为向量表示，捕捉词汇之间的语法和语义关系。</li><li>位置编码：给嵌入向量添加位置信息，帮助模型理解词在句子中的顺序。</li><li>自注意力机制：这是编码器的核心，通过计算每个词与其他词之间的相关性，确定注意力权重，捕捉输入序列中的重要信息。</li><li>多头自注意力：使用多个“头”来分别关注输入数据的不同方面，增强模型的表达能力。</li><li>前馈神经网络：对多头自注意力的输出进行处理，帮助模型识别更复杂的模式。</li><li>堆叠编码器：将多个编码器层叠加在一起，让模型能够在不同层次上理解输入数据，从而逐步提炼信息。</li></ol><p><strong>Transformer解码器</strong></p><p>Transformer解码器的工作流程可以简化为以下几个步骤：</p><ol><li>输入处理：解码器接收上一个时间步的输出和编码器的输出。初始步骤时，输入通常是一个特殊的起始标记（如 <code>&lt;sos&gt;</code>）或先前生成的结果。</li><li>嵌入和位置编码：解码器将每个输入词转化为向量，并加入位置编码，使模型知道词在序列中的位置。</li><li>自注意力机制（带掩码）：解码器的自注意力机制只关注当前词之前的词，通过掩码确保模型生成下一个词时只依赖已生成的部分，从而实现自回归生成。</li><li>编码器-解码器注意力：解码器通过这个机制关注编码器的输出，帮助理解输入序列，从而生成更合适的输出。</li><li>前馈神经网络和解码器堆叠：解码器使用前馈神经网络对注意力输出进行处理，并通过多层堆叠提升对输入输出关系的理解，生成更复杂的结果。</li><li>线性层和Softmax：解码器将输出转化为词汇表大小的向量，通过Softmax层生成词的概率分布。</li><li>选择输出：模型选择概率最高的词作为下一个输出，直到生成结束标记（如 <code>&lt;eos&gt;</code>），完成整个序列的生成。</li></ol><p>解码器中的多头自注意力机制与编码器类似，但采用遮蔽处理，以防模型关注未来词语。这样，模型在预测位置<mjx-container class="MathJax" jax="SVG" style="position:relative;"><svg style="vertical-align:-0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewBox="0 -661 345 672" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></mjx-assistive-mml></mjx-container>的输出时，仅依赖于位置<mjx-container class="MathJax" jax="SVG" style="position:relative;"><svg style="vertical-align:-0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewBox="0 -661 345 672" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></mjx-assistive-mml></mjx-container>之前的已知信息。如下图所示，解码器逐步生成每个单词：</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img7.jpg" alt="https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder" tabindex="0" loading="lazy"><figcaption>https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder</figcaption></figure><p><strong>LLM中的Transformer</strong></p><p>Transformer架构是一种非常灵活且强大的神经网络结构，已经被广泛应用于各种自然语言处理任务。根据不同的任务需求，Transformer的架构可以分为几种不同的类型，每种类型都有其特定的优点和用途。以下是这几种主要结构的特点：</p><ol><li><p>仅编码器模型（自编码器模型）</p><ul><li>主要用途： 仅编码器模型通常用于从输入数据中提取有用的特征信息，进行理解或表示学习。这些模型不需要生成输出，而是侧重于学习输入的上下文和表示。</li><li>工作方式： 编码器的作用是将输入的序列通过多层的自注意力机制和前馈神经网络处理，最终将其转化为一个固定长度的向量或一组向量。</li><li>应用： 这类模型在需要提取深度特征或做文本分类、情感分析等任务时非常有效。它们不涉及生成过程，而是通过理解和表示输入数据来完成任务。</li><li>代表模型： <ul><li>BERT（双向编码器表示模型）： BERT是一种双向编码器，它通过“遮蔽”输入中的某些单词来训练模型，让模型预测这些被遮蔽的单词，从而获得输入文本的深层次理解。BERT的预训练后可以通过微调应用于多种任务，如文本分类、命名实体识别（NER）、问答等。</li></ul></li></ul></li><li><p>仅解码器模型（自回归模型）</p><ul><li>主要用途： 解码器模型通常用于生成任务，尤其是序列生成任务，如文本生成、对话生成等。这类模型的目标是从给定的输入或上下文中生成连贯的输出。</li><li>工作方式： 解码器采用自回归的方式生成序列，它会基于已生成的词或标记不断预测下一个词，直到生成完整的输出。</li><li>应用： 解码器模型广泛应用于需要生成连续文本的任务，比如机器翻译、文本生成、代码生成等。</li><li>代表模型： <ul><li>GPT：基于Transformer的解码器结构，采用自回归方式生成文本。在训练过程中，它通过大量的文本数据学习语言模式，并通过不断预测下一个词生成连贯的文章。GPT系列（如GPT-3、GPT-4）已经成为文本生成任务中的重要模型。</li></ul></li></ul></li><li><p>编码器-解码器模型（序列到序列模型）</p><ul><li>主要用途： 编码器-解码器模型适用于需要将一个输入序列映射到一个输出序列的任务，例如机器翻译、文本摘要、图像描述等。这种结构通常包含两个部分：编码器负责理解输入序列，解码器负责生成输出序列。</li><li>工作方式： 编码器首先处理输入序列，将其转化为一个中间的表示（通常是一个上下文向量），然后解码器基于该表示生成输出序列。解码器可以使用自回归方式来逐步生成输出。</li><li>应用： 这类模型适用于任何需要将一个序列转换为另一个序列的任务，常见的应用场景包括机器翻译、摘要生成、对话生成等。</li><li>代表模型： <ul><li>T5：将所有任务统一转换为文本到文本的任务，即输入和输出都是文本形式。它结合了编码器和解码器的结构，可以用于机器翻译、文本摘要、问答等多种任务。</li><li>BART：一种结合了BERT和GPT优点的模型，使用编码器-解码器架构，既能够进行双向的理解，又能进行自回归的生成。它特别适用于文本生成、序列到序列的转换等任务。</li></ul></li></ul></li></ol><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img8.jpg" alt="https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder" tabindex="0" loading="lazy"><figcaption>https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder</figcaption></figure><p>然而随着技术发展，Transformer架构不断优化，尤其是LLM（GPT系列）取得突破后，解码器模型变得更加流行，而编码器-解码器模型逐渐不再主流，原因如下：</p><ol><li>简洁高效：解码器模型结构简单，训练和推理时更加高效。</li><li>更佳上下文理解：解码器专注于生成任务，能更好地理解上下文，生成连贯、符合语境的文本。</li></ol><h3 id="_1-4-llm扩展应用" tabindex="-1"><a class="header-anchor" href="#_1-4-llm扩展应用"><span>1.4 LLM扩展应用</span></a></h3><p>为了应对日益复杂的任务需求，一些新型的大模型应运而生，它们对单一LLM的能力进行了扩展和补充。这些模型主要包括多模态大语言模型、LLM智能体（Agent）、垂直领域LLM等。以下是对这些模型的简要介绍：</p><ol><li><p>多模态大语言模型 (Multimodal Large Language Models)</p><p>多模态大语言模型通过融合文本、图像、视频和音频等多种信息，能够同时处理不同类型的输入，生成更丰富的语义理解。与传统模型不同，它在多元数据训练下显著提升了对各类数据的理解能力，展现出更强的任务适应性和通用性。例如，在图像描述任务中，模型结合图像和文本生成精准自然的语言；在音频处理任务中，通过融合音频和文本信息，提高语音识别和语义理解的准确性。</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img9.jpg" alt="https://arxiv.org/abs/2306.09093" tabindex="0" loading="lazy"><figcaption>https://arxiv.org/abs/2306.09093</figcaption></figure></li><li><p>LLM智能体（Agent）</p><p>LLM智能体（Agent）是基于LLM的人工智能系统，它能够理解、生成和处理语言，以执行各种任务。与传统的程序或工具不同，智能体不仅能够提供信息和答案，还能根据上下文进行自主推理、决策和行动。通过与用户的互动，它可以处理复杂的问题，提供个性化建议，并完成诸如对话、文本生成、翻译、问答等多种任务。智能体的核心是成熟的LLM，它通过大量的语料库学习语言的结构和含义，不断优化其理解和生成能力。</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img10.jpg" alt="https://blog.abacus.ai/blog/2023/08/31/supercharge-productivity-accomplish-10x-more-with-ai-agents/" tabindex="0" loading="lazy"><figcaption>https://blog.abacus.ai/blog/2023/08/31/supercharge-productivity-accomplish-10x-more-with-ai-agents/</figcaption></figure></li><li><p>垂直领域LLM</p><p>垂直领域LLM是指专门针对某一特定行业或应用场景进行训练和优化的LLM。这类模型与通用LLM不同，它们在处理特定领域的问题时表现出更强的专业性和精确性。垂直领域LLM通常会利用行业专有的数据和知识进行训练，从而提高在该领域内的表现。 例如，在代码生成上，它能根据需求自动生成高质量代码，减少开发时间与错误；在医学领域，它协助医生分析病历、解读检查结果，并提出诊断与治疗建议，提升诊疗效率；在法律咨询中，模型帮助解析法律条文、提供法律意见，让用户更清晰地理解法律问题和风险；在金融分析中，它能分析市场趋势、预测股市走向，为投资者提供数据支持；在客户服务方面，它能自动处理咨询、快速回应问题，提高服务质量；在技术支持中，它能识别技术问题并提供解决方案，保障用户体验。</p></li></ol><h2 id="_2-llm训练概览" tabindex="-1"><a class="header-anchor" href="#_2-llm训练概览"><span>2 LLM训练概览</span></a></h2><h3 id="_2-1-llm推理过程" tabindex="-1"><a class="header-anchor" href="#_2-1-llm推理过程"><span>2.1 LLM推理过程</span></a></h3><p>LLM推理是指在训练完成后，利用训练好的模型对新数据进行预测或生成的过程。通过LLM解决实际问题，如回答问题、生成文案等，便是在进行模型推理。可以认为，模型推理是LLM应用的核心环节。 在推理阶段，LLM根据输入的提示（prompt）以及先前生成的内容，逐步预测下一个词或标记（token）。这一过程持续进行，直到生成完整的句子或多个句子。因而这类模型被称为自回归模型（autoregressive Model）。</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img11.jpg" alt="https://www.omrimallis.com/posts/understanding-how-llm-inference-works-with-llama-cpp/" tabindex="0" loading="lazy"><figcaption>https://www.omrimallis.com/posts/understanding-how-llm-inference-works-with-llama-cpp/</figcaption></figure><p>在推理阶段，单个词生成的过程如下所示：</p><ol><li>提示（Prompt）作为输入文本，用来引导模型生成特定类型的回应或输出。首先，分词器会将提示文本拆分成一系列的标记（tokens）。根据模型的词汇表，一些单词可能会被拆成多个标记，每个标记都会对应一个唯一的数字。接下来，这些数字会被数字转化成固定长度的向量嵌入（embedding）。所有的向量合起来形成一个embedding矩阵，作为模型的输入。</li><li>Embedding矩阵首先通过Transformer层进行处理，Transformer由多个堆叠的子层组成，每一层的输出作为下一层的输入。每个子层包含自注意力机制，能够在处理当前输入时综合考虑序列中其他位置的信息，从而捕捉全局依赖关系。与此同时，经过每一层处理后，输入矩阵的维度保持不变。</li><li>在Transformer层处理后，模型生成logits，这些logits表示每个可能token的预测分数。然后通过softmax函数将logits 转换为概率分布，并使用多种采样技术（如贪心解码、top-k采样或top-p采样等）之一从概率分布中选择下一个token。</li><li>上一步所选的token会被附加到当前生成的token序列中。然后，新的token序列作作为输入，模型会再次执行步骤1至步骤3的过程生成后续token。生成后续token。此过程会持续进行，直到模型生成特殊的结束标记（EOS），或达到预设的token数量。</li></ol><h3 id="_2-2-llm应用构建" tabindex="-1"><a class="header-anchor" href="#_2-2-llm应用构建"><span>2.2 LLM应用构建</span></a></h3><p>构建LLM应用时，选择合适的方法整合专有和领域数据是关键一步，常用的方式包括提示词工程（Prompt Engineering）、模型训练与微调、以及检索增强生成（RAG，Retrieval-Augmented Generation）等。</p><h4 id="_2-2-1-提示词工程" tabindex="-1"><a class="header-anchor" href="#_2-2-1-提示词工程"><span>2.2.1 提示词工程</span></a></h4><p>提示词工程通是用户和LLM互动中最常用的方式。提示词工程通过设计和优化输入给模型的提示词（如问题或指令），帮助模型生成更加准确、符合需求的回答。相当于在告诉模型应该关注哪些信息或如何理解问题。可以把它理解为学会提出正确的问题，以获得最佳的答案。不过，能从中获得的帮助是有限的，因为模型的回答只能基于它已经学到的信息。</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img12.jpg" alt="https://myscale.com/blog/prompt-engineering-vs-finetuning-vs-rag/" tabindex="0" loading="lazy"><figcaption>https://myscale.com/blog/prompt-engineering-vs-finetuning-vs-rag/</figcaption></figure><p>提示词工程的优缺点以及适用环境如下所示：</p><p>优点：</p><ol><li>易用：操作简单，无需专业技术，任何用户都能轻松上手。</li><li>成本低：使用预训练模型，计算开销小，比微调方式更具成本效益。</li><li>灵活：可以快速调整提示内容，探索不同的结果，无需重新训练模型。</li></ol><p>缺点：</p><ol><li>一致性差：模型的响应质量可能因提示的措辞不同而产生较大的差异。</li><li>定制化受限：回答的个性化程度取决于提示的设计和技巧，定制能力有限。</li><li>知识局限：输出依赖于模型训练时获得的知识，无法处理过于专业或最新的信息。</li></ol><p>适用环境：</p><ol><li>模型能力视情况而定：提示词工程的效果依赖于所用模型的能力。在使用前，用户应评估模型是否具备处理业务问题的基础能力。若模型基础能力较强，提示词工程可作为快速、高效的解决方案。</li><li>适合通用任务和简单场景：与其他深度学习技术相比，提示词工程的开发门槛较低，适用于常识问答、文本生成、情感分析、角色扮演等通用任务和简单应用。</li></ol><p>对于提示词工程的应用，Zero-Shot Learning（零样本学习）和Few-Shot Learning（少样本学习）是两种常见的提示词策略，它们在帮助用户获取所需内容时各有特点。以下是对这两种学习模式及其应用的进一步扩展说明：</p><p><strong>Zero-Shot Learning</strong></p><p>在Zero-Shot Learning模式下，用户提出任务时并不提供任何示例或样本，模型依赖于其预先学习的知识和语言能力直接生成答案。这样的模式适用于当用户需要一种快速、直接的生成内容方式，且不想提供或不需要提供额外的训练数据或背景信息。</p><p>举例来说，如果用户想了解宠物狗的基本情况，可以在LLM应用中通过一个简洁、明确的提示词来引导模型生成所需的内容：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>请写一段介绍宠物狗的文字，描述一下它的外观、性格特点以及和人类相处的情况。</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>此时，模型基于其在大量文本数据中学习到的语言规律和知识，能够从各类资料中提取信息，生成一段介绍宠物狗的文字，涵盖它的外观、性格以及与人类的互动方式。例如，模型可能会生成如下内容：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>宠物狗通常体型适中，拥有毛茸茸的皮毛，种类繁多，常见的有短毛、长毛、卷毛等。它们的耳朵形状、眼睛颜色和尾巴的长短各不相同。性格上，狗狗一般忠诚、活泼，喜爱与人类互动，是非常好的家庭伴侣。它们常常热情迎接主人，喜欢与家人一起散步、玩耍。狗狗特别喜欢获得主人的关注和奖励，在日常生活中会表现出对主人的深厚感情。</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这种生成方式快速高效，适合快速获取一些普遍性信息。</p><p><strong>Few-Shot Learning</strong></p><p>与Zero-Shot Learning不同，Few-Shot Learning是通过提供少量示例或样本来帮助模型更好地理解任务要求。通过这些示例，模型能够更准确地理解输入和输出之间的关系，从而提高生成内容的质量。此方式在某些情况下会更加精确，尤其是当用户有特定需求时，示例可以帮助引导模型产生更符合预期的回答。</p><p>例如，以下是一个典型的Few-Shot Learning的提示词示例：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>以下是几个描述动物的示例，请你按照这样的格式写一段介绍宠物狗的文字，描述它的外观、性格特点以及和人类相处的情况。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>示例 1：</span></span>
<span class="line"><span>   动物：猫咪</span></span>
<span class="line"><span>   外观：猫咪体型较小，毛茸茸的身体，眼睛大而明亮，耳朵尖尖，尾巴长而灵活，走路时轻盈优雅。</span></span>
<span class="line"><span>   性格特点：猫咪性格独立，喜欢自己待着，但也会对主人撒娇，开心时会发出呼噜声。</span></span>
<span class="line"><span>   和人类相处：它喜欢依偎在主人身边，陪伴主人休息或看电视，偶尔会捣乱，但总是给家庭带来温馨感。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>示例 2：</span></span>
<span class="line"><span>   动物：兔子</span></span>
<span class="line"><span>   外观：兔子身体小巧，耳朵长而竖立，眼睛圆润，嘴巴三瓣，后腿强壮，蹦跳时非常可爱。</span></span>
<span class="line"><span>   性格特点：兔子性格温顺胆小，喜欢啃食干草和胡萝卜，平时安静乖巧。</span></span>
<span class="line"><span>   和人类相处：兔子是孩子们的好伙伴，可以被抱在怀里抚摸，吃东西时很治愈。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>请写一段介绍宠物狗的文字：</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在这个示例中，通过提供两个不同动物的描述，LLM能够识别出描述结构和内容的相似性，从而在生成宠物狗的描述时保持一致的格式和逻辑结构。在LLM应用中使用该提示词，生成的内容可能是：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>动物：宠物狗</span></span>
<span class="line"><span>外观：宠物狗体型从小巧到中等大小不等，毛发种类繁多，有短毛、长毛或卷毛。它们的眼睛明亮，耳朵多为立耳或垂耳，尾巴通常是卷曲或直的，走动时充满活力。</span></span>
<span class="line"><span>性格特点：宠物狗通常友好、忠诚，喜欢与人类互动，性格开朗，适合做家庭宠物。它们非常聪明，能够学会一些基本的指令，喜欢参与户外活动。</span></span>
<span class="line"><span>和人类相处：狗狗是人类的忠实伙伴，喜欢陪伴主人，无论是散步、玩耍还是安静地待在主人身边，都会表现出对主人的深厚情感。狗狗还会通过摇尾巴、撒娇等方式表达情感，是非常合适的家庭宠物。</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_2-2-2-模型训练与微调" tabindex="-1"><a class="header-anchor" href="#_2-2-2-模型训练与微调"><span>2.2.2 模型训练与微调</span></a></h4><p>LLM的训练通过海量数据学习语言规律和知识，而微调则是在特定任务或领域上对已经训练好的模型进行优化，以便更好地满足具体需求。训练LLM通常需要巨大的显存和长时间的训练周期，受限于成本。微调常常通过在已有的LLM模型上附加额外结构、冻结原模型的参数，仅训练新结构，从而降低计算开销。在推理阶段，额外结构可以与原模型合并（但并非所有结构都支持合并）。目前，LoRA（低秩适配）是最流行的微调方法，它具有简单的结构和较低的训练成本，并在部分任务上能够接近全量微调的效果。</p><p>微调使模型能够学习新知识或调整生成结果。通过向已训练好的LLM提供额外数据，微调会改变模型的权重，从而更好地控制生成内容。与全量训练相比，微调通常是一个相对轻量的过程，且往往只需少量数据便能在特定任务上显著提升性能。然而，微调也可能带来意想不到的副作用，甚至可能削弱模型的通用能力，因此需要谨慎评估其效果。</p><p>对于大多数公司来说，微调模型是一种更加经济、高效和灵活的选择，尤其是在LLM已经预训练的情况下。公司无需承担从零开始训练模型的高昂成本和技术难题，只需关注特定领域的定制化需求。</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img13.jpg" alt="https://clive-gomes.medium.com/pre-training-large-language-models-at-scale-d2b133d5e219" tabindex="0" loading="lazy"><figcaption>https://clive-gomes.medium.com/pre-training-large-language-models-at-scale-d2b133d5e219</figcaption></figure><p>下面是微调的优缺点以及适用场景的总结：</p><p><strong>优点</strong></p><ol><li>高定制化：微调能根据特定任务调整模型，提升在特定领域或任务中的表现，如金融、法律、医学等领域的专业应用。</li><li>一致性高：微调能减少因提示词不同导致的输出差异，使模型在特定任务中的表现更加稳定和一致。</li><li>长效性与可扩展性：微调后的模型能在当前任务中表现更好，且可以通过进一步微调适应新任务，具有较强的长期适应性。</li><li>应对复杂场景：微调能处理比提示词工程更复杂的场景，尤其是需要高精度和深度的任务，如技术文档生成、编程辅助等。</li></ol><p><strong>缺点</strong></p><ol><li>数据质量要求高：微调通常需要大量特定领域的高质量标注数据，这增加了数据准备的成本。</li><li>计算资源需求高：微调涉及重新训练部分模型参数，计算开销较大，需要较强的计算资源。</li><li>开发难度较大：微调需要一定的深度学习背景，开发者需要理解如何设计数据、调整参数和评估效果，门槛较高。</li><li>过拟合风险：如果微调的数据集过于单一或有限，模型可能在特定任务上过拟合，导致在其他场景中表现差。</li></ol><p><strong>适用环境</strong></p><ol><li>需要高定制化的任务：如医疗、法律、金融等领域，微调能帮助模型精确处理专业术语和规则。</li><li>拥有大量标注数据的任务：当有足够标注数据时，微调能有效提升模型性能。</li><li>要求高度一致性的任务：如自动文案生成、客户支持等，微调能确保模型输出的稳定性和一致性。</li><li>复杂或多任务场景：在多任务学习或复杂问题求解中，微调能够提升模型在不同任务中的适应性和处理能力。</li></ol><p>除了模型训练和微调，开发LLM的一个关键环节是确保模型能够理解并回答符合人类需求的问题，这一过程被称为人类对齐。经过人类对齐的模型（Chat模型）通常能够更好地进行通用的问答任务，还可以在此基础上通过少量数据进行微调，以适应特定领域的应用场景。需要注意的是，人类对齐的技术难度通常高于微调，一般由LLM开发方负责实施。</p><p>此外，如果想要获取公开的LLM数据集以进行模型微调，可以参考以下开源仓库：<a href="https://github.com/IBM/data-prep-kit" target="_blank" rel="noopener noreferrer">data-prep-kit</a>和<a href="https://github.com/Zjh-819/LLMDataHub" target="_blank" rel="noopener noreferrer">LLMDataHub</a>。</p><h4 id="_2-2-3-rag" tabindex="-1"><a class="header-anchor" href="#_2-2-3-rag"><span>2.2.3 RAG</span></a></h4><p><strong>检索增强生成（RAG）简介</strong></p><p>检索增强生成（RAG, Retrieval-Augmented Generation）是一种融合LLM与外部知识库的技术。其核心理念是在LLM为用户提供答案时，首先通过从知识库中检索相关信息，并基于这些信息生成精确的回答，类似于对信息库进行快速查询以获得最佳解答。RAG的工作流程如下：</p><ol><li>问题转化与检索：当用户提出问题时，RAG系统会将问题转换为向量表示，并利用向量数据库进行高效检索，找到与问题相关的文档或信息。</li><li>信息召回：系统从知识库中召回与问题相关的文档或信息，确保模型能够基于最新且相关的内容生成答案。</li><li>答案生成：通过将检索到的信息与LLM的生成能力相结合，生成最终的回答。此过程可以是直接返回检索结果，也可以将召回的资料作为上下文输入LLM，由模型进一步加工整理，生成更为详细和精准的答案。</li></ol><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img14.jpg" alt="https://gradientflow.substack.com/p/best-practices-in-retrieval-augmented" tabindex="0" loading="lazy"><figcaption>https://gradientflow.substack.com/p/best-practices-in-retrieval-augmented</figcaption></figure><p>RAG的优缺点及适用场景总结：</p><p><strong>优点</strong></p><ol><li>提高准确性与覆盖面：结合外部信息，RAG能够生成更准确、详细的答案，尤其适用于处理大量实时信息的任务，如问答和文本生成。</li><li>灵活性强：动态检索相关文档，避免依赖固定训练数据，适应多领域及变化任务。</li><li>生成与检索结合：融合生成模型的语言能力与检索模型的知识，使答案既自然流畅又准确及时。</li><li>减少训练难度：相比微调模型，RAG通过检索系统的外部知识提升表现，减少对大规模标注数据的依赖。</li></ol><p><strong>缺点</strong></p><ol><li>依赖外部数据源：若检索源质量差或不准，生成结果会受到影响。</li><li>计算资源需求高：双重过程增加计算开销，尤其在实时检索时需更多资源。</li><li>模型复杂度高：联合训练与推理增加系统复杂性，需更多调试与优化。</li><li>上下文窗口限制：信息量受限于上下文窗口，超大规模知识无法完全纳入生成过程。</li></ol><p><strong>适用场景</strong></p><ol><li>实时更新任务：如新闻生成、知识问答，能够整合最新外部数据，生成高质量内容。</li><li>处理大量知识或冷门任务：适合医学、法律等领域，能检索并生成准确答案。</li><li>跨领域应用：支持跨学科研究与复杂决策，利用多领域信息进行综合分析。</li><li>增强通用LLM：提升通用LLM的表现，尤其在缺乏实时信息或知识库时。</li></ol><h3 id="_2-3-llm评估" tabindex="-1"><a class="header-anchor" href="#_2-3-llm评估"><span>2.3 LLM评估</span></a></h3><p>LLM表现出卓越的泛化能力和适应性，在以前未见过的任务和不同领域中展现出强大的迁移能力。然而，其强大的能力也为评估带来了新的挑战。由于其输出具有高度生成性和开放性，标准化指标通常不足以进行全面评估。</p><p>这是因为尽管LLM具有巨大的潜力和显著的优势，但它也面临着一些关键挑战。例如，LLM的评估结果往往受到提示模板的影响，这可能导致评估有偏见或不一致。考虑到 LLM是在大量文本语料库上训练的，它们还可能继承各种隐性偏见，影响其评估的公平性和可靠性。</p><p>目前，常见的评估方法主要分为两种：自动评估和人工评估。其分类标准基于评估是否可以自动计算：若评估标准能够自动计算，则归类为自动评估；否则，归类为人工评估。关于LLM评估的详细指南可以查看huggingface提供评估工具：<a href="https://github.com/huggingface/evaluation-guidebook" target="_blank" rel="noopener noreferrer">evaluation-guidebook</a>。</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img15.jpg" alt="https://arxiv.org/pdf/2310.19736" tabindex="0" loading="lazy"><figcaption>https://arxiv.org/pdf/2310.19736</figcaption></figure><h4 id="_2-3-1-llm自动评估" tabindex="-1"><a class="header-anchor" href="#_2-3-1-llm自动评估"><span>2.3.1 LLM自动评估</span></a></h4><p>自动评估是最常见且广泛应用的评估方法之一，通常利用标准化的指标和工具来衡量模型性能。与人工评估相比，自动评估不依赖大量人工参与，能够节省时间并减少人为主观偏差，从而使评估过程更加规范化。自动评估通常从多个维度对模型进行评价，包括准确率、校准性、公平性和鲁棒性等：</p><ol><li><p>准确率：衡量模型在特定任务上正确预测的程度。准确率的定义因任务和问题的不同而有所差异，通常使用多种指标进行衡量，如精确匹配、F1 分数和 ROUGE 分数。</p><ul><li>精确匹配（Exact Match）：用于评估模型在文本生成任务中的输出是否与参考答案完全一致。在问答任务中，如果模型生成的答案与人工提供的答案完全一致，则精确匹配为1，否则为0。</li><li>F1分数：综合考虑模型的精度和召回率。</li><li>ROUGE分数：主要用于评估文本摘要和机器翻译任务，衡量生成文本与参考文本之间的重叠和匹配程度。</li></ul></li><li><p>校准性：衡量模型输出的置信度与实际预测精度之间的一致性。</p><ul><li>期望校准误差（Expected Calibration Error）：评估模型校准性能的常用方法。该方法通过将预测概率划分为多个区间，计算每个区间内的预测误差，并对这些误差加权平均，得出整体的校准误差。较低的值表示模型在不同置信度水平下具有较好的校准性。</li><li>选择性准确率和覆盖率的曲线下面积（AUC）：选择性准确率表示在特定置信度阈值下，模型正确预测的比例，而覆盖率则是该置信度阈值下，模型预测结果中有效预测的比例。通过绘制选择性准确率与覆盖率之间的关系曲线，可以计算出其曲线下面积AUC。AUC值较大的模型通常表明高置信度的预测更为准确。</li></ul></li><li><p>公平性：评估模型对不同群体表现的一致性，即模型在不同群体中的表现是否公平。群体差异可能涉及性别、种族、年龄等因素：</p><ul><li>人口平衡差异（Demographic Parity Difference）：衡量模型的预测是否在不同人群之间均匀分布。如果不同群体的预测结果差异较大，说明模型可能存在对某些群体的偏见。</li><li>平等机会差异（Equalized Odds Difference）：旨在确保模型在不同群体中具有相等的错误率，即模型在各群体中的预测错误概率应相似。</li></ul></li><li><p>鲁棒性：评估模型在面对各种挑战性输入时的表现，包括对抗性攻击、数据分布变化和噪声等因素的影响：</p><ul><li>攻击成功率（Attack Success Rate）：用于评估LLM在面对对抗性攻击时的鲁棒性。</li><li>性能下降率（Performance Drop Rate）：评估LLM在面对不同提示词时的鲁棒性，衡量模型性能在这些情况下的下降程度。</li></ul></li></ol><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img16.jpg" alt="https://www.airtrain.ai/blog/the-comprehensive-guide-to-llm-evaluation" tabindex="0" loading="lazy"><figcaption>https://www.airtrain.ai/blog/the-comprehensive-guide-to-llm-evaluation</figcaption></figure><h4 id="_2-3-2-llm人工评估" tabindex="-1"><a class="header-anchor" href="#_2-3-2-llm人工评估"><span>2.3.2 LLM人工评估</span></a></h4><p>随着LLM能力的不断增强，它们已经超越了传统的通用自然语言任务评估标准。虽然一些生成任务可以采用自动评估方法，但在人类评估的情况下，生成结果往往能超越标准答案，因此备受青睐。</p><p>人工评估是一种通过人类参与来评估模型生成结果质量和准确性的方法。与自动评估相比，人工评估更贴近实际应用场景，能够提供更全面、准确的反馈。在LLM的人工评估中，通常会邀请评估者（如专家、研究人员或普通用户）对模型生成的结果进行评价。然而，即使是人工评估也可能存在较大的波动和不稳定性，这可能与文化差异和个体差异有关。在实际应用中，通常会综合考虑这两种评估方法，并根据具体情况进行权衡。</p><p>探索LLM的人工评估方法需要特别关注多个关键因素，以确保评估结果的可靠性和准确性。评估者的数量是一个至关重要的因素，它与评估的代表性和统计意义密切相关。合理选择评估者数量有助于对LLM进行更细致、全面的评估，从而更可靠地将评估结果推广到更广泛的场景中。</p><p>评估标准是人工评估过程中的核心内容。这些标准能够全面分析LLM在语法、语义和上下文等方面的表现，从而更深入地评估生成文本的质量。常见的评估标准包括：</p><ol><li>准确性：准确性是评估标准中最为关键的一项，关注生成文本的正确性与精确性。该标准要求检查模型生成的信息是否与事实一致，避免出现错误或不准确的内容。</li><li>相关性：相关性评估生成内容的适切性和重要性，考察文本是否与给定的上下文或问题紧密相关，确保提供的信息不仅直接相关，还具有实际应用价值。</li><li>流畅性：流畅性评估模型生成内容的连贯性和一致性。一个流畅的文本不仅语法正确，还需确保可读性和用户体验，避免出现生硬的表达或突兀的语言转换。</li><li>透明性：透明性关注模型决策过程的清晰度与可解释性，评估模型是否能够清晰地传达其思维过程，使用户理解为何以及如何生成某些回答。透明的模型能够提供对其内部工作原理的深入洞察。</li><li>安全性：安全性是评估标准中的一个关键项，关注生成文本可能带来的潜在风险或不良后果。该标准评估模型在避免生成不适当、冒犯性或有害内容方面的能力，确保用户的安全，并防止虚假信息的传播。</li><li>人类对齐性：人类对齐性评估生成内容是否符合人类的价值观、偏好和期望。该标准关注生成内容的伦理影响，确保模型生成的文本符合社会规范与用户期望，促进积极的用户互动。</li></ol><h4 id="_2-3-3-llm评估工具" tabindex="-1"><a class="header-anchor" href="#_2-3-3-llm评估工具"><span>2.3.3 LLM评估工具</span></a></h4><p>随着LLM在各行各业及应用场景中的广泛应用，评估流程在自然语言处理、内容生成、客户服务自动化等任务中的重要性日益凸显。与此同时，随着LLM技术的不断进步，涌现出一系列自动化评估工具、评估数据集和评估基准，以更好地满足日益增长的实际应用需求。开源仓库<a href="https://github.com/Hannibal046/Awesome-LLM" target="_blank" rel="noopener noreferrer">Awesome-LLM</a>和<a href="https://github.com/onejune2018/Awesome-LLM-Eval" target="_blank" rel="noopener noreferrer">Awesome LLM Eval</a>提供了各类LLM评测工具、基准/数据集、排行榜等内容的精选资源。</p><p>如果想了解LLM的评估情况，尤其是当前开源LLM的表现，可以参考<a href="https:////huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/" target="_blank" rel="noopener noreferrer">Open LLM</a>排行榜，这是由Hugging Face 设立的一个专注于评测开源LLM的公开榜单。该排行榜汇集了多个模型的评测结果，展示了各种模型在不同任务中的性能，包括推理速度、生成质量、理解能力等多个维度。</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img17.jpg" alt="https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/" tabindex="0" loading="lazy"><figcaption>https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/</figcaption></figure><h3 id="_2-4-llm量化、部署、优化" tabindex="-1"><a class="header-anchor" href="#_2-4-llm量化、部署、优化"><span>2.4 LLM量化、部署、优化</span></a></h3><h4 id="_2-4-1-模型量化" tabindex="-1"><a class="header-anchor" href="#_2-4-1-模型量化"><span>2.4.1 模型量化</span></a></h4><p>随着LLM技术的迅猛发展，其模型复杂度呈现出指数级增长，导致参数数量的显著增加。例如，2018年发布的首个GPT模型拥有约1.1亿个参数，而至2019年底，GPT-2的参数量已扩展至15亿，2020年底发布的GPT-3更是突破了1750亿个参数。目前，GPT-4的参数量已预计突破1万亿。</p><p>这一增长伴随着一系列挑战：随着模型规模的扩大，内存需求急剧上升。这种日益增长的内存需求不仅限制了推理模型的训练与部署，也制约了基于LLM的解决方案在实际应用中的普及。因此，如何在保证模型性能的前提下缩减模型规模，成为亟待解决的核心问题。量化技术作为一种有效的解决手段，在尽可能保持性能的同时，显著降低内存占用。</p><p>量化旨在将LLM中的权重和激活值从高精度表示转化为低精度表示，即将数据从能够存储更多信息的类型转换为存储信息较少的类型。例如，将32位浮点数（float32）转换为8位整数（int8）。尽管量化技术在LLM中得到广泛应用，但它很早便在深度学习领域中得到应用，尤其在图像处理等任务中。通过减少每个权重或激活值所需的位数，量化显著减少了模型的总体大小。因此，量化不仅能够减小LLM在内存中的占用，还能降低存储需求并提升能效。然而，在提升计算效率的同时，量化技术需要在性能和精度之间寻找到合理的平衡点。</p><p>量化的基本原理是基于每个张量（tensor）的浮点型最大值与最小值，将其映射为一个固定范围内的整数集合，例如[-127, 127]。其公式可表示为：</p><mjx-container class="MathJax" jax="SVG" display="true" style="position:relative;"><svg style="vertical-align:-2.148ex;" xmlns="http://www.w3.org/2000/svg" width="25.867ex" height="5.428ex" role="img" focusable="false" viewBox="0 -1449.5 11433.1 2399" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(479,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(722,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1166,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(1444,0)"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1944,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(2500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(2849.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mtext" transform="translate(3905.4,0)"><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(392,0)"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(892,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1448,0)"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(2004,0)"></path></g><g data-mml-node="mrow" transform="translate(6632.1,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z"></path></g><g data-mml-node="mfrac" transform="translate(736,0)"><g data-mml-node="mtext" transform="translate(220,676)"><path data-c="77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(722,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1166,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(1444,0)"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1944,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(2500,0)"></path></g><g data-mml-node="mtext" transform="translate(634.5,-686)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(394,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(838,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1338,0)"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1616,0)"></path></g><rect width="3089" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(4065,0) translate(0 -0.5)"><path data-c="29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>q</mi><mrow data-mjx-texclass="ORD"><mtext>weight</mtext></mrow></msub><mo>=</mo><mtext>round</mtext><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mfrac><mtext>weight</mtext><mtext>scale</mtext></mfrac><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container><p>其中<mjx-container class="MathJax" jax="SVG" style="position:relative;"><svg style="vertical-align:-0.669ex;" xmlns="http://www.w3.org/2000/svg" width="5.819ex" height="1.669ex" role="img" focusable="false" viewBox="0 -442 2571.8 737.7" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(479,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(722,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1166,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(1444,0)"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1944,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(2500,0)"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>q</mi><mrow data-mjx-texclass="ORD"><mtext>weight</mtext></mrow></msub></math></mjx-assistive-mml></mjx-container> 为量化后的权重，<mjx-container class="MathJax" jax="SVG" style="position:relative;"><svg style="vertical-align:-0.466ex;" xmlns="http://www.w3.org/2000/svg" width="6.536ex" height="2.036ex" role="img" focusable="false" viewBox="0 -694 2889 900" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(722,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1166,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(1444,0)"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1944,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(2500,0)"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>weight</mtext></math></mjx-assistive-mml></mjx-container> 为量化前的权重，<mjx-container class="MathJax" jax="SVG" style="position:relative;"><svg style="vertical-align:-0.025ex;" xmlns="http://www.w3.org/2000/svg" width="4.661ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 2060 705" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(394,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(838,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1338,0)"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1616,0)"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>scale</mtext></math></mjx-assistive-mml></mjx-container> 为缩放因子。可以看出，在进行量化时，通过缩放和取整操作，浮点数会丢失小数部分。在后续的计算或反量化过程中，由于无法完全恢复原浮点值，因此会出现一定的精度损失。</p><p>量化过程可以类比于图像压缩。高分辨率图像通常需要进行压缩，以加快网页加载速度。压缩通过去除部分数据或信息位，减小图像文件的大小。尽管压缩会在一定程度上影响图像质量，但它显著减少了文件体积，同时仍能提供较为清晰的视觉效果。</p><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img18.jpg" alt="https://medium.com/@abonia/llm-series-quantization-overview-1b37c560946b" tabindex="0" loading="lazy"><figcaption>https://medium.com/@abonia/llm-series-quantization-overview-1b37c560946b</figcaption></figure><p>根据量化发生的阶段，量化方法可以分为两种：一种是训练后量化（Post-Training Quantization，PTQ），也称为离线量化，它在模型训练完成后对参数进行量化，不修改训练过程。在推理阶段，模型参数的动态范围将被重新计算；另一种是训练感知量化（Quantization-Aware Training，QAT），也称为在线量化，它通过修改训练过程，模拟量化对模型的影响，从而增强模型对量化误差的鲁棒性，并提高最终的准确性。在QAT过程中，训练的中间状态同时保存量化后的权重和原始未量化的权重（两者存储在内存中），推理时使用量化版本的模型，而在反向传播阶段则使用未量化的权重进行更新。QAT相较PTQ更加复杂且训练时间较长，但通常能够带来更高的准确性。</p><p>更多关于LLM量化的详细介绍可参考：<a href="https://medium.com/@abonia/llm-series-quantization-overview-1b37c560946b" target="_blank" rel="noopener noreferrer">Quantization Overview</a>。</p><h4 id="_2-4-2-模型推理部署" tabindex="-1"><a class="header-anchor" href="#_2-4-2-模型推理部署"><span>2.4.2 模型推理部署</span></a></h4><p><strong>LLM推理</strong></p><p>LLM的推理部署有多种方式：</p><ul><li>直接使用PyTorch代码： 对于熟悉PyTorch的用户来说，可以直接利用其提供的接口进行推理。</li><li>使用专用框架： <ul><li>VLLM: 专为高效处理LLM而设计。</li><li>XInference: 提供便捷的部署流程，可以快速将模型部署到不同的硬件平台。</li><li>FastChat: 专注于对话模型的推理和优化。</li></ul></li><li>使用C++推理框架： <ul><li>llama.cpp/chatglm.cpp/qwen.cpp: 提供了高性能的C++实现，适合对性能有较高要求的场景。</li></ul></li></ul><p><strong>文本生成策略</strong></p><p>在文本生成过程中，LLM通常采用自回归生成方式，即基于已生成的部分预测下一个部分。不同的采样策略会影响模型生成下一个词的方式，常见的采样策略包括：</p><ul><li>贪婪搜索（Greedy Search）：模型根据前文内容，从词表中选择生成概率最高的下一个token。该方法简单高效，但由于始终选择概率最大值，生成的文本可能显得单调和重复。</li><li>束搜索（Beam Search）：与贪婪搜索不同，束搜索会同时考虑生成概率最高的k个token。在每一步生成下一个token时，模型会根据当前已生成的tokens，生成k个候选token，从而形成k²个可能的组合，并从中选择概率最高的k个序列继续生成，最终输出条件概率最优的序列。该方法能够在生成质量与多样性之间取得平衡，但可能导致生成的文本显得较为保守且不够自然。</li><li>随机采样（Sampling）：根据每个token的生成概率，从词表中随机选择下一个token。此方法能够增加生成文本的多样性，是目前主流的文本生成方式，但也可能导致生成的文本缺乏连贯性或逻辑性。</li></ul><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img19.jpg" alt="https://heidloff.net/article/greedy-beam-sampling/" tabindex="0" loading="lazy"><figcaption>https://heidloff.net/article/greedy-beam-sampling/</figcaption></figure><p>可以看出，以上方法各自存在一定的局限性，因此LLM中引入了temperature温度参数，用于调节生成文本的随机性与确定性，并结合top-k采样和top-p采样这两种介于贪心解码和完全随机采样之间的策略，以优化文本生成过程。具体解释如下：</p><ul><li>temperature：该参数控制生成文本的随机性与确定性之间的平衡。该值越高，生成的文本越具有多样性；而值越低，生成的文本则趋向于更加确定性和一致性。</li><li>top-k：top-k采样是对传统贪心解码策略的一种优化，它从概率排名前k的token中进行采样，允许其他高概率的token也有机会被选中。这种方式通过引入一定的随机性，有助于提升生成文本的质量。</li><li>top-p：top-p采样在每一步生成时，只从累积概率超过预设阈值p的最小token集合中进行随机采样，忽略低概率的token。该方法聚焦于概率分布的核心部分，避免了过多依赖概率较低的尾部元素。</li></ul><p>top-p采样在实际应用中通常被认为比top-k采样更自然和灵活，因为它允许模型考虑更多的候选词，通过累积概率的方式来选择下一个词，从而生成的文本更加连贯和多样化，而不是像 top-k采样那样只从概率最高的几个词中选择，可能导致生成的文本过于单一和重复。</p><p>对于温度参数（temperature），首先需要了解Softmax函数的基本概念。Softmax函数广泛应用于神经网络的输出层。它将一个向量或一组实数映射到另一个向量，使得输出值位于0到1之间，并且所有输出值的总和为1。因此，Softmax函数的输出可以被解释为概率分布。</p><p>具体而言，对于输入向量<mjx-container class="MathJax" jax="SVG" style="position:relative;"><svg style="vertical-align:-0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.052ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 465 453" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>z</mi></math></mjx-assistive-mml></mjx-container>中的第<mjx-container class="MathJax" jax="SVG" style="position:relative;"><svg style="vertical-align:-0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewBox="0 -661 345 672" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></mjx-assistive-mml></mjx-container>个元素，Softmax函数的定义为：</p><mjx-container class="MathJax" jax="SVG" display="true" style="position:relative;"><svg style="vertical-align:-2.578ex;" xmlns="http://www.w3.org/2000/svg" width="21.934ex" height="5.636ex" role="img" focusable="false" viewBox="0 -1351.5 9695 2491.1" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(556,0)"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1056,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1362,0)"></path><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1751,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2584,0)"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(3084,0)"></path></g><g data-mml-node="mo" transform="translate(3612,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(4001,0)"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(498,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(4793,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5459.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(6515.5,0)"><g data-mml-node="msup" transform="translate(1035.2,676)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(498,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1089,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g><g data-mml-node="msup" transform="translate(1597,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,318.6) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(498,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></g></g><rect width="2939.5" height="60" x="120" y="220"></rect></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Softmax</mtext><mo stretchy="false">(</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><msup><mi>e</mi><mrow data-mjx-texclass="ORD"><msub><mi>z</mi><mi>i</mi></msub></mrow></msup><mrow><munder><mo data-mjx-texclass="OP">∑</mo><mrow data-mjx-texclass="ORD"><mi>j</mi></mrow></munder><msup><mi>e</mi><mrow data-mjx-texclass="ORD"><msub><mi>z</mi><mi>j</mi></msub></mrow></msup></mrow></mfrac></math></mjx-assistive-mml></mjx-container><p>其中，<mjx-container class="MathJax" jax="SVG" style="position:relative;"><svg style="vertical-align:-0.025ex;" xmlns="http://www.w3.org/2000/svg" width="2.509ex" height="1.553ex" role="img" focusable="false" viewBox="0 -675.5 1109 686.5" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(498,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>e</mi><mrow data-mjx-texclass="ORD"><msub><mi>z</mi><mi>i</mi></msub></mrow></msup></math></mjx-assistive-mml></mjx-container>表示<mjx-container class="MathJax" jax="SVG" style="position:relative;"><svg style="vertical-align:-0.357ex;" xmlns="http://www.w3.org/2000/svg" width="1.792ex" height="1.357ex" role="img" focusable="false" viewBox="0 -442 792 599.8" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(498,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>z</mi><mi>i</mi></msub></math></mjx-assistive-mml></mjx-container>的指数，而分母是所有输入元素的指数和。这样的设计确保了较大值的输入元素对应的概率较高，而较小值的输入元素对应的概率较低，但不会完全为零。</p><p>为了调整输出的概率分布，在Softmax函数中引入了温度参数（temperature parameter）<mjx-container class="MathJax" jax="SVG" style="position:relative;"><svg style="vertical-align:0;" xmlns="http://www.w3.org/2000/svg" width="1.593ex" height="1.532ex" role="img" focusable="false" viewBox="0 -677 704 677" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi></math></mjx-assistive-mml></mjx-container>。温度参数<mjx-container class="MathJax" jax="SVG" style="position:relative;"><svg style="vertical-align:0;" xmlns="http://www.w3.org/2000/svg" width="1.593ex" height="1.532ex" role="img" focusable="false" viewBox="0 -677 704 677" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi></math></mjx-assistive-mml></mjx-container>可以通过修改指数部分来控制输出的平滑度。具体形式为：</p><mjx-container class="MathJax" jax="SVG" display="true" style="position:relative;"><svg style="vertical-align:-2.802ex;" xmlns="http://www.w3.org/2000/svg" width="26.459ex" height="6.353ex" role="img" focusable="false" viewBox="0 -1569.3 11695 2807.8" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(556,0)"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1056,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1362,0)"></path><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1751,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2584,0)"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(3084,0)"></path></g><g data-mml-node="mo" transform="translate(3612,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(4001,0)"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(498,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(4793,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(5237.6,0)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mo" transform="translate(5941.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(6608.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(7664.2,0)"><g data-mml-node="msup" transform="translate(1035.2,676)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(498,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(792,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path></g></g><g data-mml-node="mi" transform="translate(1292,0)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-808.9)"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1089,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g><g data-mml-node="msup" transform="translate(1597,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,318.6) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(498,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(839.3,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path></g></g><g data-mml-node="mi" transform="translate(1339.3,0)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></g><rect width="3790.8" height="60" x="120" y="220"></rect></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Softmax</mtext><mo stretchy="false">(</mo><msub><mi>z</mi><mi>i</mi></msub><mo>,</mo><mi>T</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><msup><mi>e</mi><mrow data-mjx-texclass="ORD"><msub><mi>z</mi><mi>i</mi></msub><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mi>T</mi></mrow></msup><mrow><munder><mo data-mjx-texclass="OP">∑</mo><mrow data-mjx-texclass="ORD"><mi>j</mi></mrow></munder><msup><mi>e</mi><mrow data-mjx-texclass="ORD"><msub><mi>z</mi><mi>j</mi></msub><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mi>T</mi></mrow></msup></mrow></mfrac></math></mjx-assistive-mml></mjx-container><p>当<mjx-container class="MathJax" jax="SVG" style="position:relative;"><svg style="vertical-align:0;" xmlns="http://www.w3.org/2000/svg" width="1.593ex" height="1.532ex" role="img" focusable="false" viewBox="0 -677 704 677" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi></math></mjx-assistive-mml></mjx-container>值较大时，输出的概率分布趋于平坦，即所有输出的概率接近均匀分布；而当<mjx-container class="MathJax" jax="SVG" style="position:relative;"><svg style="vertical-align:0;" xmlns="http://www.w3.org/2000/svg" width="1.593ex" height="1.532ex" role="img" focusable="false" viewBox="0 -677 704 677" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi></math></mjx-assistive-mml></mjx-container>趋向于0时，概率分布则变得更加集中，几乎所有的概率都会集中在最大的元素上。这种调整可以控制模型输出的确定性或多样性。</p><p>关于文本生成策略更详细的介绍见：<img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img20.jpg" alt="https://newsletter.theaiedge.io/p/how-llms-generate-text" loading="lazy"></p><h4 id="_2-4-3-模型优化技术" tabindex="-1"><a class="header-anchor" href="#_2-4-3-模型优化技术"><span>2.4.3 模型优化技术</span></a></h4><p>随着LLM的发展，各种优化技术从不同角度不断涌现，具体包括常见以下几种：</p><ol><li><p>Static kv-cache and torch.compile</p><ul><li>Static kv-cache（键值缓存）是一种优化技术，旨在存储LLM在解码过程中的键值对，以避免重复计算，从而提高效率。与<code>torch.compile</code>结合使用时，通过预先分配kv-cache的大小，可以实现静态分配，进一步优化性能，可能带来最多4倍的速度提升。</li></ul></li><li><p>Speculative decoding</p><ul><li>推测性解码是一种加速自回归模型采样的技术。它使用一个较小且更快的辅助模型生成候选token，然后由较大的LLM在单次前向传播中验证这些token。如果验证正确，LLM可以“免费”获得这些token，而不需要自己生成，且不会损失准确性。</li></ul></li><li><p>Prompt lookup decoding</p><ul><li>Prompt lookup decoding适用于输入和输出之间存在重叠词汇的任务（如摘要生成）。它通过在输入提示中进行字符串匹配，生成候选token序列，从而替代传统推测性解码中的草稿模型。</li></ul></li><li><p>Attention optimizations</p><ul><li>FlashAttention-2：这是一种优化算法，通过将注意力计算分解为更小的块，减少GPU内存的中间读写操作，从而加速推理过程。</li><li>Fine-Tuning with torch.compile and Padding-Free Data Collation：通过使用<code>torch.compile</code>进行微调，结合无填充数据整理技术，可以进一步提高模型运行效率。</li><li>PyTorch scaled dot product attention：通过硬件加速和优化的计算图来加速模型的训练和推理。</li></ul></li><li><p>VLLM</p><ul><li>VLLM是一个快速且易于使用的LLM推理与服务库，支持分布式和容器化部署，且内置LLM服务，用户可通过命令直接启动。</li></ul></li><li><p>FastChat</p><ul><li>FastChat是一个开源平台，旨在支持训练和分布式部署。它提供了先进模型的训练评估代码和分布式多模型服务系统，包含Web界面以及与OpenAI兼容的RESTful API。</li></ul></li></ol><p>关于这些技术的详细介绍见：<a href="https://huggingface.co/docs/transformers/main/en/llm_optims#llm-inference-optimization" target="_blank" rel="noopener noreferrer">llm inference optimization</a>。</p><h2 id="_3-总结" tabindex="-1"><a class="header-anchor" href="#_3-总结"><span>3 总结</span></a></h2><p>涉及LLM的项目可能是一项艰巨的任务。它需要适当的协调和技能才能成功执行任务。一个LLM项目从最初的构思到最终部署的整个过程。可以将这个过程分为如下主要阶段：</p><ol><li><p>定义项目的范围：</p><ul><li>明确目标：首先要明确这个LLM项目的目标是什么？是用于生成文本、对话助手、翻译语言、还是执行其他任务？</li><li>确定范围：接下来要确定项目的范围，即这个LLM模型需要处理的数据量、任务复杂度以及所需的性能。</li></ul></li><li><p>数据预处理和相关考虑：</p><ul><li>数据收集：收集与项目相关的大量高质量数据。</li><li>数据清洗：对数据进行清洗，去除噪声、错误和不一致的数据。</li><li>数据标注：为数据添加标签，以便模型能够学习到正确的关联。</li></ul></li><li><p>选择一个基座的模型：</p><ul><li>模型选择：根据项目的需求选择一个合适的基座模型，以及是使用Base模型还是Chat模型。不同的模型在处理不同任务时表现会有所不同。</li><li>考虑因素：在选择模型时，需要考虑模型的规模、参数数量、训练数据量以及计算资源等因素。</li></ul></li><li><p>模型训练：</p><ul><li>模型训练：利用准备好的数据集和适当的训练方法对模型进行训练，特别要注重选择合适的训练策略。</li><li>训练稳定性：LLM的训练相比其他深度学习模型更容易遇到意外问题，如不收敛、训练不稳定、突发中断等，要提前做好应对方案。</li></ul></li><li><p>强化学习：</p><ul><li>交互学习：通过与环境的交互，让模型不断学习和改进。</li><li>奖励机制：设计合理的奖励机制，引导模型朝着目标方向发展。</li></ul></li><li><p>评估模型：</p><ul><li>性能评估：使用测试数据对模型的性能进行评估，以确定模型是否达到预期的效果。</li><li>指标选择：选择合适的评价指标。</li></ul></li><li><p>模型优化和部署：</p><ul><li>模型优化：对模型进行量化等，以减小模型的尺寸和提高推理速度。</li><li>部署：将训练好的模型部署到实际应用中，提供服务。</li></ul></li><li><p>模型监控和构建LLM应用：</p><ul><li>模型监控：持续监控模型的性能，及时发现问题并进行调整。</li><li>应用开发：基于训练好的模型开发各种LLM应用，如聊天机器人、文本生成工具等。</li></ul></li></ol><figure><img src="https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/大模型/大模型学习1-大语言模型基础知识/img/img21.jpg" alt="https://datasciencedojo.com/blog/llm-project-lifecycle/" tabindex="0" loading="lazy"><figcaption>https://datasciencedojo.com/blog/llm-project-lifecycle/</figcaption></figure><p>总之，LLM项目的整个生命周期是一个持续迭代的过程，涵盖了目标定义、模型训练、模型部署、监控以及应用开发等各个环节，且每个阶段都紧密相连、相互依赖。训练LLM的难点，不仅仅在于单一技术的挑战，更在于系统性复杂性的应对。这一过程需要数据、工程师、框架和硬件等多个方面的紧密协作与配合，才能推动工作的顺利进行。</p><h2 id="_4-参考" tabindex="-1"><a class="header-anchor" href="#_4-参考"><span>4 参考</span></a></h2><ul><li><a href="https://github.com/modelscope/modelscope-classroom" target="_blank" rel="noopener noreferrer">modelscope-classroom</a></li><li><a href="https://arxiv.org/abs/2307.09288" target="_blank" rel="noopener noreferrer">Llama 2: Open Foundation and Fine-Tuned Chat Models</a></li><li><a href="https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder" target="_blank" rel="noopener noreferrer">Understanding Encoder And Decoder LLMs</a></li><li><a href="https://myscale.com/blog/prompt-engineering-vs-finetuning-vs-rag/" target="_blank" rel="noopener noreferrer">Prompt Engineering vs Fine-tuning vs RAG</a></li><li><a href="https://github.com/IBM/data-prep-kit" target="_blank" rel="noopener noreferrer">data-prep-kit</a></li><li><a href="https://github.com/Zjh-819/LLMDataHub" target="_blank" rel="noopener noreferrer">LLMDataHub</a></li><li><a href="https://github.com/huggingface/evaluation-guidebook" target="_blank" rel="noopener noreferrer">evaluation-guidebook</a></li><li><a href="https://github.com/Hannibal046/Awesome-LLM" target="_blank" rel="noopener noreferrer">Awesome-LLM</a></li><li><a href="https://github.com/onejune2018/Awesome-LLM-Eval" target="_blank" rel="noopener noreferrer">Awesome LLM Eval</a></li><li><a href="https://medium.com/@abonia/llm-series-quantization-overview-1b37c560946b" target="_blank" rel="noopener noreferrer">Quantization Overview</a></li><li><a href="https://newsletter.theaiedge.io/p/how-llms-generate-text" target="_blank" rel="noopener noreferrer">How LLMs Generate Text</a></li><li><a href="https://huggingface.co/docs/transformers/main/en/llm_optims#llm-inference-optimization" target="_blank" rel="noopener noreferrer">llm inference optimization</a></li></ul></div><!----><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><!----><a class="route-link auto-link next" href="/blog/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/2025-02-28-_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A02-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8C%97.html" aria-label="[深度学习] 大模型学习2-提示词工程指北" iconsizing="both"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">[深度学习] 大模型学习2-提示词工程指北<!----></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><!----><div class="vp-copyright">Copyright © 2025 落痕月极 </div></footer></div><!--]--><!--[--><!----><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-TQoR7mvJ.js" defer></script>
  </body>
</html>
